Log file created at: 2017/05/30 14:20:26
Running on machine: DESKTOP-DPP5KFC
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0530 14:20:26.061117  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:20:26.061117  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:20:26.061117  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:20:26.062089  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:20:26.062850  6908 layer_factory.hpp:77] Creating layer input
I0530 14:20:26.062850  6908 net.cpp:84] Creating Layer input
I0530 14:20:26.062850  6908 net.cpp:380] input -> data
I0530 14:20:26.116853  6908 net.cpp:122] Setting up input
I0530 14:20:26.116853  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:20:26.116853  6908 net.cpp:137] Memory required for data: 16384
I0530 14:20:26.116853  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:20:26.116853  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:20:26.116853  6908 net.cpp:406] conv1_1 <- data
I0530 14:20:26.116853  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:20:26.118880  6908 net.cpp:122] Setting up conv1_1
I0530 14:20:26.118880  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:20:26.118880  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:20:26.118880  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:20:26.118880  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:20:26.118880  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:20:26.118880  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:20:26.118880  6908 net.cpp:122] Setting up relu1_1
I0530 14:20:26.118880  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:20:26.118880  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:20:26.118880  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:20:26.118880  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:20:26.118880  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:20:26.118880  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:20:26.119877  6908 net.cpp:122] Setting up conv1_2
I0530 14:20:26.119877  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:20:26.119877  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:20:26.119877  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:20:26.119877  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:20:26.119877  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:20:26.119877  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:20:26.119877  6908 net.cpp:122] Setting up relu1_2
I0530 14:20:26.119877  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:20:26.119877  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:20:26.119877  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:20:26.119877  6908 net.cpp:84] Creating Layer pool1
I0530 14:20:26.119877  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:20:26.119877  6908 net.cpp:380] pool1 -> pool1
I0530 14:20:26.119877  6908 net.cpp:122] Setting up pool1
I0530 14:20:26.119877  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:20:26.119877  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:20:26.119877  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:20:26.119877  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:20:26.119877  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:20:26.119877  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:20:26.120877  6908 net.cpp:122] Setting up conv2_1
I0530 14:20:26.120877  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:20:26.120877  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:20:26.120877  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:20:26.120877  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:20:26.120877  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:20:26.120877  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:20:26.120877  6908 net.cpp:122] Setting up relu2_1
I0530 14:20:26.120877  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:20:26.120877  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:20:26.120877  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:20:26.120877  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:20:26.120877  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:20:26.120877  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:20:26.120877  6908 net.cpp:122] Setting up conv2_2
I0530 14:20:26.120877  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:20:26.120877  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:20:26.120877  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:20:26.120877  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:20:26.120877  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:20:26.120877  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:20:26.120877  6908 net.cpp:122] Setting up relu2_2
I0530 14:20:26.120877  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:20:26.120877  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:20:26.120877  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:20:26.120877  6908 net.cpp:84] Creating Layer pool2
I0530 14:20:26.120877  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:20:26.120877  6908 net.cpp:380] pool2 -> pool2
I0530 14:20:26.121876  6908 net.cpp:122] Setting up pool2
I0530 14:20:26.121876  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:26.121876  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:20:26.121876  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:20:26.121876  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:20:26.121876  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:20:26.121876  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:20:26.121876  6908 net.cpp:122] Setting up conv3_1
I0530 14:20:26.121876  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:26.121876  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:20:26.121876  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:20:26.121876  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:20:26.121876  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:20:26.121876  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:20:26.121876  6908 net.cpp:122] Setting up relu3_1
I0530 14:20:26.121876  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:26.121876  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:20:26.121876  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:20:26.121876  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:20:26.121876  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:20:26.121876  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:20:26.122876  6908 net.cpp:122] Setting up conv3_2
I0530 14:20:26.122876  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:26.122876  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:20:26.122876  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:20:26.122876  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:20:26.122876  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:20:26.122876  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:20:26.122876  6908 net.cpp:122] Setting up relu3_2
I0530 14:20:26.122876  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:26.122876  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:20:26.122876  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:20:26.122876  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:20:26.122876  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:20:26.122876  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:20:26.124877  6908 net.cpp:122] Setting up conv3_3
I0530 14:20:26.124877  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:26.124877  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:20:26.124877  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:20:26.124877  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:20:26.124877  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:20:26.124877  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:20:26.124877  6908 net.cpp:122] Setting up relu3_3
I0530 14:20:26.124877  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:26.124877  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:20:26.124877  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:20:26.124877  6908 net.cpp:84] Creating Layer pool3
I0530 14:20:26.124877  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:20:26.124877  6908 net.cpp:380] pool3 -> pool3
I0530 14:20:26.124877  6908 net.cpp:122] Setting up pool3
I0530 14:20:26.124877  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:20:26.124877  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:20:26.124877  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:20:26.124877  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:20:26.124877  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:20:26.124877  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:20:26.125874  6908 net.cpp:122] Setting up conv4_1
I0530 14:20:26.125874  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:26.125874  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:20:26.125874  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:20:26.125874  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:20:26.125874  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:20:26.125874  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:20:26.125874  6908 net.cpp:122] Setting up relu4_1
I0530 14:20:26.125874  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:26.125874  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:20:26.125874  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:20:26.125874  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:20:26.125874  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:20:26.125874  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:20:26.129881  6908 net.cpp:122] Setting up conv4_2
I0530 14:20:26.129881  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:26.129881  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:20:26.129881  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:20:26.129881  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:20:26.129881  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:20:26.129881  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:20:26.129881  6908 net.cpp:122] Setting up relu4_2
I0530 14:20:26.129881  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:26.129881  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:20:26.129881  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:20:26.129881  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:20:26.129881  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:20:26.129881  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:20:26.133882  6908 net.cpp:122] Setting up conv4_3
I0530 14:20:26.133882  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:26.133882  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:20:26.133882  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:20:26.133882  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:20:26.133882  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:20:26.133882  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:20:26.133882  6908 net.cpp:122] Setting up relu4_3
I0530 14:20:26.133882  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:26.133882  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:20:26.133882  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:20:26.133882  6908 net.cpp:84] Creating Layer pool4
I0530 14:20:26.133882  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:20:26.133882  6908 net.cpp:380] pool4 -> pool4
I0530 14:20:26.133882  6908 net.cpp:122] Setting up pool4
I0530 14:20:26.133882  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:26.133882  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:20:26.133882  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:20:26.133882  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:20:26.133882  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:20:26.133882  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:20:26.137881  6908 net.cpp:122] Setting up conv5_1
I0530 14:20:26.137881  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:26.137881  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:20:26.137881  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:20:26.137881  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:20:26.137881  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:20:26.137881  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:20:26.137881  6908 net.cpp:122] Setting up relu5_1
I0530 14:20:26.137881  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:26.137881  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:20:26.137881  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:20:26.137881  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:20:26.137881  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:20:26.137881  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:20:26.140883  6908 net.cpp:122] Setting up conv5_2
I0530 14:20:26.140883  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:26.140883  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:20:26.140883  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:20:26.140883  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:20:26.140883  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:20:26.140883  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:20:26.140883  6908 net.cpp:122] Setting up relu5_2
I0530 14:20:26.140883  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:26.140883  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:20:26.140883  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:20:26.140883  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:20:26.140883  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:20:26.140883  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:20:26.144882  6908 net.cpp:122] Setting up conv5_3
I0530 14:20:26.144882  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:26.144882  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:20:26.144882  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:20:26.144882  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:20:26.144882  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:20:26.144882  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:20:26.144882  6908 net.cpp:122] Setting up relu5_3
I0530 14:20:26.144882  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:26.144882  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:20:26.144882  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:20:26.144882  6908 net.cpp:84] Creating Layer pool5
I0530 14:20:26.144882  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:20:26.144882  6908 net.cpp:380] pool5 -> pool5
I0530 14:20:26.144882  6908 net.cpp:122] Setting up pool5
I0530 14:20:26.144882  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:20:26.144882  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:20:26.144882  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:20:26.144882  6908 net.cpp:84] Creating Layer drop6
I0530 14:20:26.144882  6908 net.cpp:406] drop6 <- pool5
I0530 14:20:26.144882  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:20:26.144882  6908 net.cpp:122] Setting up drop6
I0530 14:20:26.144882  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:20:26.144882  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:20:26.144882  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:20:26.144882  6908 net.cpp:84] Creating Layer fc6
I0530 14:20:26.144882  6908 net.cpp:406] fc6 <- pool5
I0530 14:20:26.144882  6908 net.cpp:380] fc6 -> fc6
I0530 14:20:26.148875  6908 net.cpp:122] Setting up fc6
I0530 14:20:26.148875  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:20:26.148875  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:20:26.148875  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:20:26.148875  6908 net.cpp:84] Creating Layer relu6
I0530 14:20:26.148875  6908 net.cpp:406] relu6 <- fc6
I0530 14:20:26.148875  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:20:26.148875  6908 net.cpp:122] Setting up relu6
I0530 14:20:26.148875  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:20:26.148875  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:20:26.148875  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:20:26.148875  6908 net.cpp:84] Creating Layer fc7
I0530 14:20:26.148875  6908 net.cpp:406] fc7 <- fc6
I0530 14:20:26.148875  6908 net.cpp:380] fc7 -> fc7
I0530 14:20:26.148875  6908 net.cpp:122] Setting up fc7
I0530 14:20:26.148875  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:20:26.148875  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:20:26.148875  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:20:26.148875  6908 net.cpp:84] Creating Layer prob
I0530 14:20:26.148875  6908 net.cpp:406] prob <- fc7
I0530 14:20:26.148875  6908 net.cpp:380] prob -> prob
I0530 14:20:26.148875  6908 net.cpp:122] Setting up prob
I0530 14:20:26.148875  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:20:26.148875  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:20:26.148875  6908 net.cpp:200] prob does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:200] input does not need backward computation.
I0530 14:20:26.148875  6908 net.cpp:242] This network produces output prob
I0530 14:20:26.148875  6908 net.cpp:255] Network initialization done.
I0530 14:20:26.191876  6908 net.cpp:744] Ignoring source layer data
I0530 14:20:26.193882  6908 net.cpp:744] Ignoring source layer loss
I0530 14:20:45.225832  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:20:45.225832  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:20:45.225832  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:20:45.226832  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:20:45.226832  6908 layer_factory.hpp:77] Creating layer input
I0530 14:20:45.226832  6908 net.cpp:84] Creating Layer input
I0530 14:20:45.226832  6908 net.cpp:380] input -> data
I0530 14:20:45.227833  6908 net.cpp:122] Setting up input
I0530 14:20:45.227833  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:20:45.227833  6908 net.cpp:137] Memory required for data: 16384
I0530 14:20:45.227833  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:20:45.227833  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:20:45.227833  6908 net.cpp:406] conv1_1 <- data
I0530 14:20:45.227833  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:20:45.228832  6908 net.cpp:122] Setting up conv1_1
I0530 14:20:45.228832  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:20:45.228832  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:20:45.228832  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:20:45.228832  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:20:45.228832  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:20:45.228832  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:20:45.228832  6908 net.cpp:122] Setting up relu1_1
I0530 14:20:45.228832  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:20:45.228832  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:20:45.228832  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:20:45.228832  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:20:45.228832  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:20:45.228832  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:20:45.230859  6908 net.cpp:122] Setting up conv1_2
I0530 14:20:45.230859  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:20:45.230859  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:20:45.230859  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:20:45.230859  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:20:45.230859  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:20:45.230859  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:20:45.230859  6908 net.cpp:122] Setting up relu1_2
I0530 14:20:45.230859  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:20:45.230859  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:20:45.230859  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:20:45.230859  6908 net.cpp:84] Creating Layer pool1
I0530 14:20:45.230859  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:20:45.230859  6908 net.cpp:380] pool1 -> pool1
I0530 14:20:45.230859  6908 net.cpp:122] Setting up pool1
I0530 14:20:45.230859  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:20:45.230859  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:20:45.230859  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:20:45.230859  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:20:45.230859  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:20:45.230859  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:20:45.230859  6908 net.cpp:122] Setting up conv2_1
I0530 14:20:45.230859  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:20:45.230859  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:20:45.230859  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:20:45.230859  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:20:45.230859  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:20:45.230859  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:20:45.230859  6908 net.cpp:122] Setting up relu2_1
I0530 14:20:45.230859  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:20:45.230859  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:20:45.230859  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:20:45.230859  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:20:45.230859  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:20:45.230859  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:20:45.231861  6908 net.cpp:122] Setting up conv2_2
I0530 14:20:45.231861  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:20:45.231861  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:20:45.231861  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:20:45.231861  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:20:45.231861  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:20:45.231861  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:20:45.231861  6908 net.cpp:122] Setting up relu2_2
I0530 14:20:45.231861  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:20:45.231861  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:20:45.231861  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:20:45.231861  6908 net.cpp:84] Creating Layer pool2
I0530 14:20:45.231861  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:20:45.231861  6908 net.cpp:380] pool2 -> pool2
I0530 14:20:45.231861  6908 net.cpp:122] Setting up pool2
I0530 14:20:45.231861  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:45.231861  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:20:45.231861  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:20:45.231861  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:20:45.231861  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:20:45.231861  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:20:45.232863  6908 net.cpp:122] Setting up conv3_1
I0530 14:20:45.232863  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:45.232863  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:20:45.232863  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:20:45.232863  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:20:45.232863  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:20:45.232863  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:20:45.232863  6908 net.cpp:122] Setting up relu3_1
I0530 14:20:45.232863  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:45.232863  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:20:45.232863  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:20:45.232863  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:20:45.232863  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:20:45.232863  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:20:45.233861  6908 net.cpp:122] Setting up conv3_2
I0530 14:20:45.233861  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:45.233861  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:20:45.233861  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:20:45.233861  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:20:45.233861  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:20:45.233861  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:20:45.233861  6908 net.cpp:122] Setting up relu3_2
I0530 14:20:45.233861  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:45.233861  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:20:45.233861  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:20:45.233861  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:20:45.233861  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:20:45.233861  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:20:45.234833  6908 net.cpp:122] Setting up conv3_3
I0530 14:20:45.234833  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:45.234833  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:20:45.234833  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:20:45.234833  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:20:45.234833  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:20:45.234833  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:20:45.234833  6908 net.cpp:122] Setting up relu3_3
I0530 14:20:45.234833  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:20:45.234833  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:20:45.234833  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:20:45.234833  6908 net.cpp:84] Creating Layer pool3
I0530 14:20:45.234833  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:20:45.234833  6908 net.cpp:380] pool3 -> pool3
I0530 14:20:45.234833  6908 net.cpp:122] Setting up pool3
I0530 14:20:45.234833  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:20:45.234833  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:20:45.234833  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:20:45.234833  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:20:45.234833  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:20:45.234833  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:20:45.236861  6908 net.cpp:122] Setting up conv4_1
I0530 14:20:45.236861  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:45.236861  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:20:45.236861  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:20:45.236861  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:20:45.236861  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:20:45.236861  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:20:45.236861  6908 net.cpp:122] Setting up relu4_1
I0530 14:20:45.236861  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:45.236861  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:20:45.236861  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:20:45.236861  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:20:45.236861  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:20:45.236861  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:20:45.240865  6908 net.cpp:122] Setting up conv4_2
I0530 14:20:45.240865  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:45.240865  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:20:45.240865  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:20:45.240865  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:20:45.240865  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:20:45.240865  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:20:45.240865  6908 net.cpp:122] Setting up relu4_2
I0530 14:20:45.240865  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:45.240865  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:20:45.240865  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:20:45.240865  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:20:45.240865  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:20:45.240865  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:20:45.243861  6908 net.cpp:122] Setting up conv4_3
I0530 14:20:45.243861  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:45.243861  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:20:45.243861  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:20:45.243861  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:20:45.243861  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:20:45.243861  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:20:45.243861  6908 net.cpp:122] Setting up relu4_3
I0530 14:20:45.243861  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:20:45.243861  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:20:45.243861  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:20:45.243861  6908 net.cpp:84] Creating Layer pool4
I0530 14:20:45.244865  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:20:45.244865  6908 net.cpp:380] pool4 -> pool4
I0530 14:20:45.244865  6908 net.cpp:122] Setting up pool4
I0530 14:20:45.244865  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:45.244865  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:20:45.244865  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:20:45.244865  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:20:45.244865  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:20:45.244865  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:20:45.247925  6908 net.cpp:122] Setting up conv5_1
I0530 14:20:45.247925  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:45.247925  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:20:45.247925  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:20:45.247925  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:20:45.247925  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:20:45.247925  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:20:45.247925  6908 net.cpp:122] Setting up relu5_1
I0530 14:20:45.247925  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:45.247925  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:20:45.247925  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:20:45.247925  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:20:45.247925  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:20:45.247925  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:20:45.251947  6908 net.cpp:122] Setting up conv5_2
I0530 14:20:45.251947  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:45.251947  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:20:45.251947  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:20:45.251947  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:20:45.251947  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:20:45.251947  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:20:45.251947  6908 net.cpp:122] Setting up relu5_2
I0530 14:20:45.251947  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:45.251947  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:20:45.251947  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:20:45.251947  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:20:45.251947  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:20:45.251947  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:20:45.255513  6908 net.cpp:122] Setting up conv5_3
I0530 14:20:45.255513  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:45.255513  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:20:45.255513  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:20:45.255513  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:20:45.255513  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:20:45.255513  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:20:45.255513  6908 net.cpp:122] Setting up relu5_3
I0530 14:20:45.255513  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:20:45.255513  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:20:45.255513  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:20:45.255513  6908 net.cpp:84] Creating Layer pool5
I0530 14:20:45.255513  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:20:45.255513  6908 net.cpp:380] pool5 -> pool5
I0530 14:20:45.255513  6908 net.cpp:122] Setting up pool5
I0530 14:20:45.255513  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:20:45.255513  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:20:45.255513  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:20:45.255513  6908 net.cpp:84] Creating Layer drop6
I0530 14:20:45.255513  6908 net.cpp:406] drop6 <- pool5
I0530 14:20:45.255513  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:20:45.255513  6908 net.cpp:122] Setting up drop6
I0530 14:20:45.255513  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:20:45.255513  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:20:45.255513  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:20:45.255513  6908 net.cpp:84] Creating Layer fc6
I0530 14:20:45.255513  6908 net.cpp:406] fc6 <- pool5
I0530 14:20:45.256515  6908 net.cpp:380] fc6 -> fc6
I0530 14:20:45.259512  6908 net.cpp:122] Setting up fc6
I0530 14:20:45.259512  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:20:45.259512  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:20:45.259512  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:20:45.259512  6908 net.cpp:84] Creating Layer relu6
I0530 14:20:45.259512  6908 net.cpp:406] relu6 <- fc6
I0530 14:20:45.259512  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:20:45.259512  6908 net.cpp:122] Setting up relu6
I0530 14:20:45.259512  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:20:45.259512  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:20:45.259512  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:20:45.259512  6908 net.cpp:84] Creating Layer fc7
I0530 14:20:45.259512  6908 net.cpp:406] fc7 <- fc6
I0530 14:20:45.259512  6908 net.cpp:380] fc7 -> fc7
I0530 14:20:45.259512  6908 net.cpp:122] Setting up fc7
I0530 14:20:45.259512  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:20:45.259512  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:20:45.259512  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:20:45.259512  6908 net.cpp:84] Creating Layer prob
I0530 14:20:45.259512  6908 net.cpp:406] prob <- fc7
I0530 14:20:45.259512  6908 net.cpp:380] prob -> prob
I0530 14:20:45.259512  6908 net.cpp:122] Setting up prob
I0530 14:20:45.259512  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:20:45.259512  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:20:45.259512  6908 net.cpp:200] prob does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:200] input does not need backward computation.
I0530 14:20:45.259512  6908 net.cpp:242] This network produces output prob
I0530 14:20:45.259512  6908 net.cpp:255] Network initialization done.
I0530 14:20:45.278512  6908 net.cpp:744] Ignoring source layer data
I0530 14:20:45.281481  6908 net.cpp:744] Ignoring source layer loss
I0530 14:23:44.991871  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:23:44.991871  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:23:44.991871  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:23:44.997954  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:23:44.997954  6908 layer_factory.hpp:77] Creating layer input
I0530 14:23:44.997954  6908 net.cpp:84] Creating Layer input
I0530 14:23:44.997954  6908 net.cpp:380] input -> data
I0530 14:23:44.998847  6908 net.cpp:122] Setting up input
I0530 14:23:44.998847  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:23:44.998847  6908 net.cpp:137] Memory required for data: 16384
I0530 14:23:44.998847  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:23:44.998847  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:23:44.998847  6908 net.cpp:406] conv1_1 <- data
I0530 14:23:44.998847  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:23:45.000869  6908 net.cpp:122] Setting up conv1_1
I0530 14:23:45.000869  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:23:45.000869  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:23:45.000869  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:23:45.000869  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:23:45.000869  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:23:45.000869  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:23:45.000869  6908 net.cpp:122] Setting up relu1_1
I0530 14:23:45.000869  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:23:45.000869  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:23:45.000869  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:23:45.000869  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:23:45.000869  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:23:45.000869  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:23:45.001868  6908 net.cpp:122] Setting up conv1_2
I0530 14:23:45.001868  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:23:45.001868  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:23:45.001868  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:23:45.001868  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:23:45.001868  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:23:45.001868  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:23:45.001868  6908 net.cpp:122] Setting up relu1_2
I0530 14:23:45.001868  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:23:45.001868  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:23:45.001868  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:23:45.001868  6908 net.cpp:84] Creating Layer pool1
I0530 14:23:45.001868  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:23:45.001868  6908 net.cpp:380] pool1 -> pool1
I0530 14:23:45.001868  6908 net.cpp:122] Setting up pool1
I0530 14:23:45.001868  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:23:45.001868  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:23:45.001868  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:23:45.001868  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:23:45.002846  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:23:45.002846  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:23:45.002846  6908 net.cpp:122] Setting up conv2_1
I0530 14:23:45.002846  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:23:45.002846  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:23:45.002846  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:23:45.002846  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:23:45.002846  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:23:45.002846  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:23:45.002846  6908 net.cpp:122] Setting up relu2_1
I0530 14:23:45.002846  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:23:45.002846  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:23:45.002846  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:23:45.002846  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:23:45.002846  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:23:45.002846  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:23:45.003846  6908 net.cpp:122] Setting up conv2_2
I0530 14:23:45.003846  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:23:45.003846  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:23:45.003846  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:23:45.003846  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:23:45.003846  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:23:45.003846  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:23:45.003846  6908 net.cpp:122] Setting up relu2_2
I0530 14:23:45.003846  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:23:45.003846  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:23:45.003846  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:23:45.003846  6908 net.cpp:84] Creating Layer pool2
I0530 14:23:45.003846  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:23:45.003846  6908 net.cpp:380] pool2 -> pool2
I0530 14:23:45.003846  6908 net.cpp:122] Setting up pool2
I0530 14:23:45.003846  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:23:45.003846  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:23:45.003846  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:23:45.003846  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:23:45.003846  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:23:45.003846  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:23:45.004847  6908 net.cpp:122] Setting up conv3_1
I0530 14:23:45.004847  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:23:45.004847  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:23:45.004847  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:23:45.004847  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:23:45.004847  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:23:45.004847  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:23:45.004847  6908 net.cpp:122] Setting up relu3_1
I0530 14:23:45.004847  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:23:45.004847  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:23:45.004847  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:23:45.004847  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:23:45.004847  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:23:45.004847  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:23:45.005846  6908 net.cpp:122] Setting up conv3_2
I0530 14:23:45.005846  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:23:45.005846  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:23:45.005846  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:23:45.005846  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:23:45.005846  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:23:45.005846  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:23:45.005846  6908 net.cpp:122] Setting up relu3_2
I0530 14:23:45.005846  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:23:45.005846  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:23:45.005846  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:23:45.005846  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:23:45.005846  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:23:45.005846  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:23:45.006846  6908 net.cpp:122] Setting up conv3_3
I0530 14:23:45.006846  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:23:45.006846  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:23:45.006846  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:23:45.006846  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:23:45.006846  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:23:45.006846  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:23:45.006846  6908 net.cpp:122] Setting up relu3_3
I0530 14:23:45.006846  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:23:45.006846  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:23:45.006846  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:23:45.006846  6908 net.cpp:84] Creating Layer pool3
I0530 14:23:45.006846  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:23:45.006846  6908 net.cpp:380] pool3 -> pool3
I0530 14:23:45.006846  6908 net.cpp:122] Setting up pool3
I0530 14:23:45.006846  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:23:45.006846  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:23:45.006846  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:23:45.006846  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:23:45.006846  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:23:45.006846  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:23:45.008846  6908 net.cpp:122] Setting up conv4_1
I0530 14:23:45.008846  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:23:45.008846  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:23:45.008846  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:23:45.008846  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:23:45.008846  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:23:45.008846  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:23:45.008846  6908 net.cpp:122] Setting up relu4_1
I0530 14:23:45.008846  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:23:45.008846  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:23:45.008846  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:23:45.008846  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:23:45.008846  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:23:45.008846  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:23:45.012786  6908 net.cpp:122] Setting up conv4_2
I0530 14:23:45.012786  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:23:45.012786  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:23:45.012786  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:23:45.012786  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:23:45.012786  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:23:45.012786  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:23:45.012786  6908 net.cpp:122] Setting up relu4_2
I0530 14:23:45.012786  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:23:45.012786  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:23:45.012786  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:23:45.012786  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:23:45.012786  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:23:45.012786  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:23:45.015842  6908 net.cpp:122] Setting up conv4_3
I0530 14:23:45.015842  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:23:45.015842  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:23:45.015842  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:23:45.015842  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:23:45.015842  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:23:45.015842  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:23:45.015842  6908 net.cpp:122] Setting up relu4_3
I0530 14:23:45.015842  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:23:45.015842  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:23:45.015842  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:23:45.015842  6908 net.cpp:84] Creating Layer pool4
I0530 14:23:45.015842  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:23:45.015842  6908 net.cpp:380] pool4 -> pool4
I0530 14:23:45.015842  6908 net.cpp:122] Setting up pool4
I0530 14:23:45.015842  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:23:45.015842  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:23:45.015842  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:23:45.015842  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:23:45.015842  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:23:45.015842  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:23:45.019842  6908 net.cpp:122] Setting up conv5_1
I0530 14:23:45.019842  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:23:45.019842  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:23:45.019842  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:23:45.019842  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:23:45.019842  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:23:45.019842  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:23:45.019842  6908 net.cpp:122] Setting up relu5_1
I0530 14:23:45.019842  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:23:45.019842  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:23:45.019842  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:23:45.019842  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:23:45.019842  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:23:45.019842  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:23:45.023843  6908 net.cpp:122] Setting up conv5_2
I0530 14:23:45.023843  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:23:45.023843  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:23:45.023843  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:23:45.023843  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:23:45.023843  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:23:45.023843  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:23:45.023843  6908 net.cpp:122] Setting up relu5_2
I0530 14:23:45.023843  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:23:45.023843  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:23:45.023843  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:23:45.023843  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:23:45.023843  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:23:45.023843  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:23:45.027842  6908 net.cpp:122] Setting up conv5_3
I0530 14:23:45.027842  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:23:45.027842  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:23:45.027842  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:23:45.027842  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:23:45.027842  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:23:45.027842  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:23:45.027842  6908 net.cpp:122] Setting up relu5_3
I0530 14:23:45.027842  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:23:45.027842  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:23:45.027842  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:23:45.027842  6908 net.cpp:84] Creating Layer pool5
I0530 14:23:45.027842  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:23:45.027842  6908 net.cpp:380] pool5 -> pool5
I0530 14:23:45.027842  6908 net.cpp:122] Setting up pool5
I0530 14:23:45.027842  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:23:45.027842  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:23:45.027842  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:23:45.027842  6908 net.cpp:84] Creating Layer drop6
I0530 14:23:45.027842  6908 net.cpp:406] drop6 <- pool5
I0530 14:23:45.027842  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:23:45.027842  6908 net.cpp:122] Setting up drop6
I0530 14:23:45.027842  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:23:45.027842  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:23:45.027842  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:23:45.027842  6908 net.cpp:84] Creating Layer fc6
I0530 14:23:45.027842  6908 net.cpp:406] fc6 <- pool5
I0530 14:23:45.027842  6908 net.cpp:380] fc6 -> fc6
I0530 14:23:45.030843  6908 net.cpp:122] Setting up fc6
I0530 14:23:45.030843  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:23:45.030843  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:23:45.030843  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:23:45.030843  6908 net.cpp:84] Creating Layer relu6
I0530 14:23:45.030843  6908 net.cpp:406] relu6 <- fc6
I0530 14:23:45.030843  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:23:45.030843  6908 net.cpp:122] Setting up relu6
I0530 14:23:45.030843  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:23:45.030843  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:23:45.030843  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:23:45.030843  6908 net.cpp:84] Creating Layer fc7
I0530 14:23:45.030843  6908 net.cpp:406] fc7 <- fc6
I0530 14:23:45.030843  6908 net.cpp:380] fc7 -> fc7
I0530 14:23:45.030843  6908 net.cpp:122] Setting up fc7
I0530 14:23:45.030843  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:23:45.030843  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:23:45.030843  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:23:45.030843  6908 net.cpp:84] Creating Layer prob
I0530 14:23:45.030843  6908 net.cpp:406] prob <- fc7
I0530 14:23:45.030843  6908 net.cpp:380] prob -> prob
I0530 14:23:45.030843  6908 net.cpp:122] Setting up prob
I0530 14:23:45.030843  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:23:45.030843  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:23:45.030843  6908 net.cpp:200] prob does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:200] input does not need backward computation.
I0530 14:23:45.030843  6908 net.cpp:242] This network produces output prob
I0530 14:23:45.030843  6908 net.cpp:255] Network initialization done.
I0530 14:23:45.049842  6908 net.cpp:744] Ignoring source layer data
I0530 14:23:45.052844  6908 net.cpp:744] Ignoring source layer loss
I0530 14:24:24.040516  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:24:24.040516  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:24:24.040516  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:24:24.040516  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:24:24.041517  6908 layer_factory.hpp:77] Creating layer input
I0530 14:24:24.041517  6908 net.cpp:84] Creating Layer input
I0530 14:24:24.041517  6908 net.cpp:380] input -> data
I0530 14:24:24.041517  6908 net.cpp:122] Setting up input
I0530 14:24:24.041517  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:24:24.041517  6908 net.cpp:137] Memory required for data: 16384
I0530 14:24:24.041517  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:24:24.041517  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:24:24.041517  6908 net.cpp:406] conv1_1 <- data
I0530 14:24:24.041517  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:24:24.043520  6908 net.cpp:122] Setting up conv1_1
I0530 14:24:24.043520  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:24:24.043520  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:24:24.043520  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:24:24.043520  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:24:24.043520  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:24:24.043520  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:24:24.043520  6908 net.cpp:122] Setting up relu1_1
I0530 14:24:24.043520  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:24:24.043520  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:24:24.043520  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:24:24.043520  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:24:24.043520  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:24:24.043520  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:24:24.044520  6908 net.cpp:122] Setting up conv1_2
I0530 14:24:24.044520  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:24:24.044520  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:24:24.044520  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:24:24.044520  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:24:24.044520  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:24:24.044520  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:24:24.044520  6908 net.cpp:122] Setting up relu1_2
I0530 14:24:24.044520  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:24:24.044520  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:24:24.044520  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:24:24.044520  6908 net.cpp:84] Creating Layer pool1
I0530 14:24:24.044520  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:24:24.044520  6908 net.cpp:380] pool1 -> pool1
I0530 14:24:24.044520  6908 net.cpp:122] Setting up pool1
I0530 14:24:24.044520  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:24:24.044520  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:24:24.044520  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:24:24.044520  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:24:24.045521  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:24:24.045521  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:24:24.045521  6908 net.cpp:122] Setting up conv2_1
I0530 14:24:24.045521  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:24:24.045521  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:24:24.045521  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:24:24.045521  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:24:24.045521  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:24:24.045521  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:24:24.045521  6908 net.cpp:122] Setting up relu2_1
I0530 14:24:24.045521  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:24:24.045521  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:24:24.045521  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:24:24.045521  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:24:24.045521  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:24:24.045521  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:24:24.046517  6908 net.cpp:122] Setting up conv2_2
I0530 14:24:24.046517  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:24:24.046517  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:24:24.046517  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:24:24.046517  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:24:24.046517  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:24:24.046517  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:24:24.046517  6908 net.cpp:122] Setting up relu2_2
I0530 14:24:24.046517  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:24:24.046517  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:24:24.046517  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:24:24.046517  6908 net.cpp:84] Creating Layer pool2
I0530 14:24:24.046517  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:24:24.046517  6908 net.cpp:380] pool2 -> pool2
I0530 14:24:24.046517  6908 net.cpp:122] Setting up pool2
I0530 14:24:24.046517  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:24.046517  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:24:24.046517  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:24:24.046517  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:24:24.046517  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:24:24.046517  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:24:24.046517  6908 net.cpp:122] Setting up conv3_1
I0530 14:24:24.046517  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:24.046517  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:24:24.046517  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:24:24.046517  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:24:24.046517  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:24:24.046517  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:24:24.046517  6908 net.cpp:122] Setting up relu3_1
I0530 14:24:24.047520  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:24.047520  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:24:24.047520  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:24:24.047520  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:24:24.047520  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:24:24.047520  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:24:24.047520  6908 net.cpp:122] Setting up conv3_2
I0530 14:24:24.047520  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:24.047520  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:24:24.047520  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:24:24.047520  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:24:24.047520  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:24:24.047520  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:24:24.047520  6908 net.cpp:122] Setting up relu3_2
I0530 14:24:24.047520  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:24.047520  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:24:24.047520  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:24:24.047520  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:24:24.047520  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:24:24.047520  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:24:24.049520  6908 net.cpp:122] Setting up conv3_3
I0530 14:24:24.049520  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:24.049520  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:24:24.049520  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:24:24.049520  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:24:24.049520  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:24:24.049520  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:24:24.049520  6908 net.cpp:122] Setting up relu3_3
I0530 14:24:24.049520  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:24.049520  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:24:24.049520  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:24:24.049520  6908 net.cpp:84] Creating Layer pool3
I0530 14:24:24.049520  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:24:24.049520  6908 net.cpp:380] pool3 -> pool3
I0530 14:24:24.049520  6908 net.cpp:122] Setting up pool3
I0530 14:24:24.049520  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:24:24.049520  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:24:24.049520  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:24:24.049520  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:24:24.049520  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:24:24.049520  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:24:24.051524  6908 net.cpp:122] Setting up conv4_1
I0530 14:24:24.051524  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:24.051524  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:24:24.051524  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:24:24.051524  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:24:24.051524  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:24:24.051524  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:24:24.051524  6908 net.cpp:122] Setting up relu4_1
I0530 14:24:24.051524  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:24.051524  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:24:24.051524  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:24:24.051524  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:24:24.051524  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:24:24.051524  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:24:24.054524  6908 net.cpp:122] Setting up conv4_2
I0530 14:24:24.054524  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:24.054524  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:24:24.054524  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:24:24.054524  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:24:24.054524  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:24:24.054524  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:24:24.054524  6908 net.cpp:122] Setting up relu4_2
I0530 14:24:24.054524  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:24.054524  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:24:24.054524  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:24:24.054524  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:24:24.054524  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:24:24.054524  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:24:24.058524  6908 net.cpp:122] Setting up conv4_3
I0530 14:24:24.058524  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:24.058524  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:24:24.058524  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:24:24.058524  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:24:24.058524  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:24:24.058524  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:24:24.058524  6908 net.cpp:122] Setting up relu4_3
I0530 14:24:24.058524  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:24.058524  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:24:24.058524  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:24:24.058524  6908 net.cpp:84] Creating Layer pool4
I0530 14:24:24.058524  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:24:24.058524  6908 net.cpp:380] pool4 -> pool4
I0530 14:24:24.058524  6908 net.cpp:122] Setting up pool4
I0530 14:24:24.058524  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:24.058524  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:24:24.058524  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:24:24.058524  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:24:24.058524  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:24:24.058524  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:24:24.062526  6908 net.cpp:122] Setting up conv5_1
I0530 14:24:24.062526  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:24.062526  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:24:24.062526  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:24:24.062526  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:24:24.062526  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:24:24.062526  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:24:24.062526  6908 net.cpp:122] Setting up relu5_1
I0530 14:24:24.062526  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:24.062526  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:24:24.062526  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:24:24.062526  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:24:24.062526  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:24:24.062526  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:24:24.066524  6908 net.cpp:122] Setting up conv5_2
I0530 14:24:24.066524  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:24.066524  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:24:24.066524  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:24:24.066524  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:24:24.066524  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:24:24.066524  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:24:24.066524  6908 net.cpp:122] Setting up relu5_2
I0530 14:24:24.066524  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:24.066524  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:24:24.066524  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:24:24.066524  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:24:24.066524  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:24:24.066524  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:24:24.070524  6908 net.cpp:122] Setting up conv5_3
I0530 14:24:24.070524  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:24.070524  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:24:24.070524  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:24:24.070524  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:24:24.070524  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:24:24.070524  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:24:24.070524  6908 net.cpp:122] Setting up relu5_3
I0530 14:24:24.070524  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:24.070524  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:24:24.070524  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:24:24.070524  6908 net.cpp:84] Creating Layer pool5
I0530 14:24:24.070524  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:24:24.070524  6908 net.cpp:380] pool5 -> pool5
I0530 14:24:24.070524  6908 net.cpp:122] Setting up pool5
I0530 14:24:24.070524  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:24:24.070524  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:24:24.070524  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:24:24.070524  6908 net.cpp:84] Creating Layer drop6
I0530 14:24:24.070524  6908 net.cpp:406] drop6 <- pool5
I0530 14:24:24.070524  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:24:24.070524  6908 net.cpp:122] Setting up drop6
I0530 14:24:24.070524  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:24:24.070524  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:24:24.070524  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:24:24.070524  6908 net.cpp:84] Creating Layer fc6
I0530 14:24:24.070524  6908 net.cpp:406] fc6 <- pool5
I0530 14:24:24.070524  6908 net.cpp:380] fc6 -> fc6
I0530 14:24:24.073524  6908 net.cpp:122] Setting up fc6
I0530 14:24:24.073524  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:24:24.073524  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:24:24.073524  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:24:24.073524  6908 net.cpp:84] Creating Layer relu6
I0530 14:24:24.073524  6908 net.cpp:406] relu6 <- fc6
I0530 14:24:24.073524  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:24:24.073524  6908 net.cpp:122] Setting up relu6
I0530 14:24:24.073524  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:24:24.073524  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:24:24.073524  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:24:24.073524  6908 net.cpp:84] Creating Layer fc7
I0530 14:24:24.073524  6908 net.cpp:406] fc7 <- fc6
I0530 14:24:24.073524  6908 net.cpp:380] fc7 -> fc7
I0530 14:24:24.073524  6908 net.cpp:122] Setting up fc7
I0530 14:24:24.073524  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:24:24.073524  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:24:24.073524  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:24:24.073524  6908 net.cpp:84] Creating Layer prob
I0530 14:24:24.073524  6908 net.cpp:406] prob <- fc7
I0530 14:24:24.073524  6908 net.cpp:380] prob -> prob
I0530 14:24:24.073524  6908 net.cpp:122] Setting up prob
I0530 14:24:24.073524  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:24:24.073524  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:24:24.073524  6908 net.cpp:200] prob does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:200] input does not need backward computation.
I0530 14:24:24.073524  6908 net.cpp:242] This network produces output prob
I0530 14:24:24.073524  6908 net.cpp:255] Network initialization done.
I0530 14:24:24.092525  6908 net.cpp:744] Ignoring source layer data
I0530 14:24:24.095525  6908 net.cpp:744] Ignoring source layer loss
I0530 14:24:38.814805  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:24:38.814805  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:24:38.814805  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:24:38.814805  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:24:38.814805  6908 layer_factory.hpp:77] Creating layer input
I0530 14:24:38.814805  6908 net.cpp:84] Creating Layer input
I0530 14:24:38.814805  6908 net.cpp:380] input -> data
I0530 14:24:38.815806  6908 net.cpp:122] Setting up input
I0530 14:24:38.815806  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:24:38.815806  6908 net.cpp:137] Memory required for data: 16384
I0530 14:24:38.815806  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:24:38.815806  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:24:38.815806  6908 net.cpp:406] conv1_1 <- data
I0530 14:24:38.815806  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:24:38.816807  6908 net.cpp:122] Setting up conv1_1
I0530 14:24:38.816807  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:24:38.816807  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:24:38.816807  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:24:38.816807  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:24:38.816807  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:24:38.816807  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:24:38.816807  6908 net.cpp:122] Setting up relu1_1
I0530 14:24:38.816807  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:24:38.816807  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:24:38.816807  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:24:38.816807  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:24:38.816807  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:24:38.816807  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:24:38.817831  6908 net.cpp:122] Setting up conv1_2
I0530 14:24:38.817831  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:24:38.817831  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:24:38.817831  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:24:38.817831  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:24:38.817831  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:24:38.817831  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:24:38.817831  6908 net.cpp:122] Setting up relu1_2
I0530 14:24:38.817831  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:24:38.817831  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:24:38.817831  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:24:38.817831  6908 net.cpp:84] Creating Layer pool1
I0530 14:24:38.817831  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:24:38.817831  6908 net.cpp:380] pool1 -> pool1
I0530 14:24:38.817831  6908 net.cpp:122] Setting up pool1
I0530 14:24:38.817831  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:24:38.817831  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:24:38.817831  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:24:38.817831  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:24:38.817831  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:24:38.817831  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:24:38.818830  6908 net.cpp:122] Setting up conv2_1
I0530 14:24:38.818830  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:24:38.818830  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:24:38.818830  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:24:38.818830  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:24:38.818830  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:24:38.818830  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:24:38.818830  6908 net.cpp:122] Setting up relu2_1
I0530 14:24:38.818830  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:24:38.818830  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:24:38.818830  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:24:38.818830  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:24:38.818830  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:24:38.818830  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:24:38.818830  6908 net.cpp:122] Setting up conv2_2
I0530 14:24:38.818830  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:24:38.818830  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:24:38.818830  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:24:38.818830  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:24:38.818830  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:24:38.818830  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:24:38.818830  6908 net.cpp:122] Setting up relu2_2
I0530 14:24:38.818830  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:24:38.818830  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:24:38.818830  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:24:38.818830  6908 net.cpp:84] Creating Layer pool2
I0530 14:24:38.818830  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:24:38.818830  6908 net.cpp:380] pool2 -> pool2
I0530 14:24:38.818830  6908 net.cpp:122] Setting up pool2
I0530 14:24:38.818830  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:38.818830  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:24:38.818830  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:24:38.818830  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:24:38.818830  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:24:38.818830  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:24:38.819834  6908 net.cpp:122] Setting up conv3_1
I0530 14:24:38.819834  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:38.819834  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:24:38.819834  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:24:38.819834  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:24:38.819834  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:24:38.819834  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:24:38.819834  6908 net.cpp:122] Setting up relu3_1
I0530 14:24:38.819834  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:38.819834  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:24:38.819834  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:24:38.819834  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:24:38.819834  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:24:38.819834  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:24:38.820829  6908 net.cpp:122] Setting up conv3_2
I0530 14:24:38.820829  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:38.820829  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:24:38.820829  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:24:38.820829  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:24:38.820829  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:24:38.820829  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:24:38.820829  6908 net.cpp:122] Setting up relu3_2
I0530 14:24:38.820829  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:38.820829  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:24:38.820829  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:24:38.820829  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:24:38.820829  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:24:38.820829  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:24:38.822806  6908 net.cpp:122] Setting up conv3_3
I0530 14:24:38.822806  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:38.822806  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:24:38.822806  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:24:38.822806  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:24:38.822806  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:24:38.822806  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:24:38.822806  6908 net.cpp:122] Setting up relu3_3
I0530 14:24:38.822806  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:24:38.822806  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:24:38.822806  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:24:38.822806  6908 net.cpp:84] Creating Layer pool3
I0530 14:24:38.822806  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:24:38.822806  6908 net.cpp:380] pool3 -> pool3
I0530 14:24:38.822806  6908 net.cpp:122] Setting up pool3
I0530 14:24:38.822806  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:24:38.822806  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:24:38.822806  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:24:38.822806  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:24:38.822806  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:24:38.822806  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:24:38.823830  6908 net.cpp:122] Setting up conv4_1
I0530 14:24:38.823830  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:38.823830  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:24:38.823830  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:24:38.823830  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:24:38.823830  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:24:38.823830  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:24:38.823830  6908 net.cpp:122] Setting up relu4_1
I0530 14:24:38.823830  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:38.823830  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:24:38.823830  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:24:38.823830  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:24:38.823830  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:24:38.823830  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:24:38.827829  6908 net.cpp:122] Setting up conv4_2
I0530 14:24:38.827829  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:38.827829  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:24:38.827829  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:24:38.827829  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:24:38.827829  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:24:38.827829  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:24:38.827829  6908 net.cpp:122] Setting up relu4_2
I0530 14:24:38.827829  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:38.827829  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:24:38.827829  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:24:38.827829  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:24:38.827829  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:24:38.827829  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:24:38.831384  6908 net.cpp:122] Setting up conv4_3
I0530 14:24:38.831384  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:38.831384  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:24:38.831384  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:24:38.831384  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:24:38.831384  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:24:38.831384  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:24:38.831384  6908 net.cpp:122] Setting up relu4_3
I0530 14:24:38.831384  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:24:38.831384  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:24:38.831384  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:24:38.831384  6908 net.cpp:84] Creating Layer pool4
I0530 14:24:38.831384  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:24:38.831384  6908 net.cpp:380] pool4 -> pool4
I0530 14:24:38.831384  6908 net.cpp:122] Setting up pool4
I0530 14:24:38.831384  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:38.831384  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:24:38.831384  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:24:38.831384  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:24:38.831384  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:24:38.831384  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:24:38.835384  6908 net.cpp:122] Setting up conv5_1
I0530 14:24:38.835384  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:38.835384  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:24:38.835384  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:24:38.835384  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:24:38.835384  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:24:38.835384  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:24:38.835384  6908 net.cpp:122] Setting up relu5_1
I0530 14:24:38.835384  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:38.835384  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:24:38.835384  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:24:38.835384  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:24:38.835384  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:24:38.835384  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:24:38.838773  6908 net.cpp:122] Setting up conv5_2
I0530 14:24:38.838773  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:38.838773  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:24:38.838773  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:24:38.838773  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:24:38.838773  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:24:38.838773  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:24:38.838773  6908 net.cpp:122] Setting up relu5_2
I0530 14:24:38.838773  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:38.838773  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:24:38.838773  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:24:38.838773  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:24:38.838773  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:24:38.838773  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:24:38.842773  6908 net.cpp:122] Setting up conv5_3
I0530 14:24:38.842773  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:38.842773  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:24:38.842773  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:24:38.842773  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:24:38.842773  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:24:38.842773  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:24:38.842773  6908 net.cpp:122] Setting up relu5_3
I0530 14:24:38.842773  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:24:38.842773  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:24:38.842773  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:24:38.842773  6908 net.cpp:84] Creating Layer pool5
I0530 14:24:38.842773  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:24:38.842773  6908 net.cpp:380] pool5 -> pool5
I0530 14:24:38.842773  6908 net.cpp:122] Setting up pool5
I0530 14:24:38.842773  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:24:38.842773  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:24:38.842773  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:24:38.842773  6908 net.cpp:84] Creating Layer drop6
I0530 14:24:38.842773  6908 net.cpp:406] drop6 <- pool5
I0530 14:24:38.842773  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:24:38.842773  6908 net.cpp:122] Setting up drop6
I0530 14:24:38.842773  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:24:38.842773  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:24:38.842773  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:24:38.842773  6908 net.cpp:84] Creating Layer fc6
I0530 14:24:38.842773  6908 net.cpp:406] fc6 <- pool5
I0530 14:24:38.842773  6908 net.cpp:380] fc6 -> fc6
I0530 14:24:38.845773  6908 net.cpp:122] Setting up fc6
I0530 14:24:38.845773  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:24:38.845773  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:24:38.845773  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:24:38.845773  6908 net.cpp:84] Creating Layer relu6
I0530 14:24:38.845773  6908 net.cpp:406] relu6 <- fc6
I0530 14:24:38.845773  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:24:38.845773  6908 net.cpp:122] Setting up relu6
I0530 14:24:38.845773  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:24:38.845773  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:24:38.845773  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:24:38.845773  6908 net.cpp:84] Creating Layer fc7
I0530 14:24:38.845773  6908 net.cpp:406] fc7 <- fc6
I0530 14:24:38.845773  6908 net.cpp:380] fc7 -> fc7
I0530 14:24:38.845773  6908 net.cpp:122] Setting up fc7
I0530 14:24:38.845773  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:24:38.845773  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:24:38.845773  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:24:38.845773  6908 net.cpp:84] Creating Layer prob
I0530 14:24:38.845773  6908 net.cpp:406] prob <- fc7
I0530 14:24:38.845773  6908 net.cpp:380] prob -> prob
I0530 14:24:38.846773  6908 net.cpp:122] Setting up prob
I0530 14:24:38.846773  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:24:38.846773  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:24:38.846773  6908 net.cpp:200] prob does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:200] input does not need backward computation.
I0530 14:24:38.846773  6908 net.cpp:242] This network produces output prob
I0530 14:24:38.846773  6908 net.cpp:255] Network initialization done.
I0530 14:24:38.865773  6908 net.cpp:744] Ignoring source layer data
I0530 14:24:38.867774  6908 net.cpp:744] Ignoring source layer loss
I0530 14:25:46.704927  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:25:46.704927  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:25:46.704927  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:25:46.704927  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:25:46.704927  6908 layer_factory.hpp:77] Creating layer input
I0530 14:25:46.704927  6908 net.cpp:84] Creating Layer input
I0530 14:25:46.704927  6908 net.cpp:380] input -> data
I0530 14:25:46.705927  6908 net.cpp:122] Setting up input
I0530 14:25:46.705927  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:25:46.705927  6908 net.cpp:137] Memory required for data: 16384
I0530 14:25:46.705927  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:25:46.705927  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:25:46.705927  6908 net.cpp:406] conv1_1 <- data
I0530 14:25:46.705927  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:25:46.707927  6908 net.cpp:122] Setting up conv1_1
I0530 14:25:46.707927  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:25:46.707927  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:25:46.707927  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:25:46.707927  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:25:46.707927  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:25:46.707927  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:25:46.707927  6908 net.cpp:122] Setting up relu1_1
I0530 14:25:46.707927  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:25:46.707927  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:25:46.707927  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:25:46.707927  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:25:46.707927  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:25:46.707927  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:25:46.708927  6908 net.cpp:122] Setting up conv1_2
I0530 14:25:46.708927  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:25:46.708927  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:25:46.708927  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:25:46.708927  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:25:46.708927  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:25:46.708927  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:25:46.708927  6908 net.cpp:122] Setting up relu1_2
I0530 14:25:46.708927  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:25:46.708927  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:25:46.708927  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:25:46.708927  6908 net.cpp:84] Creating Layer pool1
I0530 14:25:46.708927  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:25:46.708927  6908 net.cpp:380] pool1 -> pool1
I0530 14:25:46.708927  6908 net.cpp:122] Setting up pool1
I0530 14:25:46.708927  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:25:46.708927  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:25:46.708927  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:25:46.708927  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:25:46.708927  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:25:46.708927  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:25:46.709956  6908 net.cpp:122] Setting up conv2_1
I0530 14:25:46.709956  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:25:46.709956  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:25:46.709956  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:25:46.709956  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:25:46.709956  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:25:46.709956  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:25:46.709956  6908 net.cpp:122] Setting up relu2_1
I0530 14:25:46.709956  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:25:46.709956  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:25:46.709956  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:25:46.709956  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:25:46.709956  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:25:46.709956  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:25:46.709956  6908 net.cpp:122] Setting up conv2_2
I0530 14:25:46.709956  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:25:46.709956  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:25:46.709956  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:25:46.709956  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:25:46.709956  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:25:46.709956  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:25:46.709956  6908 net.cpp:122] Setting up relu2_2
I0530 14:25:46.709956  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:25:46.709956  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:25:46.709956  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:25:46.709956  6908 net.cpp:84] Creating Layer pool2
I0530 14:25:46.709956  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:25:46.709956  6908 net.cpp:380] pool2 -> pool2
I0530 14:25:46.709956  6908 net.cpp:122] Setting up pool2
I0530 14:25:46.709956  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:25:46.709956  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:25:46.709956  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:25:46.709956  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:25:46.709956  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:25:46.709956  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:25:46.710957  6908 net.cpp:122] Setting up conv3_1
I0530 14:25:46.710957  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:25:46.710957  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:25:46.710957  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:25:46.710957  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:25:46.710957  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:25:46.710957  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:25:46.710957  6908 net.cpp:122] Setting up relu3_1
I0530 14:25:46.710957  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:25:46.710957  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:25:46.710957  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:25:46.710957  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:25:46.710957  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:25:46.710957  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:25:46.711959  6908 net.cpp:122] Setting up conv3_2
I0530 14:25:46.711959  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:25:46.711959  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:25:46.711959  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:25:46.711959  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:25:46.711959  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:25:46.711959  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:25:46.711959  6908 net.cpp:122] Setting up relu3_2
I0530 14:25:46.711959  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:25:46.711959  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:25:46.711959  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:25:46.711959  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:25:46.711959  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:25:46.711959  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:25:46.713956  6908 net.cpp:122] Setting up conv3_3
I0530 14:25:46.713956  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:25:46.713956  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:25:46.713956  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:25:46.713956  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:25:46.713956  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:25:46.713956  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:25:46.713956  6908 net.cpp:122] Setting up relu3_3
I0530 14:25:46.713956  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:25:46.713956  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:25:46.713956  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:25:46.713956  6908 net.cpp:84] Creating Layer pool3
I0530 14:25:46.713956  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:25:46.713956  6908 net.cpp:380] pool3 -> pool3
I0530 14:25:46.713956  6908 net.cpp:122] Setting up pool3
I0530 14:25:46.713956  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:25:46.713956  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:25:46.713956  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:25:46.713956  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:25:46.713956  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:25:46.713956  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:25:46.714960  6908 net.cpp:122] Setting up conv4_1
I0530 14:25:46.714960  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:25:46.714960  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:25:46.714960  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:25:46.714960  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:25:46.714960  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:25:46.714960  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:25:46.714960  6908 net.cpp:122] Setting up relu4_1
I0530 14:25:46.714960  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:25:46.714960  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:25:46.714960  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:25:46.714960  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:25:46.714960  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:25:46.714960  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:25:46.718950  6908 net.cpp:122] Setting up conv4_2
I0530 14:25:46.718950  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:25:46.718950  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:25:46.718950  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:25:46.718950  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:25:46.718950  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:25:46.718950  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:25:46.718950  6908 net.cpp:122] Setting up relu4_2
I0530 14:25:46.718950  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:25:46.718950  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:25:46.718950  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:25:46.718950  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:25:46.718950  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:25:46.718950  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:25:46.722949  6908 net.cpp:122] Setting up conv4_3
I0530 14:25:46.722949  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:25:46.722949  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:25:46.722949  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:25:46.722949  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:25:46.722949  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:25:46.722949  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:25:46.722949  6908 net.cpp:122] Setting up relu4_3
I0530 14:25:46.722949  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:25:46.722949  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:25:46.722949  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:25:46.722949  6908 net.cpp:84] Creating Layer pool4
I0530 14:25:46.722949  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:25:46.722949  6908 net.cpp:380] pool4 -> pool4
I0530 14:25:46.722949  6908 net.cpp:122] Setting up pool4
I0530 14:25:46.722949  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:25:46.722949  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:25:46.722949  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:25:46.722949  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:25:46.722949  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:25:46.722949  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:25:46.726949  6908 net.cpp:122] Setting up conv5_1
I0530 14:25:46.726949  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:25:46.726949  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:25:46.726949  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:25:46.726949  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:25:46.726949  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:25:46.726949  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:25:46.726949  6908 net.cpp:122] Setting up relu5_1
I0530 14:25:46.726949  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:25:46.726949  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:25:46.726949  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:25:46.726949  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:25:46.726949  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:25:46.726949  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:25:46.730949  6908 net.cpp:122] Setting up conv5_2
I0530 14:25:46.730949  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:25:46.730949  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:25:46.730949  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:25:46.730949  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:25:46.730949  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:25:46.730949  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:25:46.730949  6908 net.cpp:122] Setting up relu5_2
I0530 14:25:46.730949  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:25:46.730949  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:25:46.730949  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:25:46.730949  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:25:46.730949  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:25:46.730949  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:25:46.733949  6908 net.cpp:122] Setting up conv5_3
I0530 14:25:46.733949  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:25:46.733949  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:25:46.733949  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:25:46.733949  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:25:46.733949  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:25:46.733949  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:25:46.733949  6908 net.cpp:122] Setting up relu5_3
I0530 14:25:46.733949  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:25:46.733949  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:25:46.733949  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:25:46.733949  6908 net.cpp:84] Creating Layer pool5
I0530 14:25:46.733949  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:25:46.733949  6908 net.cpp:380] pool5 -> pool5
I0530 14:25:46.733949  6908 net.cpp:122] Setting up pool5
I0530 14:25:46.733949  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:25:46.733949  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:25:46.733949  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:25:46.733949  6908 net.cpp:84] Creating Layer drop6
I0530 14:25:46.733949  6908 net.cpp:406] drop6 <- pool5
I0530 14:25:46.733949  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:25:46.733949  6908 net.cpp:122] Setting up drop6
I0530 14:25:46.733949  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:25:46.733949  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:25:46.733949  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:25:46.733949  6908 net.cpp:84] Creating Layer fc6
I0530 14:25:46.733949  6908 net.cpp:406] fc6 <- pool5
I0530 14:25:46.733949  6908 net.cpp:380] fc6 -> fc6
I0530 14:25:46.737949  6908 net.cpp:122] Setting up fc6
I0530 14:25:46.737949  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:25:46.737949  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:25:46.737949  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:25:46.737949  6908 net.cpp:84] Creating Layer relu6
I0530 14:25:46.737949  6908 net.cpp:406] relu6 <- fc6
I0530 14:25:46.737949  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:25:46.737949  6908 net.cpp:122] Setting up relu6
I0530 14:25:46.737949  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:25:46.737949  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:25:46.737949  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:25:46.737949  6908 net.cpp:84] Creating Layer fc7
I0530 14:25:46.737949  6908 net.cpp:406] fc7 <- fc6
I0530 14:25:46.737949  6908 net.cpp:380] fc7 -> fc7
I0530 14:25:46.737949  6908 net.cpp:122] Setting up fc7
I0530 14:25:46.737949  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:25:46.737949  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:25:46.737949  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:25:46.737949  6908 net.cpp:84] Creating Layer prob
I0530 14:25:46.737949  6908 net.cpp:406] prob <- fc7
I0530 14:25:46.737949  6908 net.cpp:380] prob -> prob
I0530 14:25:46.737949  6908 net.cpp:122] Setting up prob
I0530 14:25:46.737949  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:25:46.737949  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:25:46.737949  6908 net.cpp:200] prob does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:200] input does not need backward computation.
I0530 14:25:46.737949  6908 net.cpp:242] This network produces output prob
I0530 14:25:46.737949  6908 net.cpp:255] Network initialization done.
I0530 14:25:46.756929  6908 net.cpp:744] Ignoring source layer data
I0530 14:25:46.759954  6908 net.cpp:744] Ignoring source layer loss
I0530 14:26:21.836870  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:26:21.836870  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:26:21.836870  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:26:21.836870  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:26:21.836870  6908 layer_factory.hpp:77] Creating layer input
I0530 14:26:21.836870  6908 net.cpp:84] Creating Layer input
I0530 14:26:21.836870  6908 net.cpp:380] input -> data
I0530 14:26:21.837882  6908 net.cpp:122] Setting up input
I0530 14:26:21.837882  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:26:21.837882  6908 net.cpp:137] Memory required for data: 16384
I0530 14:26:21.837882  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:26:21.837882  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:26:21.837882  6908 net.cpp:406] conv1_1 <- data
I0530 14:26:21.837882  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:26:21.839871  6908 net.cpp:122] Setting up conv1_1
I0530 14:26:21.839871  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:26:21.839871  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:26:21.839871  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:26:21.839871  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:26:21.839871  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:26:21.839871  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:26:21.839871  6908 net.cpp:122] Setting up relu1_1
I0530 14:26:21.839871  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:26:21.839871  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:26:21.839871  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:26:21.839871  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:26:21.839871  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:26:21.839871  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:26:21.840872  6908 net.cpp:122] Setting up conv1_2
I0530 14:26:21.840872  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:26:21.840872  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:26:21.840872  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:26:21.840872  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:26:21.840872  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:26:21.840872  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:26:21.840872  6908 net.cpp:122] Setting up relu1_2
I0530 14:26:21.840872  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:26:21.840872  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:26:21.840872  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:26:21.840872  6908 net.cpp:84] Creating Layer pool1
I0530 14:26:21.840872  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:26:21.840872  6908 net.cpp:380] pool1 -> pool1
I0530 14:26:21.840872  6908 net.cpp:122] Setting up pool1
I0530 14:26:21.840872  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:26:21.840872  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:26:21.840872  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:26:21.840872  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:26:21.840872  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:26:21.840872  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:26:21.841869  6908 net.cpp:122] Setting up conv2_1
I0530 14:26:21.841869  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:26:21.841869  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:26:21.841869  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:26:21.841869  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:26:21.841869  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:26:21.841869  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:26:21.841869  6908 net.cpp:122] Setting up relu2_1
I0530 14:26:21.841869  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:26:21.841869  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:26:21.841869  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:26:21.841869  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:26:21.841869  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:26:21.841869  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:26:21.841869  6908 net.cpp:122] Setting up conv2_2
I0530 14:26:21.841869  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:26:21.841869  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:26:21.841869  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:26:21.841869  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:26:21.841869  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:26:21.841869  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:26:21.841869  6908 net.cpp:122] Setting up relu2_2
I0530 14:26:21.841869  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:26:21.841869  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:26:21.841869  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:26:21.841869  6908 net.cpp:84] Creating Layer pool2
I0530 14:26:21.841869  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:26:21.841869  6908 net.cpp:380] pool2 -> pool2
I0530 14:26:21.841869  6908 net.cpp:122] Setting up pool2
I0530 14:26:21.842869  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:21.842869  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:26:21.842869  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:26:21.842869  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:26:21.842869  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:26:21.842869  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:26:21.842869  6908 net.cpp:122] Setting up conv3_1
I0530 14:26:21.842869  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:21.842869  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:26:21.842869  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:26:21.842869  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:26:21.842869  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:26:21.842869  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:26:21.842869  6908 net.cpp:122] Setting up relu3_1
I0530 14:26:21.843869  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:21.843869  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:26:21.843869  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:26:21.843869  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:26:21.843869  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:26:21.843869  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:26:21.843869  6908 net.cpp:122] Setting up conv3_2
I0530 14:26:21.843869  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:21.843869  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:26:21.843869  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:26:21.843869  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:26:21.843869  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:26:21.844868  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:26:21.844868  6908 net.cpp:122] Setting up relu3_2
I0530 14:26:21.844868  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:21.844868  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:26:21.844868  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:26:21.844868  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:26:21.844868  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:26:21.844868  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:26:21.845870  6908 net.cpp:122] Setting up conv3_3
I0530 14:26:21.845870  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:21.845870  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:26:21.845870  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:26:21.845870  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:26:21.845870  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:26:21.845870  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:26:21.845870  6908 net.cpp:122] Setting up relu3_3
I0530 14:26:21.845870  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:21.845870  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:26:21.845870  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:26:21.845870  6908 net.cpp:84] Creating Layer pool3
I0530 14:26:21.845870  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:26:21.845870  6908 net.cpp:380] pool3 -> pool3
I0530 14:26:21.845870  6908 net.cpp:122] Setting up pool3
I0530 14:26:21.845870  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:26:21.845870  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:26:21.845870  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:26:21.845870  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:26:21.845870  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:26:21.845870  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:26:21.847868  6908 net.cpp:122] Setting up conv4_1
I0530 14:26:21.847868  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:21.847868  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:26:21.847868  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:26:21.847868  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:26:21.847868  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:26:21.847868  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:26:21.847868  6908 net.cpp:122] Setting up relu4_1
I0530 14:26:21.847868  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:21.847868  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:26:21.847868  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:26:21.847868  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:26:21.847868  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:26:21.847868  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:26:21.851872  6908 net.cpp:122] Setting up conv4_2
I0530 14:26:21.851872  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:21.851872  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:26:21.851872  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:26:21.851872  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:26:21.851872  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:26:21.851872  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:26:21.851872  6908 net.cpp:122] Setting up relu4_2
I0530 14:26:21.851872  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:21.851872  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:26:21.851872  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:26:21.851872  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:26:21.851872  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:26:21.851872  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:26:21.855868  6908 net.cpp:122] Setting up conv4_3
I0530 14:26:21.855868  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:21.855868  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:26:21.855868  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:26:21.855868  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:26:21.855868  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:26:21.855868  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:26:21.855868  6908 net.cpp:122] Setting up relu4_3
I0530 14:26:21.855868  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:21.855868  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:26:21.855868  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:26:21.855868  6908 net.cpp:84] Creating Layer pool4
I0530 14:26:21.855868  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:26:21.855868  6908 net.cpp:380] pool4 -> pool4
I0530 14:26:21.855868  6908 net.cpp:122] Setting up pool4
I0530 14:26:21.855868  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:21.855868  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:26:21.855868  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:26:21.855868  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:26:21.855868  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:26:21.855868  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:26:21.859057  6908 net.cpp:122] Setting up conv5_1
I0530 14:26:21.859057  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:21.859057  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:26:21.859057  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:26:21.859057  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:26:21.859057  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:26:21.859057  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:26:21.859057  6908 net.cpp:122] Setting up relu5_1
I0530 14:26:21.859057  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:21.859057  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:26:21.859057  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:26:21.859057  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:26:21.859057  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:26:21.859057  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:26:21.863057  6908 net.cpp:122] Setting up conv5_2
I0530 14:26:21.863057  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:21.863057  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:26:21.863057  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:26:21.863057  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:26:21.863057  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:26:21.863057  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:26:21.863057  6908 net.cpp:122] Setting up relu5_2
I0530 14:26:21.863057  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:21.863057  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:26:21.863057  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:26:21.863057  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:26:21.863057  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:26:21.863057  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:26:21.867056  6908 net.cpp:122] Setting up conv5_3
I0530 14:26:21.867056  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:21.867056  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:26:21.867056  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:26:21.867056  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:26:21.867056  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:26:21.867056  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:26:21.867056  6908 net.cpp:122] Setting up relu5_3
I0530 14:26:21.867056  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:21.867056  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:26:21.867056  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:26:21.867056  6908 net.cpp:84] Creating Layer pool5
I0530 14:26:21.867056  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:26:21.867056  6908 net.cpp:380] pool5 -> pool5
I0530 14:26:21.867056  6908 net.cpp:122] Setting up pool5
I0530 14:26:21.867056  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:26:21.867056  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:26:21.867056  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:26:21.867056  6908 net.cpp:84] Creating Layer drop6
I0530 14:26:21.867056  6908 net.cpp:406] drop6 <- pool5
I0530 14:26:21.867056  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:26:21.867056  6908 net.cpp:122] Setting up drop6
I0530 14:26:21.867056  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:26:21.867056  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:26:21.867056  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:26:21.867056  6908 net.cpp:84] Creating Layer fc6
I0530 14:26:21.867056  6908 net.cpp:406] fc6 <- pool5
I0530 14:26:21.867056  6908 net.cpp:380] fc6 -> fc6
I0530 14:26:21.870056  6908 net.cpp:122] Setting up fc6
I0530 14:26:21.870056  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:26:21.870056  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:26:21.870056  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:26:21.870056  6908 net.cpp:84] Creating Layer relu6
I0530 14:26:21.870056  6908 net.cpp:406] relu6 <- fc6
I0530 14:26:21.870056  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:26:21.870056  6908 net.cpp:122] Setting up relu6
I0530 14:26:21.870056  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:26:21.870056  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:26:21.870056  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:26:21.870056  6908 net.cpp:84] Creating Layer fc7
I0530 14:26:21.870056  6908 net.cpp:406] fc7 <- fc6
I0530 14:26:21.870056  6908 net.cpp:380] fc7 -> fc7
I0530 14:26:21.870056  6908 net.cpp:122] Setting up fc7
I0530 14:26:21.870056  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:26:21.870056  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:26:21.870056  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:26:21.870056  6908 net.cpp:84] Creating Layer prob
I0530 14:26:21.870056  6908 net.cpp:406] prob <- fc7
I0530 14:26:21.870056  6908 net.cpp:380] prob -> prob
I0530 14:26:21.870056  6908 net.cpp:122] Setting up prob
I0530 14:26:21.870056  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:26:21.870056  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:26:21.870056  6908 net.cpp:200] prob does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:26:21.870056  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:26:21.871057  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:26:21.871057  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:26:21.871057  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:26:21.871057  6908 net.cpp:200] input does not need backward computation.
I0530 14:26:21.871057  6908 net.cpp:242] This network produces output prob
I0530 14:26:21.871057  6908 net.cpp:255] Network initialization done.
I0530 14:26:21.889057  6908 net.cpp:744] Ignoring source layer data
I0530 14:26:21.892057  6908 net.cpp:744] Ignoring source layer loss
I0530 14:26:38.144384  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:26:38.144384  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:26:38.144384  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:26:38.144384  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:26:38.144384  6908 layer_factory.hpp:77] Creating layer input
I0530 14:26:38.144384  6908 net.cpp:84] Creating Layer input
I0530 14:26:38.144384  6908 net.cpp:380] input -> data
I0530 14:26:38.145360  6908 net.cpp:122] Setting up input
I0530 14:26:38.145360  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:26:38.145360  6908 net.cpp:137] Memory required for data: 16384
I0530 14:26:38.145360  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:26:38.145360  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:26:38.145360  6908 net.cpp:406] conv1_1 <- data
I0530 14:26:38.145360  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:26:38.146361  6908 net.cpp:122] Setting up conv1_1
I0530 14:26:38.146361  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:26:38.146361  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:26:38.146361  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:26:38.146361  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:26:38.146361  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:26:38.146361  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:26:38.146361  6908 net.cpp:122] Setting up relu1_1
I0530 14:26:38.146361  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:26:38.146361  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:26:38.146361  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:26:38.146361  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:26:38.146361  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:26:38.146361  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:26:38.147384  6908 net.cpp:122] Setting up conv1_2
I0530 14:26:38.147384  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:26:38.147384  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:26:38.147384  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:26:38.147384  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:26:38.147384  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:26:38.147384  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:26:38.147384  6908 net.cpp:122] Setting up relu1_2
I0530 14:26:38.147384  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:26:38.147384  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:26:38.147384  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:26:38.147384  6908 net.cpp:84] Creating Layer pool1
I0530 14:26:38.147384  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:26:38.147384  6908 net.cpp:380] pool1 -> pool1
I0530 14:26:38.147384  6908 net.cpp:122] Setting up pool1
I0530 14:26:38.147384  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:26:38.147384  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:26:38.147384  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:26:38.147384  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:26:38.147384  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:26:38.147384  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:26:38.148385  6908 net.cpp:122] Setting up conv2_1
I0530 14:26:38.148385  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:26:38.148385  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:26:38.148385  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:26:38.148385  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:26:38.148385  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:26:38.148385  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:26:38.148385  6908 net.cpp:122] Setting up relu2_1
I0530 14:26:38.148385  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:26:38.148385  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:26:38.148385  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:26:38.148385  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:26:38.148385  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:26:38.148385  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:26:38.148385  6908 net.cpp:122] Setting up conv2_2
I0530 14:26:38.148385  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:26:38.148385  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:26:38.148385  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:26:38.148385  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:26:38.148385  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:26:38.148385  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:26:38.148385  6908 net.cpp:122] Setting up relu2_2
I0530 14:26:38.148385  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:26:38.148385  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:26:38.148385  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:26:38.148385  6908 net.cpp:84] Creating Layer pool2
I0530 14:26:38.149382  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:26:38.149382  6908 net.cpp:380] pool2 -> pool2
I0530 14:26:38.149382  6908 net.cpp:122] Setting up pool2
I0530 14:26:38.149382  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:38.149382  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:26:38.149382  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:26:38.149382  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:26:38.149382  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:26:38.149382  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:26:38.149382  6908 net.cpp:122] Setting up conv3_1
I0530 14:26:38.149382  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:38.149382  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:26:38.149382  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:26:38.149382  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:26:38.149382  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:26:38.149382  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:26:38.149382  6908 net.cpp:122] Setting up relu3_1
I0530 14:26:38.149382  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:38.149382  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:26:38.149382  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:26:38.149382  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:26:38.149382  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:26:38.149382  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:26:38.150384  6908 net.cpp:122] Setting up conv3_2
I0530 14:26:38.150384  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:38.150384  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:26:38.150384  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:26:38.150384  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:26:38.150384  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:26:38.150384  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:26:38.150384  6908 net.cpp:122] Setting up relu3_2
I0530 14:26:38.150384  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:38.150384  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:26:38.150384  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:26:38.150384  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:26:38.150384  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:26:38.150384  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:26:38.152384  6908 net.cpp:122] Setting up conv3_3
I0530 14:26:38.152384  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:38.152384  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:26:38.152384  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:26:38.152384  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:26:38.152384  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:26:38.152384  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:26:38.152384  6908 net.cpp:122] Setting up relu3_3
I0530 14:26:38.152384  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:26:38.152384  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:26:38.152384  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:26:38.152384  6908 net.cpp:84] Creating Layer pool3
I0530 14:26:38.152384  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:26:38.152384  6908 net.cpp:380] pool3 -> pool3
I0530 14:26:38.152384  6908 net.cpp:122] Setting up pool3
I0530 14:26:38.152384  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:26:38.152384  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:26:38.152384  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:26:38.152384  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:26:38.152384  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:26:38.152384  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:26:38.153384  6908 net.cpp:122] Setting up conv4_1
I0530 14:26:38.153384  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:38.153384  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:26:38.153384  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:26:38.153384  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:26:38.153384  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:26:38.153384  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:26:38.153384  6908 net.cpp:122] Setting up relu4_1
I0530 14:26:38.153384  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:38.153384  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:26:38.153384  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:26:38.153384  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:26:38.153384  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:26:38.153384  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:26:38.157135  6908 net.cpp:122] Setting up conv4_2
I0530 14:26:38.157135  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:38.157135  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:26:38.157135  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:26:38.157135  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:26:38.157135  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:26:38.157135  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:26:38.157135  6908 net.cpp:122] Setting up relu4_2
I0530 14:26:38.157135  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:38.157135  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:26:38.157135  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:26:38.157135  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:26:38.157135  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:26:38.157135  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:26:38.161166  6908 net.cpp:122] Setting up conv4_3
I0530 14:26:38.161166  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:38.161166  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:26:38.161166  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:26:38.161166  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:26:38.161166  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:26:38.161166  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:26:38.161166  6908 net.cpp:122] Setting up relu4_3
I0530 14:26:38.161166  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:26:38.161166  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:26:38.161166  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:26:38.161166  6908 net.cpp:84] Creating Layer pool4
I0530 14:26:38.161166  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:26:38.161166  6908 net.cpp:380] pool4 -> pool4
I0530 14:26:38.161166  6908 net.cpp:122] Setting up pool4
I0530 14:26:38.161166  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:38.161166  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:26:38.161166  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:26:38.161166  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:26:38.161166  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:26:38.161166  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:26:38.165158  6908 net.cpp:122] Setting up conv5_1
I0530 14:26:38.165158  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:38.165158  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:26:38.165158  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:26:38.165158  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:26:38.165158  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:26:38.165158  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:26:38.165158  6908 net.cpp:122] Setting up relu5_1
I0530 14:26:38.165158  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:38.165158  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:26:38.165158  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:26:38.165158  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:26:38.165158  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:26:38.165158  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:26:38.168607  6908 net.cpp:122] Setting up conv5_2
I0530 14:26:38.168607  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:38.168607  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:26:38.168607  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:26:38.168607  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:26:38.168607  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:26:38.168607  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:26:38.168607  6908 net.cpp:122] Setting up relu5_2
I0530 14:26:38.168607  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:38.168607  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:26:38.168607  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:26:38.168607  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:26:38.168607  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:26:38.168607  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:26:38.172228  6908 net.cpp:122] Setting up conv5_3
I0530 14:26:38.172228  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:38.172228  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:26:38.172228  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:26:38.172228  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:26:38.172228  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:26:38.172228  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:26:38.172228  6908 net.cpp:122] Setting up relu5_3
I0530 14:26:38.172228  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:26:38.172228  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:26:38.172228  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:26:38.172228  6908 net.cpp:84] Creating Layer pool5
I0530 14:26:38.172228  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:26:38.172228  6908 net.cpp:380] pool5 -> pool5
I0530 14:26:38.172228  6908 net.cpp:122] Setting up pool5
I0530 14:26:38.172228  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:26:38.172228  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:26:38.172228  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:26:38.172228  6908 net.cpp:84] Creating Layer drop6
I0530 14:26:38.172228  6908 net.cpp:406] drop6 <- pool5
I0530 14:26:38.172228  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:26:38.172228  6908 net.cpp:122] Setting up drop6
I0530 14:26:38.172228  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:26:38.172228  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:26:38.172228  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:26:38.172228  6908 net.cpp:84] Creating Layer fc6
I0530 14:26:38.172228  6908 net.cpp:406] fc6 <- pool5
I0530 14:26:38.172228  6908 net.cpp:380] fc6 -> fc6
I0530 14:26:38.176229  6908 net.cpp:122] Setting up fc6
I0530 14:26:38.176229  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:26:38.176229  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:26:38.176229  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:26:38.176229  6908 net.cpp:84] Creating Layer relu6
I0530 14:26:38.176229  6908 net.cpp:406] relu6 <- fc6
I0530 14:26:38.176229  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:26:38.176229  6908 net.cpp:122] Setting up relu6
I0530 14:26:38.176229  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:26:38.176229  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:26:38.176229  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:26:38.176229  6908 net.cpp:84] Creating Layer fc7
I0530 14:26:38.176229  6908 net.cpp:406] fc7 <- fc6
I0530 14:26:38.176229  6908 net.cpp:380] fc7 -> fc7
I0530 14:26:38.176229  6908 net.cpp:122] Setting up fc7
I0530 14:26:38.176229  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:26:38.176229  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:26:38.176229  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:26:38.176229  6908 net.cpp:84] Creating Layer prob
I0530 14:26:38.176229  6908 net.cpp:406] prob <- fc7
I0530 14:26:38.176229  6908 net.cpp:380] prob -> prob
I0530 14:26:38.176229  6908 net.cpp:122] Setting up prob
I0530 14:26:38.176229  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:26:38.176229  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:26:38.176229  6908 net.cpp:200] prob does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:200] input does not need backward computation.
I0530 14:26:38.176229  6908 net.cpp:242] This network produces output prob
I0530 14:26:38.176229  6908 net.cpp:255] Network initialization done.
I0530 14:26:38.194228  6908 net.cpp:744] Ignoring source layer data
I0530 14:26:38.197229  6908 net.cpp:744] Ignoring source layer loss
I0530 14:27:09.794337  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:27:09.794337  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:27:09.794337  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:27:09.794337  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:27:09.795336  6908 layer_factory.hpp:77] Creating layer input
I0530 14:27:09.795336  6908 net.cpp:84] Creating Layer input
I0530 14:27:09.795336  6908 net.cpp:380] input -> data
I0530 14:27:09.795336  6908 net.cpp:122] Setting up input
I0530 14:27:09.795336  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:27:09.795336  6908 net.cpp:137] Memory required for data: 16384
I0530 14:27:09.795336  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:27:09.795336  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:27:09.795336  6908 net.cpp:406] conv1_1 <- data
I0530 14:27:09.795336  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:27:09.797314  6908 net.cpp:122] Setting up conv1_1
I0530 14:27:09.797314  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:27:09.797314  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:27:09.797314  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:27:09.797314  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:27:09.797314  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:27:09.797314  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:27:09.797314  6908 net.cpp:122] Setting up relu1_1
I0530 14:27:09.797314  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:27:09.797314  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:27:09.797314  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:27:09.797314  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:27:09.797314  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:27:09.797314  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:27:09.798313  6908 net.cpp:122] Setting up conv1_2
I0530 14:27:09.798313  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:27:09.798313  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:27:09.798313  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:27:09.798313  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:27:09.798313  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:27:09.798313  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:27:09.798313  6908 net.cpp:122] Setting up relu1_2
I0530 14:27:09.798313  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:27:09.798313  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:27:09.798313  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:27:09.798313  6908 net.cpp:84] Creating Layer pool1
I0530 14:27:09.798313  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:27:09.798313  6908 net.cpp:380] pool1 -> pool1
I0530 14:27:09.798313  6908 net.cpp:122] Setting up pool1
I0530 14:27:09.798313  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:09.798313  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:27:09.798313  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:27:09.798313  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:27:09.798313  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:27:09.798313  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:27:09.799346  6908 net.cpp:122] Setting up conv2_1
I0530 14:27:09.799346  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:27:09.799346  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:27:09.799346  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:27:09.799346  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:27:09.799346  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:27:09.799346  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:27:09.799346  6908 net.cpp:122] Setting up relu2_1
I0530 14:27:09.799346  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:27:09.799346  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:27:09.799346  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:27:09.799346  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:27:09.799346  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:27:09.799346  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:27:09.799346  6908 net.cpp:122] Setting up conv2_2
I0530 14:27:09.799346  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:09.799346  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:27:09.799346  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:27:09.799346  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:27:09.799346  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:27:09.799346  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:27:09.799346  6908 net.cpp:122] Setting up relu2_2
I0530 14:27:09.799346  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:09.799346  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:27:09.799346  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:27:09.799346  6908 net.cpp:84] Creating Layer pool2
I0530 14:27:09.799346  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:27:09.799346  6908 net.cpp:380] pool2 -> pool2
I0530 14:27:09.799346  6908 net.cpp:122] Setting up pool2
I0530 14:27:09.799346  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:09.799346  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:27:09.799346  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:27:09.799346  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:27:09.799346  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:27:09.799346  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:27:09.800338  6908 net.cpp:122] Setting up conv3_1
I0530 14:27:09.800338  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:09.800338  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:27:09.800338  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:27:09.800338  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:27:09.800338  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:27:09.800338  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:27:09.800338  6908 net.cpp:122] Setting up relu3_1
I0530 14:27:09.800338  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:09.800338  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:27:09.800338  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:27:09.800338  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:27:09.800338  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:27:09.800338  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:27:09.801337  6908 net.cpp:122] Setting up conv3_2
I0530 14:27:09.801337  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:09.801337  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:27:09.801337  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:27:09.801337  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:27:09.801337  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:27:09.801337  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:27:09.801337  6908 net.cpp:122] Setting up relu3_2
I0530 14:27:09.801337  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:09.801337  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:27:09.801337  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:27:09.801337  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:27:09.801337  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:27:09.801337  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:27:09.803338  6908 net.cpp:122] Setting up conv3_3
I0530 14:27:09.803338  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:09.803338  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:27:09.803338  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:27:09.803338  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:27:09.803338  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:27:09.803338  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:27:09.803338  6908 net.cpp:122] Setting up relu3_3
I0530 14:27:09.803338  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:09.803338  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:27:09.803338  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:27:09.803338  6908 net.cpp:84] Creating Layer pool3
I0530 14:27:09.803338  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:27:09.803338  6908 net.cpp:380] pool3 -> pool3
I0530 14:27:09.803338  6908 net.cpp:122] Setting up pool3
I0530 14:27:09.803338  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:27:09.803338  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:27:09.803338  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:27:09.803338  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:27:09.803338  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:27:09.803338  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:27:09.804337  6908 net.cpp:122] Setting up conv4_1
I0530 14:27:09.804337  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:09.804337  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:27:09.804337  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:27:09.804337  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:27:09.804337  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:27:09.804337  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:27:09.804337  6908 net.cpp:122] Setting up relu4_1
I0530 14:27:09.804337  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:09.804337  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:27:09.804337  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:27:09.804337  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:27:09.804337  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:27:09.804337  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:27:09.807968  6908 net.cpp:122] Setting up conv4_2
I0530 14:27:09.807968  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:09.807968  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:27:09.807968  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:27:09.807968  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:27:09.807968  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:27:09.807968  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:27:09.807968  6908 net.cpp:122] Setting up relu4_2
I0530 14:27:09.807968  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:09.807968  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:27:09.807968  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:27:09.807968  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:27:09.807968  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:27:09.807968  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:27:09.811708  6908 net.cpp:122] Setting up conv4_3
I0530 14:27:09.811708  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:09.811708  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:27:09.811708  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:27:09.811708  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:27:09.811708  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:27:09.811708  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:27:09.811708  6908 net.cpp:122] Setting up relu4_3
I0530 14:27:09.811708  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:09.811708  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:27:09.811708  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:27:09.811708  6908 net.cpp:84] Creating Layer pool4
I0530 14:27:09.811708  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:27:09.811708  6908 net.cpp:380] pool4 -> pool4
I0530 14:27:09.811708  6908 net.cpp:122] Setting up pool4
I0530 14:27:09.811708  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:09.811708  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:27:09.811708  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:27:09.811708  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:27:09.811708  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:27:09.811708  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:27:09.815708  6908 net.cpp:122] Setting up conv5_1
I0530 14:27:09.815708  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:09.815708  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:27:09.815708  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:27:09.815708  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:27:09.815708  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:27:09.815708  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:27:09.815708  6908 net.cpp:122] Setting up relu5_1
I0530 14:27:09.815708  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:09.815708  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:27:09.815708  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:27:09.815708  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:27:09.815708  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:27:09.815708  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:27:09.819708  6908 net.cpp:122] Setting up conv5_2
I0530 14:27:09.819708  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:09.819708  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:27:09.819708  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:27:09.819708  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:27:09.819708  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:27:09.819708  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:27:09.819708  6908 net.cpp:122] Setting up relu5_2
I0530 14:27:09.819708  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:09.819708  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:27:09.819708  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:27:09.819708  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:27:09.819708  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:27:09.819708  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:27:09.823709  6908 net.cpp:122] Setting up conv5_3
I0530 14:27:09.823709  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:09.823709  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:27:09.823709  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:27:09.823709  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:27:09.823709  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:27:09.823709  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:27:09.823709  6908 net.cpp:122] Setting up relu5_3
I0530 14:27:09.823709  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:09.823709  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:27:09.823709  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:27:09.823709  6908 net.cpp:84] Creating Layer pool5
I0530 14:27:09.823709  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:27:09.823709  6908 net.cpp:380] pool5 -> pool5
I0530 14:27:09.823709  6908 net.cpp:122] Setting up pool5
I0530 14:27:09.823709  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:27:09.823709  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:27:09.823709  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:27:09.823709  6908 net.cpp:84] Creating Layer drop6
I0530 14:27:09.823709  6908 net.cpp:406] drop6 <- pool5
I0530 14:27:09.823709  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:27:09.823709  6908 net.cpp:122] Setting up drop6
I0530 14:27:09.823709  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:27:09.823709  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:27:09.823709  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:27:09.823709  6908 net.cpp:84] Creating Layer fc6
I0530 14:27:09.823709  6908 net.cpp:406] fc6 <- pool5
I0530 14:27:09.823709  6908 net.cpp:380] fc6 -> fc6
I0530 14:27:09.826709  6908 net.cpp:122] Setting up fc6
I0530 14:27:09.826709  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:27:09.826709  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:27:09.826709  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:27:09.826709  6908 net.cpp:84] Creating Layer relu6
I0530 14:27:09.826709  6908 net.cpp:406] relu6 <- fc6
I0530 14:27:09.826709  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:27:09.826709  6908 net.cpp:122] Setting up relu6
I0530 14:27:09.826709  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:27:09.826709  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:27:09.826709  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:27:09.826709  6908 net.cpp:84] Creating Layer fc7
I0530 14:27:09.826709  6908 net.cpp:406] fc7 <- fc6
I0530 14:27:09.826709  6908 net.cpp:380] fc7 -> fc7
I0530 14:27:09.827704  6908 net.cpp:122] Setting up fc7
I0530 14:27:09.827704  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:27:09.827704  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:27:09.827704  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:27:09.827704  6908 net.cpp:84] Creating Layer prob
I0530 14:27:09.827704  6908 net.cpp:406] prob <- fc7
I0530 14:27:09.827704  6908 net.cpp:380] prob -> prob
I0530 14:27:09.827704  6908 net.cpp:122] Setting up prob
I0530 14:27:09.827704  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:27:09.827704  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:27:09.827704  6908 net.cpp:200] prob does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:200] input does not need backward computation.
I0530 14:27:09.827704  6908 net.cpp:242] This network produces output prob
I0530 14:27:09.827704  6908 net.cpp:255] Network initialization done.
I0530 14:27:09.847677  6908 net.cpp:744] Ignoring source layer data
I0530 14:27:09.850677  6908 net.cpp:744] Ignoring source layer loss
I0530 14:27:36.175133  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:27:36.175133  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:27:36.175133  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:27:36.175133  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:27:36.175133  6908 layer_factory.hpp:77] Creating layer input
I0530 14:27:36.175133  6908 net.cpp:84] Creating Layer input
I0530 14:27:36.175133  6908 net.cpp:380] input -> data
I0530 14:27:36.176111  6908 net.cpp:122] Setting up input
I0530 14:27:36.176111  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:27:36.176111  6908 net.cpp:137] Memory required for data: 16384
I0530 14:27:36.176111  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:27:36.176111  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:27:36.176111  6908 net.cpp:406] conv1_1 <- data
I0530 14:27:36.176111  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:27:36.177111  6908 net.cpp:122] Setting up conv1_1
I0530 14:27:36.177111  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:27:36.177111  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:27:36.177111  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:27:36.177111  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:27:36.177111  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:27:36.177111  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:27:36.177111  6908 net.cpp:122] Setting up relu1_1
I0530 14:27:36.177111  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:27:36.177111  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:27:36.177111  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:27:36.177111  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:27:36.177111  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:27:36.177111  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:27:36.179111  6908 net.cpp:122] Setting up conv1_2
I0530 14:27:36.179111  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:27:36.179111  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:27:36.179111  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:27:36.179111  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:27:36.179111  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:27:36.179111  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:27:36.179111  6908 net.cpp:122] Setting up relu1_2
I0530 14:27:36.179111  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:27:36.179111  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:27:36.179111  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:27:36.179111  6908 net.cpp:84] Creating Layer pool1
I0530 14:27:36.179111  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:27:36.179111  6908 net.cpp:380] pool1 -> pool1
I0530 14:27:36.179111  6908 net.cpp:122] Setting up pool1
I0530 14:27:36.179111  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:36.179111  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:27:36.179111  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:27:36.179111  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:27:36.179111  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:27:36.179111  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:27:36.179111  6908 net.cpp:122] Setting up conv2_1
I0530 14:27:36.179111  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:27:36.179111  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:27:36.179111  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:27:36.179111  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:27:36.179111  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:27:36.179111  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:27:36.179111  6908 net.cpp:122] Setting up relu2_1
I0530 14:27:36.179111  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:27:36.179111  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:27:36.179111  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:27:36.179111  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:27:36.179111  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:27:36.179111  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:27:36.180111  6908 net.cpp:122] Setting up conv2_2
I0530 14:27:36.180111  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:36.180111  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:27:36.180111  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:27:36.180111  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:27:36.180111  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:27:36.180111  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:27:36.180111  6908 net.cpp:122] Setting up relu2_2
I0530 14:27:36.180111  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:36.180111  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:27:36.180111  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:27:36.180111  6908 net.cpp:84] Creating Layer pool2
I0530 14:27:36.180111  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:27:36.180111  6908 net.cpp:380] pool2 -> pool2
I0530 14:27:36.180111  6908 net.cpp:122] Setting up pool2
I0530 14:27:36.180111  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:36.180111  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:27:36.180111  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:27:36.180111  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:27:36.180111  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:27:36.180111  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:27:36.181112  6908 net.cpp:122] Setting up conv3_1
I0530 14:27:36.181112  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:36.181112  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:27:36.181112  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:27:36.181112  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:27:36.181112  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:27:36.181112  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:27:36.181112  6908 net.cpp:122] Setting up relu3_1
I0530 14:27:36.181112  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:36.181112  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:27:36.181112  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:27:36.181112  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:27:36.181112  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:27:36.181112  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:27:36.182111  6908 net.cpp:122] Setting up conv3_2
I0530 14:27:36.182111  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:36.182111  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:27:36.182111  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:27:36.182111  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:27:36.182111  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:27:36.182111  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:27:36.182111  6908 net.cpp:122] Setting up relu3_2
I0530 14:27:36.182111  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:36.182111  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:27:36.182111  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:27:36.182111  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:27:36.182111  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:27:36.182111  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:27:36.183112  6908 net.cpp:122] Setting up conv3_3
I0530 14:27:36.183112  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:36.183112  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:27:36.183112  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:27:36.183112  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:27:36.183112  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:27:36.183112  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:27:36.183112  6908 net.cpp:122] Setting up relu3_3
I0530 14:27:36.183112  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:36.183112  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:27:36.183112  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:27:36.183112  6908 net.cpp:84] Creating Layer pool3
I0530 14:27:36.183112  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:27:36.183112  6908 net.cpp:380] pool3 -> pool3
I0530 14:27:36.183112  6908 net.cpp:122] Setting up pool3
I0530 14:27:36.183112  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:27:36.183112  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:27:36.183112  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:27:36.183112  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:27:36.183112  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:27:36.183112  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:27:36.185111  6908 net.cpp:122] Setting up conv4_1
I0530 14:27:36.185111  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:36.185111  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:27:36.185111  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:27:36.185111  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:27:36.185111  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:27:36.185111  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:27:36.185111  6908 net.cpp:122] Setting up relu4_1
I0530 14:27:36.185111  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:36.185111  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:27:36.185111  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:27:36.185111  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:27:36.185111  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:27:36.185111  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:27:36.188380  6908 net.cpp:122] Setting up conv4_2
I0530 14:27:36.188380  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:36.188380  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:27:36.188380  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:27:36.188380  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:27:36.188380  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:27:36.188380  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:27:36.188380  6908 net.cpp:122] Setting up relu4_2
I0530 14:27:36.188380  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:36.188380  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:27:36.188380  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:27:36.188380  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:27:36.188380  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:27:36.188380  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:27:36.192757  6908 net.cpp:122] Setting up conv4_3
I0530 14:27:36.192757  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:36.192757  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:27:36.192757  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:27:36.192757  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:27:36.192757  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:27:36.192757  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:27:36.192757  6908 net.cpp:122] Setting up relu4_3
I0530 14:27:36.192757  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:36.192757  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:27:36.192757  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:27:36.192757  6908 net.cpp:84] Creating Layer pool4
I0530 14:27:36.192757  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:27:36.192757  6908 net.cpp:380] pool4 -> pool4
I0530 14:27:36.192757  6908 net.cpp:122] Setting up pool4
I0530 14:27:36.192757  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:36.192757  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:27:36.192757  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:27:36.192757  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:27:36.192757  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:27:36.192757  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:27:36.195757  6908 net.cpp:122] Setting up conv5_1
I0530 14:27:36.195757  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:36.195757  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:27:36.195757  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:27:36.195757  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:27:36.195757  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:27:36.195757  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:27:36.195757  6908 net.cpp:122] Setting up relu5_1
I0530 14:27:36.195757  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:36.195757  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:27:36.195757  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:27:36.195757  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:27:36.195757  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:27:36.195757  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:27:36.199757  6908 net.cpp:122] Setting up conv5_2
I0530 14:27:36.199757  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:36.199757  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:27:36.199757  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:27:36.199757  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:27:36.199757  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:27:36.199757  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:27:36.199757  6908 net.cpp:122] Setting up relu5_2
I0530 14:27:36.199757  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:36.199757  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:27:36.199757  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:27:36.199757  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:27:36.199757  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:27:36.199757  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:27:36.203413  6908 net.cpp:122] Setting up conv5_3
I0530 14:27:36.203413  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:36.203413  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:27:36.203413  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:27:36.203413  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:27:36.203413  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:27:36.203413  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:27:36.203413  6908 net.cpp:122] Setting up relu5_3
I0530 14:27:36.203413  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:36.203413  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:27:36.203413  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:27:36.203413  6908 net.cpp:84] Creating Layer pool5
I0530 14:27:36.203413  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:27:36.203413  6908 net.cpp:380] pool5 -> pool5
I0530 14:27:36.203413  6908 net.cpp:122] Setting up pool5
I0530 14:27:36.203413  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:27:36.203413  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:27:36.203413  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:27:36.203413  6908 net.cpp:84] Creating Layer drop6
I0530 14:27:36.203413  6908 net.cpp:406] drop6 <- pool5
I0530 14:27:36.203413  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:27:36.203413  6908 net.cpp:122] Setting up drop6
I0530 14:27:36.203413  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:27:36.203413  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:27:36.203413  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:27:36.203413  6908 net.cpp:84] Creating Layer fc6
I0530 14:27:36.203413  6908 net.cpp:406] fc6 <- pool5
I0530 14:27:36.203413  6908 net.cpp:380] fc6 -> fc6
I0530 14:27:36.207413  6908 net.cpp:122] Setting up fc6
I0530 14:27:36.207413  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:27:36.207413  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:27:36.207413  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:27:36.207413  6908 net.cpp:84] Creating Layer relu6
I0530 14:27:36.207413  6908 net.cpp:406] relu6 <- fc6
I0530 14:27:36.207413  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:27:36.207413  6908 net.cpp:122] Setting up relu6
I0530 14:27:36.207413  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:27:36.207413  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:27:36.207413  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:27:36.207413  6908 net.cpp:84] Creating Layer fc7
I0530 14:27:36.207413  6908 net.cpp:406] fc7 <- fc6
I0530 14:27:36.207413  6908 net.cpp:380] fc7 -> fc7
I0530 14:27:36.207413  6908 net.cpp:122] Setting up fc7
I0530 14:27:36.207413  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:27:36.207413  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:27:36.207413  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:27:36.207413  6908 net.cpp:84] Creating Layer prob
I0530 14:27:36.207413  6908 net.cpp:406] prob <- fc7
I0530 14:27:36.207413  6908 net.cpp:380] prob -> prob
I0530 14:27:36.207413  6908 net.cpp:122] Setting up prob
I0530 14:27:36.207413  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:27:36.207413  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:27:36.207413  6908 net.cpp:200] prob does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:200] input does not need backward computation.
I0530 14:27:36.207413  6908 net.cpp:242] This network produces output prob
I0530 14:27:36.207413  6908 net.cpp:255] Network initialization done.
I0530 14:27:36.226416  6908 net.cpp:744] Ignoring source layer data
I0530 14:27:36.228410  6908 net.cpp:744] Ignoring source layer loss
W0530 14:27:36.245872  6908 net.hpp:41] DEPRECATED: ForwardPrefilled() will be removed in a future version. Use Forward().
W0530 14:27:36.246843  6908 gpu_memory.cpp:79] Lazily initializing GPU Memory Manager Scope on device 0. Note: it's recommended to do this explicitly in your main() function.
I0530 14:27:49.444118  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:27:49.444118  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:27:49.444118  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:27:49.444118  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:27:49.444118  6908 layer_factory.hpp:77] Creating layer input
I0530 14:27:49.444118  6908 net.cpp:84] Creating Layer input
I0530 14:27:49.444118  6908 net.cpp:380] input -> data
I0530 14:27:49.445137  6908 net.cpp:122] Setting up input
I0530 14:27:49.445137  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:27:49.445137  6908 net.cpp:137] Memory required for data: 16384
I0530 14:27:49.445137  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:27:49.445137  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:27:49.445137  6908 net.cpp:406] conv1_1 <- data
I0530 14:27:49.445137  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:27:49.446120  6908 net.cpp:122] Setting up conv1_1
I0530 14:27:49.446120  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:27:49.446120  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:27:49.446120  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:27:49.446120  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:27:49.446120  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:27:49.446120  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:27:49.446120  6908 net.cpp:122] Setting up relu1_1
I0530 14:27:49.446120  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:27:49.446120  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:27:49.446120  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:27:49.446120  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:27:49.446120  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:27:49.446120  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:27:49.447147  6908 net.cpp:122] Setting up conv1_2
I0530 14:27:49.447147  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:27:49.447147  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:27:49.447147  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:27:49.447147  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:27:49.447147  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:27:49.447147  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:27:49.447147  6908 net.cpp:122] Setting up relu1_2
I0530 14:27:49.447147  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:27:49.447147  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:27:49.447147  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:27:49.447147  6908 net.cpp:84] Creating Layer pool1
I0530 14:27:49.447147  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:27:49.447147  6908 net.cpp:380] pool1 -> pool1
I0530 14:27:49.447147  6908 net.cpp:122] Setting up pool1
I0530 14:27:49.447147  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:49.447147  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:27:49.447147  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:27:49.447147  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:27:49.447147  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:27:49.447147  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:27:49.448120  6908 net.cpp:122] Setting up conv2_1
I0530 14:27:49.448120  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:27:49.448120  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:27:49.448120  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:27:49.448120  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:27:49.448120  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:27:49.448120  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:27:49.448120  6908 net.cpp:122] Setting up relu2_1
I0530 14:27:49.448120  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:27:49.448120  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:27:49.448120  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:27:49.448120  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:27:49.448120  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:27:49.448120  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:27:49.448120  6908 net.cpp:122] Setting up conv2_2
I0530 14:27:49.448120  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:49.448120  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:27:49.448120  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:27:49.448120  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:27:49.448120  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:27:49.448120  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:27:49.448120  6908 net.cpp:122] Setting up relu2_2
I0530 14:27:49.448120  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:27:49.448120  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:27:49.448120  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:27:49.448120  6908 net.cpp:84] Creating Layer pool2
I0530 14:27:49.448120  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:27:49.448120  6908 net.cpp:380] pool2 -> pool2
I0530 14:27:49.449148  6908 net.cpp:122] Setting up pool2
I0530 14:27:49.449148  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:49.449148  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:27:49.449148  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:27:49.449148  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:27:49.449148  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:27:49.449148  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:27:49.449148  6908 net.cpp:122] Setting up conv3_1
I0530 14:27:49.449148  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:49.449148  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:27:49.449148  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:27:49.449148  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:27:49.449148  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:27:49.449148  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:27:49.449148  6908 net.cpp:122] Setting up relu3_1
I0530 14:27:49.449148  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:49.449148  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:27:49.449148  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:27:49.449148  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:27:49.449148  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:27:49.449148  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:27:49.450147  6908 net.cpp:122] Setting up conv3_2
I0530 14:27:49.450147  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:49.450147  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:27:49.450147  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:27:49.450147  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:27:49.450147  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:27:49.450147  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:27:49.450147  6908 net.cpp:122] Setting up relu3_2
I0530 14:27:49.450147  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:49.450147  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:27:49.450147  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:27:49.450147  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:27:49.450147  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:27:49.450147  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:27:49.451755  6908 net.cpp:122] Setting up conv3_3
I0530 14:27:49.451755  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:49.451755  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:27:49.451755  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:27:49.451755  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:27:49.451755  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:27:49.451755  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:27:49.451755  6908 net.cpp:122] Setting up relu3_3
I0530 14:27:49.451755  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:27:49.451755  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:27:49.451755  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:27:49.451755  6908 net.cpp:84] Creating Layer pool3
I0530 14:27:49.451755  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:27:49.451755  6908 net.cpp:380] pool3 -> pool3
I0530 14:27:49.451755  6908 net.cpp:122] Setting up pool3
I0530 14:27:49.451755  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:27:49.451755  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:27:49.451755  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:27:49.451755  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:27:49.451755  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:27:49.451755  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:27:49.453757  6908 net.cpp:122] Setting up conv4_1
I0530 14:27:49.453757  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:49.453757  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:27:49.453757  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:27:49.453757  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:27:49.453757  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:27:49.453757  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:27:49.453757  6908 net.cpp:122] Setting up relu4_1
I0530 14:27:49.453757  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:49.453757  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:27:49.453757  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:27:49.453757  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:27:49.453757  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:27:49.453757  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:27:49.456710  6908 net.cpp:122] Setting up conv4_2
I0530 14:27:49.456710  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:49.456710  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:27:49.456710  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:27:49.456710  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:27:49.456710  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:27:49.456710  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:27:49.456710  6908 net.cpp:122] Setting up relu4_2
I0530 14:27:49.456710  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:49.457711  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:27:49.457711  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:27:49.457711  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:27:49.457711  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:27:49.457711  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:27:49.460711  6908 net.cpp:122] Setting up conv4_3
I0530 14:27:49.460711  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:49.460711  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:27:49.460711  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:27:49.460711  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:27:49.460711  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:27:49.460711  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:27:49.460711  6908 net.cpp:122] Setting up relu4_3
I0530 14:27:49.460711  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:27:49.460711  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:27:49.460711  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:27:49.460711  6908 net.cpp:84] Creating Layer pool4
I0530 14:27:49.460711  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:27:49.460711  6908 net.cpp:380] pool4 -> pool4
I0530 14:27:49.460711  6908 net.cpp:122] Setting up pool4
I0530 14:27:49.460711  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:49.460711  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:27:49.460711  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:27:49.460711  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:27:49.460711  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:27:49.460711  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:27:49.464711  6908 net.cpp:122] Setting up conv5_1
I0530 14:27:49.464711  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:49.464711  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:27:49.464711  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:27:49.464711  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:27:49.464711  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:27:49.464711  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:27:49.464711  6908 net.cpp:122] Setting up relu5_1
I0530 14:27:49.464711  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:49.464711  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:27:49.464711  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:27:49.464711  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:27:49.464711  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:27:49.464711  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:27:49.468677  6908 net.cpp:122] Setting up conv5_2
I0530 14:27:49.468677  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:49.468677  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:27:49.468677  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:27:49.468677  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:27:49.468677  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:27:49.468677  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:27:49.468677  6908 net.cpp:122] Setting up relu5_2
I0530 14:27:49.468677  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:49.468677  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:27:49.468677  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:27:49.468677  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:27:49.468677  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:27:49.468677  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:27:49.471678  6908 net.cpp:122] Setting up conv5_3
I0530 14:27:49.471678  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:49.471678  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:27:49.471678  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:27:49.471678  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:27:49.471678  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:27:49.471678  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:27:49.471678  6908 net.cpp:122] Setting up relu5_3
I0530 14:27:49.471678  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:27:49.471678  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:27:49.471678  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:27:49.471678  6908 net.cpp:84] Creating Layer pool5
I0530 14:27:49.471678  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:27:49.471678  6908 net.cpp:380] pool5 -> pool5
I0530 14:27:49.471678  6908 net.cpp:122] Setting up pool5
I0530 14:27:49.471678  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:27:49.471678  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:27:49.471678  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:27:49.471678  6908 net.cpp:84] Creating Layer drop6
I0530 14:27:49.471678  6908 net.cpp:406] drop6 <- pool5
I0530 14:27:49.471678  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:27:49.471678  6908 net.cpp:122] Setting up drop6
I0530 14:27:49.471678  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:27:49.471678  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:27:49.471678  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:27:49.471678  6908 net.cpp:84] Creating Layer fc6
I0530 14:27:49.471678  6908 net.cpp:406] fc6 <- pool5
I0530 14:27:49.471678  6908 net.cpp:380] fc6 -> fc6
I0530 14:27:49.475177  6908 net.cpp:122] Setting up fc6
I0530 14:27:49.475177  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:27:49.475177  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:27:49.475177  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:27:49.475177  6908 net.cpp:84] Creating Layer relu6
I0530 14:27:49.475177  6908 net.cpp:406] relu6 <- fc6
I0530 14:27:49.475177  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:27:49.475177  6908 net.cpp:122] Setting up relu6
I0530 14:27:49.475177  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:27:49.475177  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:27:49.475177  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:27:49.475177  6908 net.cpp:84] Creating Layer fc7
I0530 14:27:49.475177  6908 net.cpp:406] fc7 <- fc6
I0530 14:27:49.475177  6908 net.cpp:380] fc7 -> fc7
I0530 14:27:49.475177  6908 net.cpp:122] Setting up fc7
I0530 14:27:49.475177  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:27:49.475177  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:27:49.475177  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:27:49.475177  6908 net.cpp:84] Creating Layer prob
I0530 14:27:49.475177  6908 net.cpp:406] prob <- fc7
I0530 14:27:49.475177  6908 net.cpp:380] prob -> prob
I0530 14:27:49.475177  6908 net.cpp:122] Setting up prob
I0530 14:27:49.475177  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:27:49.475177  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:27:49.475177  6908 net.cpp:200] prob does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:200] input does not need backward computation.
I0530 14:27:49.475177  6908 net.cpp:242] This network produces output prob
I0530 14:27:49.475177  6908 net.cpp:255] Network initialization done.
I0530 14:27:49.494177  6908 net.cpp:744] Ignoring source layer data
I0530 14:27:49.496177  6908 net.cpp:744] Ignoring source layer loss
I0530 14:37:50.378154  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:37:50.378154  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:37:50.378154  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:37:50.378154  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:37:50.378154  6908 layer_factory.hpp:77] Creating layer input
I0530 14:37:50.378154  6908 net.cpp:84] Creating Layer input
I0530 14:37:50.378154  6908 net.cpp:380] input -> data
I0530 14:37:50.379179  6908 net.cpp:122] Setting up input
I0530 14:37:50.379179  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:37:50.379179  6908 net.cpp:137] Memory required for data: 16384
I0530 14:37:50.379179  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:37:50.379179  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:37:50.379179  6908 net.cpp:406] conv1_1 <- data
I0530 14:37:50.379179  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:37:50.380182  6908 net.cpp:122] Setting up conv1_1
I0530 14:37:50.380182  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:37:50.380182  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:37:50.380182  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:37:50.380182  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:37:50.380182  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:37:50.380182  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:37:50.380182  6908 net.cpp:122] Setting up relu1_1
I0530 14:37:50.380182  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:37:50.380182  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:37:50.380182  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:37:50.380182  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:37:50.380182  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:37:50.380182  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:37:50.381182  6908 net.cpp:122] Setting up conv1_2
I0530 14:37:50.381182  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:37:50.381182  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:37:50.381182  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:37:50.381182  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:37:50.381182  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:37:50.381182  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:37:50.381182  6908 net.cpp:122] Setting up relu1_2
I0530 14:37:50.381182  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:37:50.381182  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:37:50.381182  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:37:50.381182  6908 net.cpp:84] Creating Layer pool1
I0530 14:37:50.381182  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:37:50.381182  6908 net.cpp:380] pool1 -> pool1
I0530 14:37:50.381182  6908 net.cpp:122] Setting up pool1
I0530 14:37:50.381182  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:37:50.381182  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:37:50.381182  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:37:50.381182  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:37:50.381182  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:37:50.381182  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:37:50.382181  6908 net.cpp:122] Setting up conv2_1
I0530 14:37:50.382181  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:37:50.382181  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:37:50.382181  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:37:50.382181  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:37:50.382181  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:37:50.382181  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:37:50.382181  6908 net.cpp:122] Setting up relu2_1
I0530 14:37:50.382181  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:37:50.382181  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:37:50.382181  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:37:50.382181  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:37:50.382181  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:37:50.382181  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:37:50.382181  6908 net.cpp:122] Setting up conv2_2
I0530 14:37:50.382181  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:37:50.382181  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:37:50.382181  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:37:50.382181  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:37:50.382181  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:37:50.382181  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:37:50.382181  6908 net.cpp:122] Setting up relu2_2
I0530 14:37:50.382181  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:37:50.382181  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:37:50.382181  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:37:50.382181  6908 net.cpp:84] Creating Layer pool2
I0530 14:37:50.382181  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:37:50.382181  6908 net.cpp:380] pool2 -> pool2
I0530 14:37:50.382181  6908 net.cpp:122] Setting up pool2
I0530 14:37:50.382181  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:37:50.382181  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:37:50.382181  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:37:50.382181  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:37:50.382181  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:37:50.382181  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:37:50.383183  6908 net.cpp:122] Setting up conv3_1
I0530 14:37:50.383183  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:37:50.383183  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:37:50.383183  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:37:50.383183  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:37:50.383183  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:37:50.383183  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:37:50.383183  6908 net.cpp:122] Setting up relu3_1
I0530 14:37:50.383183  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:37:50.383183  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:37:50.383183  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:37:50.383183  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:37:50.383183  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:37:50.383183  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:37:50.384184  6908 net.cpp:122] Setting up conv3_2
I0530 14:37:50.384184  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:37:50.384184  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:37:50.384184  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:37:50.384184  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:37:50.384184  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:37:50.384184  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:37:50.384184  6908 net.cpp:122] Setting up relu3_2
I0530 14:37:50.384184  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:37:50.384184  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:37:50.384184  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:37:50.384184  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:37:50.384184  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:37:50.384184  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:37:50.386183  6908 net.cpp:122] Setting up conv3_3
I0530 14:37:50.386183  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:37:50.386183  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:37:50.386183  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:37:50.386183  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:37:50.386183  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:37:50.386183  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:37:50.386183  6908 net.cpp:122] Setting up relu3_3
I0530 14:37:50.386183  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:37:50.386183  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:37:50.386183  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:37:50.386183  6908 net.cpp:84] Creating Layer pool3
I0530 14:37:50.386183  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:37:50.386183  6908 net.cpp:380] pool3 -> pool3
I0530 14:37:50.386183  6908 net.cpp:122] Setting up pool3
I0530 14:37:50.386183  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:37:50.386183  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:37:50.386183  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:37:50.386183  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:37:50.386183  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:37:50.386183  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:37:50.387182  6908 net.cpp:122] Setting up conv4_1
I0530 14:37:50.387182  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:37:50.387182  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:37:50.387182  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:37:50.387182  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:37:50.387182  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:37:50.387182  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:37:50.387182  6908 net.cpp:122] Setting up relu4_1
I0530 14:37:50.387182  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:37:50.387182  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:37:50.387182  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:37:50.387182  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:37:50.387182  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:37:50.387182  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:37:50.391186  6908 net.cpp:122] Setting up conv4_2
I0530 14:37:50.391186  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:37:50.391186  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:37:50.391186  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:37:50.391186  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:37:50.391186  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:37:50.391186  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:37:50.391186  6908 net.cpp:122] Setting up relu4_2
I0530 14:37:50.391186  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:37:50.391186  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:37:50.391186  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:37:50.391186  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:37:50.391186  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:37:50.391186  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:37:50.394656  6908 net.cpp:122] Setting up conv4_3
I0530 14:37:50.394656  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:37:50.394656  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:37:50.394656  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:37:50.394656  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:37:50.394656  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:37:50.394656  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:37:50.394656  6908 net.cpp:122] Setting up relu4_3
I0530 14:37:50.394656  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:37:50.394656  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:37:50.394656  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:37:50.394656  6908 net.cpp:84] Creating Layer pool4
I0530 14:37:50.394656  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:37:50.394656  6908 net.cpp:380] pool4 -> pool4
I0530 14:37:50.394656  6908 net.cpp:122] Setting up pool4
I0530 14:37:50.394656  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:37:50.394656  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:37:50.394656  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:37:50.394656  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:37:50.394656  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:37:50.394656  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:37:50.398691  6908 net.cpp:122] Setting up conv5_1
I0530 14:37:50.398691  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:37:50.398691  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:37:50.398691  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:37:50.398691  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:37:50.398691  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:37:50.398691  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:37:50.398691  6908 net.cpp:122] Setting up relu5_1
I0530 14:37:50.398691  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:37:50.398691  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:37:50.398691  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:37:50.398691  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:37:50.398691  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:37:50.398691  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:37:50.402160  6908 net.cpp:122] Setting up conv5_2
I0530 14:37:50.402160  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:37:50.402160  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:37:50.402160  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:37:50.402160  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:37:50.402160  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:37:50.402160  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:37:50.402160  6908 net.cpp:122] Setting up relu5_2
I0530 14:37:50.402160  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:37:50.402160  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:37:50.402160  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:37:50.402160  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:37:50.402160  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:37:50.402160  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:37:50.406160  6908 net.cpp:122] Setting up conv5_3
I0530 14:37:50.406160  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:37:50.406160  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:37:50.406160  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:37:50.406160  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:37:50.406160  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:37:50.406160  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:37:50.406160  6908 net.cpp:122] Setting up relu5_3
I0530 14:37:50.406160  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:37:50.406160  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:37:50.406160  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:37:50.406160  6908 net.cpp:84] Creating Layer pool5
I0530 14:37:50.406160  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:37:50.406160  6908 net.cpp:380] pool5 -> pool5
I0530 14:37:50.406160  6908 net.cpp:122] Setting up pool5
I0530 14:37:50.406160  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:37:50.406160  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:37:50.406160  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:37:50.406160  6908 net.cpp:84] Creating Layer drop6
I0530 14:37:50.406160  6908 net.cpp:406] drop6 <- pool5
I0530 14:37:50.406160  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:37:50.406160  6908 net.cpp:122] Setting up drop6
I0530 14:37:50.406160  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:37:50.406160  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:37:50.406160  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:37:50.406160  6908 net.cpp:84] Creating Layer fc6
I0530 14:37:50.406160  6908 net.cpp:406] fc6 <- pool5
I0530 14:37:50.406160  6908 net.cpp:380] fc6 -> fc6
I0530 14:37:50.409160  6908 net.cpp:122] Setting up fc6
I0530 14:37:50.409160  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:37:50.409160  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:37:50.409160  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:37:50.410161  6908 net.cpp:84] Creating Layer relu6
I0530 14:37:50.410161  6908 net.cpp:406] relu6 <- fc6
I0530 14:37:50.410161  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:37:50.410161  6908 net.cpp:122] Setting up relu6
I0530 14:37:50.410161  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:37:50.410161  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:37:50.410161  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:37:50.410161  6908 net.cpp:84] Creating Layer fc7
I0530 14:37:50.410161  6908 net.cpp:406] fc7 <- fc6
I0530 14:37:50.410161  6908 net.cpp:380] fc7 -> fc7
I0530 14:37:50.410161  6908 net.cpp:122] Setting up fc7
I0530 14:37:50.410161  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:37:50.410161  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:37:50.410161  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:37:50.410161  6908 net.cpp:84] Creating Layer prob
I0530 14:37:50.410161  6908 net.cpp:406] prob <- fc7
I0530 14:37:50.410161  6908 net.cpp:380] prob -> prob
I0530 14:37:50.410161  6908 net.cpp:122] Setting up prob
I0530 14:37:50.410161  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:37:50.410161  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:37:50.410161  6908 net.cpp:200] prob does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:200] input does not need backward computation.
I0530 14:37:50.410161  6908 net.cpp:242] This network produces output prob
I0530 14:37:50.410161  6908 net.cpp:255] Network initialization done.
I0530 14:37:50.429153  6908 net.cpp:744] Ignoring source layer data
I0530 14:37:50.432153  6908 net.cpp:744] Ignoring source layer loss
I0530 14:38:16.370852  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:38:16.370852  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:38:16.370852  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:38:16.370852  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:38:16.370852  6908 layer_factory.hpp:77] Creating layer input
I0530 14:38:16.370852  6908 net.cpp:84] Creating Layer input
I0530 14:38:16.370852  6908 net.cpp:380] input -> data
I0530 14:38:16.371852  6908 net.cpp:122] Setting up input
I0530 14:38:16.371852  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:38:16.371852  6908 net.cpp:137] Memory required for data: 16384
I0530 14:38:16.371852  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:38:16.371852  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:38:16.371852  6908 net.cpp:406] conv1_1 <- data
I0530 14:38:16.371852  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:38:16.373854  6908 net.cpp:122] Setting up conv1_1
I0530 14:38:16.373854  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:38:16.373854  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:38:16.373854  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:38:16.373854  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:38:16.373854  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:38:16.373854  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:38:16.373854  6908 net.cpp:122] Setting up relu1_1
I0530 14:38:16.373854  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:38:16.373854  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:38:16.373854  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:38:16.373854  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:38:16.373854  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:38:16.373854  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:38:16.374860  6908 net.cpp:122] Setting up conv1_2
I0530 14:38:16.374860  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:38:16.374860  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:38:16.374860  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:38:16.374860  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:38:16.374860  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:38:16.374860  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:38:16.374860  6908 net.cpp:122] Setting up relu1_2
I0530 14:38:16.374860  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:38:16.374860  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:38:16.374860  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:38:16.374860  6908 net.cpp:84] Creating Layer pool1
I0530 14:38:16.374860  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:38:16.374860  6908 net.cpp:380] pool1 -> pool1
I0530 14:38:16.374860  6908 net.cpp:122] Setting up pool1
I0530 14:38:16.374860  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:38:16.374860  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:38:16.374860  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:38:16.374860  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:38:16.374860  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:38:16.374860  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:38:16.375852  6908 net.cpp:122] Setting up conv2_1
I0530 14:38:16.375852  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:38:16.375852  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:38:16.375852  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:38:16.375852  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:38:16.375852  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:38:16.375852  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:38:16.375852  6908 net.cpp:122] Setting up relu2_1
I0530 14:38:16.375852  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:38:16.375852  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:38:16.375852  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:38:16.375852  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:38:16.375852  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:38:16.375852  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:38:16.375852  6908 net.cpp:122] Setting up conv2_2
I0530 14:38:16.375852  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:38:16.375852  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:38:16.375852  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:38:16.375852  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:38:16.375852  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:38:16.375852  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:38:16.375852  6908 net.cpp:122] Setting up relu2_2
I0530 14:38:16.375852  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:38:16.375852  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:38:16.375852  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:38:16.375852  6908 net.cpp:84] Creating Layer pool2
I0530 14:38:16.375852  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:38:16.375852  6908 net.cpp:380] pool2 -> pool2
I0530 14:38:16.375852  6908 net.cpp:122] Setting up pool2
I0530 14:38:16.375852  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:16.375852  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:38:16.375852  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:38:16.375852  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:38:16.375852  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:38:16.375852  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:38:16.376852  6908 net.cpp:122] Setting up conv3_1
I0530 14:38:16.376852  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:16.376852  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:38:16.376852  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:38:16.376852  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:38:16.376852  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:38:16.376852  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:38:16.376852  6908 net.cpp:122] Setting up relu3_1
I0530 14:38:16.376852  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:16.376852  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:38:16.376852  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:38:16.376852  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:38:16.376852  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:38:16.376852  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:38:16.377851  6908 net.cpp:122] Setting up conv3_2
I0530 14:38:16.377851  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:16.377851  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:38:16.377851  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:38:16.377851  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:38:16.377851  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:38:16.377851  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:38:16.377851  6908 net.cpp:122] Setting up relu3_2
I0530 14:38:16.377851  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:16.377851  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:38:16.377851  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:38:16.377851  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:38:16.377851  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:38:16.377851  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:38:16.379858  6908 net.cpp:122] Setting up conv3_3
I0530 14:38:16.379858  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:16.379858  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:38:16.379858  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:38:16.379858  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:38:16.379858  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:38:16.379858  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:38:16.379858  6908 net.cpp:122] Setting up relu3_3
I0530 14:38:16.379858  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:16.379858  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:38:16.379858  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:38:16.379858  6908 net.cpp:84] Creating Layer pool3
I0530 14:38:16.379858  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:38:16.379858  6908 net.cpp:380] pool3 -> pool3
I0530 14:38:16.379858  6908 net.cpp:122] Setting up pool3
I0530 14:38:16.379858  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:38:16.379858  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:38:16.379858  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:38:16.379858  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:38:16.379858  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:38:16.379858  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:38:16.381860  6908 net.cpp:122] Setting up conv4_1
I0530 14:38:16.381860  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:16.381860  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:38:16.381860  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:38:16.381860  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:38:16.381860  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:38:16.381860  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:38:16.381860  6908 net.cpp:122] Setting up relu4_1
I0530 14:38:16.381860  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:16.381860  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:38:16.381860  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:38:16.381860  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:38:16.381860  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:38:16.381860  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:38:16.384861  6908 net.cpp:122] Setting up conv4_2
I0530 14:38:16.384861  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:16.384861  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:38:16.384861  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:38:16.384861  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:38:16.384861  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:38:16.384861  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:38:16.384861  6908 net.cpp:122] Setting up relu4_2
I0530 14:38:16.384861  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:16.384861  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:38:16.384861  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:38:16.384861  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:38:16.384861  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:38:16.384861  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:38:16.388861  6908 net.cpp:122] Setting up conv4_3
I0530 14:38:16.388861  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:16.388861  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:38:16.388861  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:38:16.388861  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:38:16.388861  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:38:16.388861  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:38:16.388861  6908 net.cpp:122] Setting up relu4_3
I0530 14:38:16.388861  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:16.388861  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:38:16.388861  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:38:16.388861  6908 net.cpp:84] Creating Layer pool4
I0530 14:38:16.388861  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:38:16.388861  6908 net.cpp:380] pool4 -> pool4
I0530 14:38:16.388861  6908 net.cpp:122] Setting up pool4
I0530 14:38:16.388861  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:16.388861  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:38:16.388861  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:38:16.388861  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:38:16.388861  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:38:16.388861  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:38:16.392860  6908 net.cpp:122] Setting up conv5_1
I0530 14:38:16.392860  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:16.392860  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:38:16.392860  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:38:16.392860  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:38:16.392860  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:38:16.392860  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:38:16.392860  6908 net.cpp:122] Setting up relu5_1
I0530 14:38:16.392860  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:16.392860  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:38:16.392860  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:38:16.392860  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:38:16.392860  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:38:16.392860  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:38:16.396860  6908 net.cpp:122] Setting up conv5_2
I0530 14:38:16.396860  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:16.396860  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:38:16.396860  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:38:16.396860  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:38:16.396860  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:38:16.396860  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:38:16.396860  6908 net.cpp:122] Setting up relu5_2
I0530 14:38:16.396860  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:16.396860  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:38:16.396860  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:38:16.396860  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:38:16.396860  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:38:16.396860  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:38:16.399862  6908 net.cpp:122] Setting up conv5_3
I0530 14:38:16.399862  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:16.399862  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:38:16.399862  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:38:16.399862  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:38:16.399862  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:38:16.399862  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:38:16.399862  6908 net.cpp:122] Setting up relu5_3
I0530 14:38:16.399862  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:16.399862  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:38:16.399862  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:38:16.399862  6908 net.cpp:84] Creating Layer pool5
I0530 14:38:16.399862  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:38:16.399862  6908 net.cpp:380] pool5 -> pool5
I0530 14:38:16.399862  6908 net.cpp:122] Setting up pool5
I0530 14:38:16.399862  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:38:16.399862  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:38:16.399862  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:38:16.399862  6908 net.cpp:84] Creating Layer drop6
I0530 14:38:16.399862  6908 net.cpp:406] drop6 <- pool5
I0530 14:38:16.399862  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:38:16.399862  6908 net.cpp:122] Setting up drop6
I0530 14:38:16.399862  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:38:16.399862  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:38:16.399862  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:38:16.399862  6908 net.cpp:84] Creating Layer fc6
I0530 14:38:16.399862  6908 net.cpp:406] fc6 <- pool5
I0530 14:38:16.399862  6908 net.cpp:380] fc6 -> fc6
I0530 14:38:16.403861  6908 net.cpp:122] Setting up fc6
I0530 14:38:16.403861  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:38:16.403861  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:38:16.403861  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:38:16.403861  6908 net.cpp:84] Creating Layer relu6
I0530 14:38:16.403861  6908 net.cpp:406] relu6 <- fc6
I0530 14:38:16.403861  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:38:16.403861  6908 net.cpp:122] Setting up relu6
I0530 14:38:16.403861  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:38:16.403861  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:38:16.403861  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:38:16.403861  6908 net.cpp:84] Creating Layer fc7
I0530 14:38:16.403861  6908 net.cpp:406] fc7 <- fc6
I0530 14:38:16.403861  6908 net.cpp:380] fc7 -> fc7
I0530 14:38:16.403861  6908 net.cpp:122] Setting up fc7
I0530 14:38:16.403861  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:38:16.403861  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:38:16.403861  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:38:16.403861  6908 net.cpp:84] Creating Layer prob
I0530 14:38:16.403861  6908 net.cpp:406] prob <- fc7
I0530 14:38:16.403861  6908 net.cpp:380] prob -> prob
I0530 14:38:16.403861  6908 net.cpp:122] Setting up prob
I0530 14:38:16.403861  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:38:16.403861  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:38:16.403861  6908 net.cpp:200] prob does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:200] input does not need backward computation.
I0530 14:38:16.403861  6908 net.cpp:242] This network produces output prob
I0530 14:38:16.403861  6908 net.cpp:255] Network initialization done.
I0530 14:38:16.422830  6908 net.cpp:744] Ignoring source layer data
I0530 14:38:16.425829  6908 net.cpp:744] Ignoring source layer loss
I0530 14:38:47.906105  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:38:47.906105  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:38:47.906105  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:38:47.907088  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:38:47.907088  6908 layer_factory.hpp:77] Creating layer input
I0530 14:38:47.907088  6908 net.cpp:84] Creating Layer input
I0530 14:38:47.907088  6908 net.cpp:380] input -> data
I0530 14:38:47.908226  6908 net.cpp:122] Setting up input
I0530 14:38:47.908226  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:38:47.908226  6908 net.cpp:137] Memory required for data: 16384
I0530 14:38:47.908226  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:38:47.908226  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:38:47.908226  6908 net.cpp:406] conv1_1 <- data
I0530 14:38:47.908226  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:38:47.910502  6908 net.cpp:122] Setting up conv1_1
I0530 14:38:47.910502  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:38:47.910502  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:38:47.910502  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:38:47.910502  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:38:47.910502  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:38:47.910502  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:38:47.910502  6908 net.cpp:122] Setting up relu1_1
I0530 14:38:47.910502  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:38:47.910502  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:38:47.910502  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:38:47.910502  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:38:47.910502  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:38:47.910502  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:38:47.911419  6908 net.cpp:122] Setting up conv1_2
I0530 14:38:47.911419  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:38:47.911419  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:38:47.911419  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:38:47.911419  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:38:47.911419  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:38:47.911419  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:38:47.911419  6908 net.cpp:122] Setting up relu1_2
I0530 14:38:47.911419  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:38:47.911419  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:38:47.911419  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:38:47.911419  6908 net.cpp:84] Creating Layer pool1
I0530 14:38:47.911419  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:38:47.911419  6908 net.cpp:380] pool1 -> pool1
I0530 14:38:47.911419  6908 net.cpp:122] Setting up pool1
I0530 14:38:47.911419  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:38:47.911419  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:38:47.911419  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:38:47.911419  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:38:47.911419  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:38:47.911419  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:38:47.912446  6908 net.cpp:122] Setting up conv2_1
I0530 14:38:47.912446  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:38:47.912446  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:38:47.912446  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:38:47.912446  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:38:47.912446  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:38:47.912446  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:38:47.912446  6908 net.cpp:122] Setting up relu2_1
I0530 14:38:47.912446  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:38:47.912446  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:38:47.912446  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:38:47.912446  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:38:47.912446  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:38:47.912446  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:38:47.913446  6908 net.cpp:122] Setting up conv2_2
I0530 14:38:47.913446  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:38:47.913446  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:38:47.913446  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:38:47.913446  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:38:47.913446  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:38:47.913446  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:38:47.913446  6908 net.cpp:122] Setting up relu2_2
I0530 14:38:47.913446  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:38:47.913446  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:38:47.913446  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:38:47.913446  6908 net.cpp:84] Creating Layer pool2
I0530 14:38:47.913446  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:38:47.913446  6908 net.cpp:380] pool2 -> pool2
I0530 14:38:47.913446  6908 net.cpp:122] Setting up pool2
I0530 14:38:47.913446  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:47.913446  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:38:47.913446  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:38:47.913446  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:38:47.913446  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:38:47.913446  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:38:47.914444  6908 net.cpp:122] Setting up conv3_1
I0530 14:38:47.914444  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:47.914444  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:38:47.914444  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:38:47.914444  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:38:47.914444  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:38:47.914444  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:38:47.914444  6908 net.cpp:122] Setting up relu3_1
I0530 14:38:47.914444  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:47.914444  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:38:47.914444  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:38:47.914444  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:38:47.914444  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:38:47.914444  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:38:47.914444  6908 net.cpp:122] Setting up conv3_2
I0530 14:38:47.914444  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:47.914444  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:38:47.914444  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:38:47.914444  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:38:47.914444  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:38:47.915444  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:38:47.915444  6908 net.cpp:122] Setting up relu3_2
I0530 14:38:47.915444  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:47.915444  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:38:47.915444  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:38:47.915444  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:38:47.915444  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:38:47.915444  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:38:47.916419  6908 net.cpp:122] Setting up conv3_3
I0530 14:38:47.916419  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:47.916419  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:38:47.916419  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:38:47.916419  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:38:47.916419  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:38:47.916419  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:38:47.916419  6908 net.cpp:122] Setting up relu3_3
I0530 14:38:47.916419  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:38:47.916419  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:38:47.916419  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:38:47.916419  6908 net.cpp:84] Creating Layer pool3
I0530 14:38:47.916419  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:38:47.916419  6908 net.cpp:380] pool3 -> pool3
I0530 14:38:47.916419  6908 net.cpp:122] Setting up pool3
I0530 14:38:47.916419  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:38:47.916419  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:38:47.916419  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:38:47.916419  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:38:47.916419  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:38:47.916419  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:38:47.918443  6908 net.cpp:122] Setting up conv4_1
I0530 14:38:47.918443  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:47.918443  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:38:47.918443  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:38:47.918443  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:38:47.918443  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:38:47.918443  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:38:47.918443  6908 net.cpp:122] Setting up relu4_1
I0530 14:38:47.918443  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:47.918443  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:38:47.918443  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:38:47.918443  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:38:47.918443  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:38:47.918443  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:38:47.922439  6908 net.cpp:122] Setting up conv4_2
I0530 14:38:47.922439  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:47.922439  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:38:47.922439  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:38:47.922439  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:38:47.922439  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:38:47.922439  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:38:47.922439  6908 net.cpp:122] Setting up relu4_2
I0530 14:38:47.922439  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:47.922439  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:38:47.922439  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:38:47.922439  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:38:47.922439  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:38:47.922439  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:38:47.925417  6908 net.cpp:122] Setting up conv4_3
I0530 14:38:47.925417  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:47.925417  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:38:47.925417  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:38:47.925417  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:38:47.925417  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:38:47.925417  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:38:47.925417  6908 net.cpp:122] Setting up relu4_3
I0530 14:38:47.925417  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:38:47.925417  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:38:47.925417  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:38:47.925417  6908 net.cpp:84] Creating Layer pool4
I0530 14:38:47.925417  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:38:47.925417  6908 net.cpp:380] pool4 -> pool4
I0530 14:38:47.925417  6908 net.cpp:122] Setting up pool4
I0530 14:38:47.925417  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:47.925417  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:38:47.925417  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:38:47.925417  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:38:47.925417  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:38:47.925417  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:38:47.929900  6908 net.cpp:122] Setting up conv5_1
I0530 14:38:47.929900  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:47.929900  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:38:47.929900  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:38:47.929900  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:38:47.929900  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:38:47.929900  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:38:47.929900  6908 net.cpp:122] Setting up relu5_1
I0530 14:38:47.929900  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:47.929900  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:38:47.929900  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:38:47.929900  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:38:47.929900  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:38:47.929900  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:38:47.933900  6908 net.cpp:122] Setting up conv5_2
I0530 14:38:47.933900  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:47.933900  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:38:47.933900  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:38:47.933900  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:38:47.933900  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:38:47.933900  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:38:47.933900  6908 net.cpp:122] Setting up relu5_2
I0530 14:38:47.933900  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:47.933900  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:38:47.933900  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:38:47.933900  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:38:47.933900  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:38:47.933900  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:38:47.936991  6908 net.cpp:122] Setting up conv5_3
I0530 14:38:47.936991  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:47.936991  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:38:47.936991  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:38:47.936991  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:38:47.936991  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:38:47.936991  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:38:47.936991  6908 net.cpp:122] Setting up relu5_3
I0530 14:38:47.936991  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:38:47.936991  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:38:47.936991  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:38:47.936991  6908 net.cpp:84] Creating Layer pool5
I0530 14:38:47.936991  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:38:47.936991  6908 net.cpp:380] pool5 -> pool5
I0530 14:38:47.936991  6908 net.cpp:122] Setting up pool5
I0530 14:38:47.936991  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:38:47.936991  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:38:47.936991  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:38:47.936991  6908 net.cpp:84] Creating Layer drop6
I0530 14:38:47.936991  6908 net.cpp:406] drop6 <- pool5
I0530 14:38:47.936991  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:38:47.936991  6908 net.cpp:122] Setting up drop6
I0530 14:38:47.936991  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:38:47.936991  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:38:47.936991  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:38:47.937993  6908 net.cpp:84] Creating Layer fc6
I0530 14:38:47.937993  6908 net.cpp:406] fc6 <- pool5
I0530 14:38:47.937993  6908 net.cpp:380] fc6 -> fc6
I0530 14:38:47.940991  6908 net.cpp:122] Setting up fc6
I0530 14:38:47.940991  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:38:47.940991  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:38:47.940991  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:38:47.940991  6908 net.cpp:84] Creating Layer relu6
I0530 14:38:47.940991  6908 net.cpp:406] relu6 <- fc6
I0530 14:38:47.940991  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:38:47.940991  6908 net.cpp:122] Setting up relu6
I0530 14:38:47.940991  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:38:47.940991  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:38:47.940991  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:38:47.940991  6908 net.cpp:84] Creating Layer fc7
I0530 14:38:47.940991  6908 net.cpp:406] fc7 <- fc6
I0530 14:38:47.940991  6908 net.cpp:380] fc7 -> fc7
I0530 14:38:47.940991  6908 net.cpp:122] Setting up fc7
I0530 14:38:47.940991  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:38:47.940991  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:38:47.940991  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:38:47.940991  6908 net.cpp:84] Creating Layer prob
I0530 14:38:47.940991  6908 net.cpp:406] prob <- fc7
I0530 14:38:47.940991  6908 net.cpp:380] prob -> prob
I0530 14:38:47.940991  6908 net.cpp:122] Setting up prob
I0530 14:38:47.940991  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:38:47.940991  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:38:47.940991  6908 net.cpp:200] prob does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:200] input does not need backward computation.
I0530 14:38:47.940991  6908 net.cpp:242] This network produces output prob
I0530 14:38:47.940991  6908 net.cpp:255] Network initialization done.
I0530 14:38:47.959992  6908 net.cpp:744] Ignoring source layer data
I0530 14:38:47.961992  6908 net.cpp:744] Ignoring source layer loss
I0530 14:39:30.202736  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:39:30.202736  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:39:30.202736  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:39:30.202736  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:39:30.202736  6908 layer_factory.hpp:77] Creating layer input
I0530 14:39:30.202736  6908 net.cpp:84] Creating Layer input
I0530 14:39:30.202736  6908 net.cpp:380] input -> data
I0530 14:39:30.203739  6908 net.cpp:122] Setting up input
I0530 14:39:30.203739  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:39:30.203739  6908 net.cpp:137] Memory required for data: 16384
I0530 14:39:30.203739  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:39:30.203739  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:39:30.203739  6908 net.cpp:406] conv1_1 <- data
I0530 14:39:30.203739  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:39:30.205736  6908 net.cpp:122] Setting up conv1_1
I0530 14:39:30.205736  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:39:30.205736  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:39:30.205736  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:39:30.205736  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:39:30.205736  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:39:30.205736  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:39:30.205736  6908 net.cpp:122] Setting up relu1_1
I0530 14:39:30.205736  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:39:30.205736  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:39:30.205736  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:39:30.205736  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:39:30.205736  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:39:30.205736  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:39:30.206737  6908 net.cpp:122] Setting up conv1_2
I0530 14:39:30.206737  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:39:30.206737  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:39:30.206737  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:39:30.206737  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:39:30.206737  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:39:30.206737  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:39:30.206737  6908 net.cpp:122] Setting up relu1_2
I0530 14:39:30.206737  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:39:30.206737  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:39:30.206737  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:39:30.206737  6908 net.cpp:84] Creating Layer pool1
I0530 14:39:30.206737  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:39:30.206737  6908 net.cpp:380] pool1 -> pool1
I0530 14:39:30.206737  6908 net.cpp:122] Setting up pool1
I0530 14:39:30.206737  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:39:30.206737  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:39:30.206737  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:39:30.206737  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:39:30.206737  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:39:30.206737  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:39:30.207736  6908 net.cpp:122] Setting up conv2_1
I0530 14:39:30.207736  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:39:30.207736  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:39:30.207736  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:39:30.207736  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:39:30.207736  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:39:30.207736  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:39:30.207736  6908 net.cpp:122] Setting up relu2_1
I0530 14:39:30.207736  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:39:30.207736  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:39:30.207736  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:39:30.207736  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:39:30.207736  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:39:30.207736  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:39:30.207736  6908 net.cpp:122] Setting up conv2_2
I0530 14:39:30.207736  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:39:30.207736  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:39:30.207736  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:39:30.207736  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:39:30.207736  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:39:30.207736  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:39:30.207736  6908 net.cpp:122] Setting up relu2_2
I0530 14:39:30.207736  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:39:30.207736  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:39:30.207736  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:39:30.207736  6908 net.cpp:84] Creating Layer pool2
I0530 14:39:30.207736  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:39:30.207736  6908 net.cpp:380] pool2 -> pool2
I0530 14:39:30.207736  6908 net.cpp:122] Setting up pool2
I0530 14:39:30.207736  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:39:30.207736  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:39:30.207736  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:39:30.207736  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:39:30.207736  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:39:30.207736  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:39:30.208741  6908 net.cpp:122] Setting up conv3_1
I0530 14:39:30.208741  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:39:30.208741  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:39:30.208741  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:39:30.208741  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:39:30.208741  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:39:30.208741  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:39:30.208741  6908 net.cpp:122] Setting up relu3_1
I0530 14:39:30.208741  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:39:30.208741  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:39:30.208741  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:39:30.208741  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:39:30.208741  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:39:30.208741  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:39:30.209741  6908 net.cpp:122] Setting up conv3_2
I0530 14:39:30.209741  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:39:30.209741  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:39:30.209741  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:39:30.209741  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:39:30.209741  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:39:30.209741  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:39:30.209741  6908 net.cpp:122] Setting up relu3_2
I0530 14:39:30.209741  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:39:30.209741  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:39:30.209741  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:39:30.209741  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:39:30.209741  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:39:30.209741  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:39:30.211741  6908 net.cpp:122] Setting up conv3_3
I0530 14:39:30.211741  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:39:30.211741  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:39:30.211741  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:39:30.211741  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:39:30.211741  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:39:30.211741  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:39:30.211741  6908 net.cpp:122] Setting up relu3_3
I0530 14:39:30.211741  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:39:30.211741  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:39:30.211741  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:39:30.211741  6908 net.cpp:84] Creating Layer pool3
I0530 14:39:30.211741  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:39:30.211741  6908 net.cpp:380] pool3 -> pool3
I0530 14:39:30.211741  6908 net.cpp:122] Setting up pool3
I0530 14:39:30.211741  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:39:30.211741  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:39:30.211741  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:39:30.211741  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:39:30.211741  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:39:30.211741  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:39:30.212741  6908 net.cpp:122] Setting up conv4_1
I0530 14:39:30.212741  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:39:30.212741  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:39:30.212741  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:39:30.212741  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:39:30.212741  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:39:30.212741  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:39:30.212741  6908 net.cpp:122] Setting up relu4_1
I0530 14:39:30.212741  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:39:30.212741  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:39:30.212741  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:39:30.212741  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:39:30.212741  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:39:30.212741  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:39:30.216747  6908 net.cpp:122] Setting up conv4_2
I0530 14:39:30.216747  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:39:30.216747  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:39:30.216747  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:39:30.216747  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:39:30.216747  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:39:30.216747  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:39:30.216747  6908 net.cpp:122] Setting up relu4_2
I0530 14:39:30.216747  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:39:30.216747  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:39:30.216747  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:39:30.216747  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:39:30.216747  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:39:30.216747  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:39:30.220746  6908 net.cpp:122] Setting up conv4_3
I0530 14:39:30.220746  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:39:30.220746  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:39:30.220746  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:39:30.220746  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:39:30.220746  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:39:30.220746  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:39:30.220746  6908 net.cpp:122] Setting up relu4_3
I0530 14:39:30.220746  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:39:30.220746  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:39:30.220746  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:39:30.220746  6908 net.cpp:84] Creating Layer pool4
I0530 14:39:30.220746  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:39:30.220746  6908 net.cpp:380] pool4 -> pool4
I0530 14:39:30.220746  6908 net.cpp:122] Setting up pool4
I0530 14:39:30.220746  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:39:30.220746  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:39:30.220746  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:39:30.220746  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:39:30.220746  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:39:30.220746  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:39:30.224747  6908 net.cpp:122] Setting up conv5_1
I0530 14:39:30.224747  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:39:30.224747  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:39:30.224747  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:39:30.224747  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:39:30.224747  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:39:30.224747  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:39:30.224747  6908 net.cpp:122] Setting up relu5_1
I0530 14:39:30.224747  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:39:30.224747  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:39:30.224747  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:39:30.224747  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:39:30.224747  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:39:30.224747  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:39:30.227746  6908 net.cpp:122] Setting up conv5_2
I0530 14:39:30.227746  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:39:30.227746  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:39:30.227746  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:39:30.227746  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:39:30.227746  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:39:30.227746  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:39:30.227746  6908 net.cpp:122] Setting up relu5_2
I0530 14:39:30.227746  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:39:30.227746  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:39:30.227746  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:39:30.227746  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:39:30.227746  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:39:30.227746  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:39:30.231750  6908 net.cpp:122] Setting up conv5_3
I0530 14:39:30.231750  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:39:30.231750  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:39:30.231750  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:39:30.231750  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:39:30.231750  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:39:30.231750  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:39:30.231750  6908 net.cpp:122] Setting up relu5_3
I0530 14:39:30.231750  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:39:30.231750  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:39:30.231750  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:39:30.231750  6908 net.cpp:84] Creating Layer pool5
I0530 14:39:30.231750  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:39:30.231750  6908 net.cpp:380] pool5 -> pool5
I0530 14:39:30.231750  6908 net.cpp:122] Setting up pool5
I0530 14:39:30.231750  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:39:30.231750  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:39:30.231750  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:39:30.231750  6908 net.cpp:84] Creating Layer drop6
I0530 14:39:30.231750  6908 net.cpp:406] drop6 <- pool5
I0530 14:39:30.231750  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:39:30.231750  6908 net.cpp:122] Setting up drop6
I0530 14:39:30.231750  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:39:30.231750  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:39:30.231750  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:39:30.231750  6908 net.cpp:84] Creating Layer fc6
I0530 14:39:30.231750  6908 net.cpp:406] fc6 <- pool5
I0530 14:39:30.231750  6908 net.cpp:380] fc6 -> fc6
I0530 14:39:30.235746  6908 net.cpp:122] Setting up fc6
I0530 14:39:30.235746  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:39:30.235746  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:39:30.235746  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:39:30.235746  6908 net.cpp:84] Creating Layer relu6
I0530 14:39:30.235746  6908 net.cpp:406] relu6 <- fc6
I0530 14:39:30.235746  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:39:30.235746  6908 net.cpp:122] Setting up relu6
I0530 14:39:30.235746  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:39:30.235746  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:39:30.235746  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:39:30.235746  6908 net.cpp:84] Creating Layer fc7
I0530 14:39:30.235746  6908 net.cpp:406] fc7 <- fc6
I0530 14:39:30.235746  6908 net.cpp:380] fc7 -> fc7
I0530 14:39:30.235746  6908 net.cpp:122] Setting up fc7
I0530 14:39:30.235746  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:39:30.235746  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:39:30.235746  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:39:30.235746  6908 net.cpp:84] Creating Layer prob
I0530 14:39:30.235746  6908 net.cpp:406] prob <- fc7
I0530 14:39:30.235746  6908 net.cpp:380] prob -> prob
I0530 14:39:30.235746  6908 net.cpp:122] Setting up prob
I0530 14:39:30.235746  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:39:30.235746  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:39:30.235746  6908 net.cpp:200] prob does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:200] input does not need backward computation.
I0530 14:39:30.235746  6908 net.cpp:242] This network produces output prob
I0530 14:39:30.235746  6908 net.cpp:255] Network initialization done.
I0530 14:39:30.254745  6908 net.cpp:744] Ignoring source layer data
I0530 14:39:30.256742  6908 net.cpp:744] Ignoring source layer loss
I0530 14:40:15.606784  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:40:15.606784  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:40:15.606784  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:40:15.606784  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:40:15.606784  6908 layer_factory.hpp:77] Creating layer input
I0530 14:40:15.606784  6908 net.cpp:84] Creating Layer input
I0530 14:40:15.606784  6908 net.cpp:380] input -> data
I0530 14:40:15.607944  6908 net.cpp:122] Setting up input
I0530 14:40:15.607944  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:40:15.607944  6908 net.cpp:137] Memory required for data: 16384
I0530 14:40:15.607944  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:40:15.607944  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:40:15.607944  6908 net.cpp:406] conv1_1 <- data
I0530 14:40:15.607944  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:40:15.608947  6908 net.cpp:122] Setting up conv1_1
I0530 14:40:15.608947  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:40:15.608947  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:40:15.608947  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:40:15.608947  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:40:15.608947  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:40:15.608947  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:40:15.608947  6908 net.cpp:122] Setting up relu1_1
I0530 14:40:15.608947  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:40:15.608947  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:40:15.608947  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:40:15.608947  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:40:15.608947  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:40:15.608947  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:40:15.609947  6908 net.cpp:122] Setting up conv1_2
I0530 14:40:15.610947  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:40:15.610947  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:40:15.610947  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:40:15.610947  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:40:15.610947  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:40:15.610947  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:40:15.610947  6908 net.cpp:122] Setting up relu1_2
I0530 14:40:15.610947  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:40:15.610947  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:40:15.610947  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:40:15.610947  6908 net.cpp:84] Creating Layer pool1
I0530 14:40:15.610947  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:40:15.610947  6908 net.cpp:380] pool1 -> pool1
I0530 14:40:15.610947  6908 net.cpp:122] Setting up pool1
I0530 14:40:15.610947  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:40:15.610947  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:40:15.610947  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:40:15.610947  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:40:15.610947  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:40:15.610947  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:40:15.610947  6908 net.cpp:122] Setting up conv2_1
I0530 14:40:15.610947  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:40:15.610947  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:40:15.610947  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:40:15.610947  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:40:15.610947  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:40:15.610947  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:40:15.610947  6908 net.cpp:122] Setting up relu2_1
I0530 14:40:15.610947  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:40:15.610947  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:40:15.610947  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:40:15.610947  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:40:15.610947  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:40:15.610947  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:40:15.611946  6908 net.cpp:122] Setting up conv2_2
I0530 14:40:15.611946  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:40:15.611946  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:40:15.611946  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:40:15.611946  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:40:15.611946  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:40:15.611946  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:40:15.611946  6908 net.cpp:122] Setting up relu2_2
I0530 14:40:15.611946  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:40:15.611946  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:40:15.611946  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:40:15.611946  6908 net.cpp:84] Creating Layer pool2
I0530 14:40:15.611946  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:40:15.611946  6908 net.cpp:380] pool2 -> pool2
I0530 14:40:15.611946  6908 net.cpp:122] Setting up pool2
I0530 14:40:15.611946  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:40:15.611946  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:40:15.611946  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:40:15.611946  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:40:15.611946  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:40:15.611946  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:40:15.612947  6908 net.cpp:122] Setting up conv3_1
I0530 14:40:15.612947  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:40:15.612947  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:40:15.612947  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:40:15.612947  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:40:15.612947  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:40:15.612947  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:40:15.612947  6908 net.cpp:122] Setting up relu3_1
I0530 14:40:15.612947  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:40:15.612947  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:40:15.612947  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:40:15.612947  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:40:15.612947  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:40:15.612947  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:40:15.612947  6908 net.cpp:122] Setting up conv3_2
I0530 14:40:15.612947  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:40:15.612947  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:40:15.612947  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:40:15.612947  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:40:15.612947  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:40:15.612947  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:40:15.612947  6908 net.cpp:122] Setting up relu3_2
I0530 14:40:15.612947  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:40:15.612947  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:40:15.612947  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:40:15.613946  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:40:15.613946  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:40:15.613946  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:40:15.614948  6908 net.cpp:122] Setting up conv3_3
I0530 14:40:15.614948  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:40:15.614948  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:40:15.614948  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:40:15.614948  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:40:15.614948  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:40:15.614948  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:40:15.614948  6908 net.cpp:122] Setting up relu3_3
I0530 14:40:15.614948  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:40:15.614948  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:40:15.614948  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:40:15.614948  6908 net.cpp:84] Creating Layer pool3
I0530 14:40:15.614948  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:40:15.614948  6908 net.cpp:380] pool3 -> pool3
I0530 14:40:15.614948  6908 net.cpp:122] Setting up pool3
I0530 14:40:15.614948  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:40:15.614948  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:40:15.614948  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:40:15.614948  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:40:15.614948  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:40:15.614948  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:40:15.616946  6908 net.cpp:122] Setting up conv4_1
I0530 14:40:15.616946  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:40:15.616946  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:40:15.616946  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:40:15.616946  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:40:15.616946  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:40:15.616946  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:40:15.616946  6908 net.cpp:122] Setting up relu4_1
I0530 14:40:15.616946  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:40:15.616946  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:40:15.616946  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:40:15.616946  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:40:15.616946  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:40:15.616946  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:40:15.619978  6908 net.cpp:122] Setting up conv4_2
I0530 14:40:15.619978  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:40:15.619978  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:40:15.619978  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:40:15.619978  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:40:15.619978  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:40:15.619978  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:40:15.619978  6908 net.cpp:122] Setting up relu4_2
I0530 14:40:15.619978  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:40:15.619978  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:40:15.619978  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:40:15.619978  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:40:15.619978  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:40:15.619978  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:40:15.623976  6908 net.cpp:122] Setting up conv4_3
I0530 14:40:15.623976  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:40:15.623976  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:40:15.623976  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:40:15.623976  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:40:15.623976  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:40:15.623976  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:40:15.623976  6908 net.cpp:122] Setting up relu4_3
I0530 14:40:15.623976  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:40:15.623976  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:40:15.623976  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:40:15.623976  6908 net.cpp:84] Creating Layer pool4
I0530 14:40:15.623976  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:40:15.623976  6908 net.cpp:380] pool4 -> pool4
I0530 14:40:15.623976  6908 net.cpp:122] Setting up pool4
I0530 14:40:15.623976  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:40:15.623976  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:40:15.623976  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:40:15.623976  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:40:15.623976  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:40:15.623976  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:40:15.627976  6908 net.cpp:122] Setting up conv5_1
I0530 14:40:15.627976  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:40:15.627976  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:40:15.627976  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:40:15.627976  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:40:15.627976  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:40:15.627976  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:40:15.627976  6908 net.cpp:122] Setting up relu5_1
I0530 14:40:15.627976  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:40:15.627976  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:40:15.627976  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:40:15.627976  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:40:15.627976  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:40:15.627976  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:40:15.631980  6908 net.cpp:122] Setting up conv5_2
I0530 14:40:15.631980  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:40:15.631980  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:40:15.631980  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:40:15.631980  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:40:15.631980  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:40:15.631980  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:40:15.631980  6908 net.cpp:122] Setting up relu5_2
I0530 14:40:15.631980  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:40:15.631980  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:40:15.631980  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:40:15.631980  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:40:15.631980  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:40:15.631980  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:40:15.635020  6908 net.cpp:122] Setting up conv5_3
I0530 14:40:15.635020  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:40:15.635020  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:40:15.635020  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:40:15.635020  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:40:15.635020  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:40:15.635020  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:40:15.635020  6908 net.cpp:122] Setting up relu5_3
I0530 14:40:15.635020  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:40:15.635020  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:40:15.635020  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:40:15.635020  6908 net.cpp:84] Creating Layer pool5
I0530 14:40:15.635020  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:40:15.635020  6908 net.cpp:380] pool5 -> pool5
I0530 14:40:15.635020  6908 net.cpp:122] Setting up pool5
I0530 14:40:15.635020  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:40:15.635020  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:40:15.635020  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:40:15.635020  6908 net.cpp:84] Creating Layer drop6
I0530 14:40:15.635020  6908 net.cpp:406] drop6 <- pool5
I0530 14:40:15.635020  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:40:15.635020  6908 net.cpp:122] Setting up drop6
I0530 14:40:15.635020  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:40:15.635020  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:40:15.635020  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:40:15.635020  6908 net.cpp:84] Creating Layer fc6
I0530 14:40:15.635020  6908 net.cpp:406] fc6 <- pool5
I0530 14:40:15.635020  6908 net.cpp:380] fc6 -> fc6
I0530 14:40:15.639020  6908 net.cpp:122] Setting up fc6
I0530 14:40:15.639020  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:40:15.639020  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:40:15.639020  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:40:15.639020  6908 net.cpp:84] Creating Layer relu6
I0530 14:40:15.639020  6908 net.cpp:406] relu6 <- fc6
I0530 14:40:15.639020  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:40:15.639020  6908 net.cpp:122] Setting up relu6
I0530 14:40:15.639020  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:40:15.639020  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:40:15.639020  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:40:15.639020  6908 net.cpp:84] Creating Layer fc7
I0530 14:40:15.639020  6908 net.cpp:406] fc7 <- fc6
I0530 14:40:15.639020  6908 net.cpp:380] fc7 -> fc7
I0530 14:40:15.639020  6908 net.cpp:122] Setting up fc7
I0530 14:40:15.639020  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:40:15.639020  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:40:15.639020  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:40:15.639020  6908 net.cpp:84] Creating Layer prob
I0530 14:40:15.639020  6908 net.cpp:406] prob <- fc7
I0530 14:40:15.639020  6908 net.cpp:380] prob -> prob
I0530 14:40:15.639020  6908 net.cpp:122] Setting up prob
I0530 14:40:15.639020  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:40:15.639020  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:40:15.639020  6908 net.cpp:200] prob does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:200] input does not need backward computation.
I0530 14:40:15.639020  6908 net.cpp:242] This network produces output prob
I0530 14:40:15.639020  6908 net.cpp:255] Network initialization done.
I0530 14:40:15.658020  6908 net.cpp:744] Ignoring source layer data
I0530 14:40:15.660020  6908 net.cpp:744] Ignoring source layer loss
I0530 14:41:09.509624  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:41:09.509624  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:41:09.509624  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:41:09.509624  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:41:09.509624  6908 layer_factory.hpp:77] Creating layer input
I0530 14:41:09.509624  6908 net.cpp:84] Creating Layer input
I0530 14:41:09.509624  6908 net.cpp:380] input -> data
I0530 14:41:09.510623  6908 net.cpp:122] Setting up input
I0530 14:41:09.510623  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:41:09.510623  6908 net.cpp:137] Memory required for data: 16384
I0530 14:41:09.510623  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:41:09.510623  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:41:09.510623  6908 net.cpp:406] conv1_1 <- data
I0530 14:41:09.510623  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:41:09.512632  6908 net.cpp:122] Setting up conv1_1
I0530 14:41:09.512632  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:41:09.512632  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:41:09.512632  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:41:09.512632  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:41:09.512632  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:41:09.512632  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:41:09.512632  6908 net.cpp:122] Setting up relu1_1
I0530 14:41:09.512632  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:41:09.512632  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:41:09.512632  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:41:09.512632  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:41:09.512632  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:41:09.512632  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:41:09.513622  6908 net.cpp:122] Setting up conv1_2
I0530 14:41:09.513622  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:41:09.513622  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:41:09.513622  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:41:09.513622  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:41:09.513622  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:41:09.513622  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:41:09.513622  6908 net.cpp:122] Setting up relu1_2
I0530 14:41:09.513622  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:41:09.513622  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:41:09.513622  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:41:09.513622  6908 net.cpp:84] Creating Layer pool1
I0530 14:41:09.513622  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:41:09.513622  6908 net.cpp:380] pool1 -> pool1
I0530 14:41:09.513622  6908 net.cpp:122] Setting up pool1
I0530 14:41:09.513622  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:09.513622  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:41:09.513622  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:41:09.513622  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:41:09.513622  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:41:09.513622  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:41:09.513622  6908 net.cpp:122] Setting up conv2_1
I0530 14:41:09.513622  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:41:09.513622  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:41:09.513622  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:41:09.513622  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:41:09.513622  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:41:09.514623  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:41:09.514623  6908 net.cpp:122] Setting up relu2_1
I0530 14:41:09.514623  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:41:09.514623  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:41:09.514623  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:41:09.514623  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:41:09.514623  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:41:09.514623  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:41:09.514623  6908 net.cpp:122] Setting up conv2_2
I0530 14:41:09.514623  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:09.514623  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:41:09.514623  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:41:09.514623  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:41:09.514623  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:41:09.514623  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:41:09.514623  6908 net.cpp:122] Setting up relu2_2
I0530 14:41:09.514623  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:09.514623  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:41:09.514623  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:41:09.514623  6908 net.cpp:84] Creating Layer pool2
I0530 14:41:09.514623  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:41:09.514623  6908 net.cpp:380] pool2 -> pool2
I0530 14:41:09.514623  6908 net.cpp:122] Setting up pool2
I0530 14:41:09.514623  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:09.514623  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:41:09.514623  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:41:09.514623  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:41:09.514623  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:41:09.514623  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:41:09.515624  6908 net.cpp:122] Setting up conv3_1
I0530 14:41:09.515624  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:09.515624  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:41:09.515624  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:41:09.515624  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:41:09.515624  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:41:09.515624  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:41:09.515624  6908 net.cpp:122] Setting up relu3_1
I0530 14:41:09.515624  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:09.515624  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:41:09.515624  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:41:09.515624  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:41:09.515624  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:41:09.515624  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:41:09.516623  6908 net.cpp:122] Setting up conv3_2
I0530 14:41:09.516623  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:09.516623  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:41:09.516623  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:41:09.516623  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:41:09.516623  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:41:09.516623  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:41:09.516623  6908 net.cpp:122] Setting up relu3_2
I0530 14:41:09.516623  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:09.516623  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:41:09.516623  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:41:09.516623  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:41:09.516623  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:41:09.516623  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:41:09.518627  6908 net.cpp:122] Setting up conv3_3
I0530 14:41:09.518627  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:09.518627  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:41:09.518627  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:41:09.518627  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:41:09.518627  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:41:09.518627  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:41:09.518627  6908 net.cpp:122] Setting up relu3_3
I0530 14:41:09.518627  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:09.518627  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:41:09.518627  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:41:09.518627  6908 net.cpp:84] Creating Layer pool3
I0530 14:41:09.518627  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:41:09.518627  6908 net.cpp:380] pool3 -> pool3
I0530 14:41:09.518627  6908 net.cpp:122] Setting up pool3
I0530 14:41:09.518627  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:41:09.518627  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:41:09.518627  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:41:09.518627  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:41:09.518627  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:41:09.518627  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:41:09.519634  6908 net.cpp:122] Setting up conv4_1
I0530 14:41:09.519634  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:09.519634  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:41:09.519634  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:41:09.519634  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:41:09.519634  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:41:09.519634  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:41:09.519634  6908 net.cpp:122] Setting up relu4_1
I0530 14:41:09.519634  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:09.519634  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:41:09.519634  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:41:09.519634  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:41:09.519634  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:41:09.519634  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:41:09.523633  6908 net.cpp:122] Setting up conv4_2
I0530 14:41:09.523633  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:09.523633  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:41:09.523633  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:41:09.523633  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:41:09.523633  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:41:09.523633  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:41:09.523633  6908 net.cpp:122] Setting up relu4_2
I0530 14:41:09.523633  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:09.523633  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:41:09.523633  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:41:09.523633  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:41:09.523633  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:41:09.523633  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:41:09.526630  6908 net.cpp:122] Setting up conv4_3
I0530 14:41:09.526630  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:09.526630  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:41:09.526630  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:41:09.526630  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:41:09.526630  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:41:09.526630  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:41:09.526630  6908 net.cpp:122] Setting up relu4_3
I0530 14:41:09.526630  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:09.526630  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:41:09.527631  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:41:09.527631  6908 net.cpp:84] Creating Layer pool4
I0530 14:41:09.527631  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:41:09.527631  6908 net.cpp:380] pool4 -> pool4
I0530 14:41:09.527631  6908 net.cpp:122] Setting up pool4
I0530 14:41:09.527631  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:09.527631  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:41:09.527631  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:41:09.527631  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:41:09.527631  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:41:09.527631  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:41:09.530632  6908 net.cpp:122] Setting up conv5_1
I0530 14:41:09.530632  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:09.530632  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:41:09.530632  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:41:09.530632  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:41:09.530632  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:41:09.530632  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:41:09.530632  6908 net.cpp:122] Setting up relu5_1
I0530 14:41:09.530632  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:09.530632  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:41:09.530632  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:41:09.530632  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:41:09.530632  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:41:09.530632  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:41:09.534631  6908 net.cpp:122] Setting up conv5_2
I0530 14:41:09.534631  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:09.534631  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:41:09.534631  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:41:09.534631  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:41:09.534631  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:41:09.534631  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:41:09.534631  6908 net.cpp:122] Setting up relu5_2
I0530 14:41:09.534631  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:09.534631  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:41:09.534631  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:41:09.534631  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:41:09.534631  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:41:09.534631  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:41:09.538631  6908 net.cpp:122] Setting up conv5_3
I0530 14:41:09.538631  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:09.538631  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:41:09.538631  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:41:09.538631  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:41:09.538631  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:41:09.538631  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:41:09.538631  6908 net.cpp:122] Setting up relu5_3
I0530 14:41:09.538631  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:09.538631  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:41:09.538631  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:41:09.538631  6908 net.cpp:84] Creating Layer pool5
I0530 14:41:09.538631  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:41:09.538631  6908 net.cpp:380] pool5 -> pool5
I0530 14:41:09.538631  6908 net.cpp:122] Setting up pool5
I0530 14:41:09.538631  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:41:09.538631  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:41:09.538631  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:41:09.538631  6908 net.cpp:84] Creating Layer drop6
I0530 14:41:09.538631  6908 net.cpp:406] drop6 <- pool5
I0530 14:41:09.538631  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:41:09.538631  6908 net.cpp:122] Setting up drop6
I0530 14:41:09.538631  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:41:09.538631  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:41:09.538631  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:41:09.538631  6908 net.cpp:84] Creating Layer fc6
I0530 14:41:09.538631  6908 net.cpp:406] fc6 <- pool5
I0530 14:41:09.538631  6908 net.cpp:380] fc6 -> fc6
I0530 14:41:09.541631  6908 net.cpp:122] Setting up fc6
I0530 14:41:09.541631  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:41:09.541631  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:41:09.541631  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:41:09.541631  6908 net.cpp:84] Creating Layer relu6
I0530 14:41:09.541631  6908 net.cpp:406] relu6 <- fc6
I0530 14:41:09.541631  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:41:09.541631  6908 net.cpp:122] Setting up relu6
I0530 14:41:09.541631  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:41:09.541631  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:41:09.541631  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:41:09.541631  6908 net.cpp:84] Creating Layer fc7
I0530 14:41:09.541631  6908 net.cpp:406] fc7 <- fc6
I0530 14:41:09.541631  6908 net.cpp:380] fc7 -> fc7
I0530 14:41:09.541631  6908 net.cpp:122] Setting up fc7
I0530 14:41:09.541631  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:41:09.541631  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:41:09.541631  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:41:09.541631  6908 net.cpp:84] Creating Layer prob
I0530 14:41:09.541631  6908 net.cpp:406] prob <- fc7
I0530 14:41:09.541631  6908 net.cpp:380] prob -> prob
I0530 14:41:09.541631  6908 net.cpp:122] Setting up prob
I0530 14:41:09.541631  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:41:09.541631  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:41:09.541631  6908 net.cpp:200] prob does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:200] input does not need backward computation.
I0530 14:41:09.541631  6908 net.cpp:242] This network produces output prob
I0530 14:41:09.541631  6908 net.cpp:255] Network initialization done.
I0530 14:41:09.560632  6908 net.cpp:744] Ignoring source layer data
I0530 14:41:09.562633  6908 net.cpp:744] Ignoring source layer loss
I0530 14:41:16.835597  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:41:16.835597  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:41:16.835597  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:41:16.836597  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:41:16.836597  6908 layer_factory.hpp:77] Creating layer input
I0530 14:41:16.836597  6908 net.cpp:84] Creating Layer input
I0530 14:41:16.836597  6908 net.cpp:380] input -> data
I0530 14:41:16.836597  6908 net.cpp:122] Setting up input
I0530 14:41:16.836597  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:41:16.836597  6908 net.cpp:137] Memory required for data: 16384
I0530 14:41:16.836597  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:41:16.836597  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:41:16.836597  6908 net.cpp:406] conv1_1 <- data
I0530 14:41:16.836597  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:41:16.838891  6908 net.cpp:122] Setting up conv1_1
I0530 14:41:16.838891  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:41:16.838891  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:41:16.838891  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:41:16.838891  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:41:16.838891  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:41:16.838891  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:41:16.838891  6908 net.cpp:122] Setting up relu1_1
I0530 14:41:16.838891  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:41:16.838891  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:41:16.838891  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:41:16.838891  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:41:16.838891  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:41:16.838891  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:41:16.839893  6908 net.cpp:122] Setting up conv1_2
I0530 14:41:16.839893  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:41:16.839893  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:41:16.839893  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:41:16.839893  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:41:16.839893  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:41:16.839893  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:41:16.839893  6908 net.cpp:122] Setting up relu1_2
I0530 14:41:16.839893  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:41:16.839893  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:41:16.839893  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:41:16.839893  6908 net.cpp:84] Creating Layer pool1
I0530 14:41:16.839893  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:41:16.839893  6908 net.cpp:380] pool1 -> pool1
I0530 14:41:16.839893  6908 net.cpp:122] Setting up pool1
I0530 14:41:16.839893  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:16.839893  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:41:16.839893  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:41:16.839893  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:41:16.839893  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:41:16.839893  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:41:16.839893  6908 net.cpp:122] Setting up conv2_1
I0530 14:41:16.839893  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:41:16.839893  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:41:16.839893  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:41:16.839893  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:41:16.839893  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:41:16.839893  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:41:16.839893  6908 net.cpp:122] Setting up relu2_1
I0530 14:41:16.839893  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:41:16.839893  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:41:16.839893  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:41:16.839893  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:41:16.839893  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:41:16.839893  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:41:16.840893  6908 net.cpp:122] Setting up conv2_2
I0530 14:41:16.840893  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:16.840893  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:41:16.840893  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:41:16.840893  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:41:16.840893  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:41:16.840893  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:41:16.840893  6908 net.cpp:122] Setting up relu2_2
I0530 14:41:16.840893  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:16.840893  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:41:16.840893  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:41:16.840893  6908 net.cpp:84] Creating Layer pool2
I0530 14:41:16.840893  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:41:16.840893  6908 net.cpp:380] pool2 -> pool2
I0530 14:41:16.840893  6908 net.cpp:122] Setting up pool2
I0530 14:41:16.840893  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:16.840893  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:41:16.840893  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:41:16.840893  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:41:16.840893  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:41:16.840893  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:41:16.841893  6908 net.cpp:122] Setting up conv3_1
I0530 14:41:16.841893  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:16.841893  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:41:16.841893  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:41:16.841893  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:41:16.841893  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:41:16.841893  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:41:16.841893  6908 net.cpp:122] Setting up relu3_1
I0530 14:41:16.841893  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:16.841893  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:41:16.841893  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:41:16.841893  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:41:16.841893  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:41:16.841893  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:41:16.842893  6908 net.cpp:122] Setting up conv3_2
I0530 14:41:16.842893  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:16.842893  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:41:16.842893  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:41:16.842893  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:41:16.842893  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:41:16.842893  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:41:16.842893  6908 net.cpp:122] Setting up relu3_2
I0530 14:41:16.842893  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:16.842893  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:41:16.842893  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:41:16.842893  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:41:16.842893  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:41:16.842893  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:41:16.843896  6908 net.cpp:122] Setting up conv3_3
I0530 14:41:16.843896  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:16.843896  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:41:16.843896  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:41:16.843896  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:41:16.843896  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:41:16.843896  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:41:16.843896  6908 net.cpp:122] Setting up relu3_3
I0530 14:41:16.843896  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:16.843896  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:41:16.843896  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:41:16.843896  6908 net.cpp:84] Creating Layer pool3
I0530 14:41:16.843896  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:41:16.843896  6908 net.cpp:380] pool3 -> pool3
I0530 14:41:16.843896  6908 net.cpp:122] Setting up pool3
I0530 14:41:16.843896  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:41:16.843896  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:41:16.843896  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:41:16.843896  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:41:16.844894  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:41:16.844894  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:41:16.845893  6908 net.cpp:122] Setting up conv4_1
I0530 14:41:16.845893  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:16.845893  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:41:16.845893  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:41:16.845893  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:41:16.845893  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:41:16.845893  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:41:16.845893  6908 net.cpp:122] Setting up relu4_1
I0530 14:41:16.845893  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:16.845893  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:41:16.845893  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:41:16.845893  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:41:16.845893  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:41:16.845893  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:41:16.849892  6908 net.cpp:122] Setting up conv4_2
I0530 14:41:16.849892  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:16.849892  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:41:16.849892  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:41:16.849892  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:41:16.849892  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:41:16.849892  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:41:16.849892  6908 net.cpp:122] Setting up relu4_2
I0530 14:41:16.849892  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:16.849892  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:41:16.849892  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:41:16.849892  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:41:16.849892  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:41:16.849892  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:41:16.852893  6908 net.cpp:122] Setting up conv4_3
I0530 14:41:16.852893  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:16.852893  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:41:16.852893  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:41:16.852893  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:41:16.852893  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:41:16.852893  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:41:16.852893  6908 net.cpp:122] Setting up relu4_3
I0530 14:41:16.852893  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:16.852893  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:41:16.852893  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:41:16.852893  6908 net.cpp:84] Creating Layer pool4
I0530 14:41:16.852893  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:41:16.852893  6908 net.cpp:380] pool4 -> pool4
I0530 14:41:16.852893  6908 net.cpp:122] Setting up pool4
I0530 14:41:16.852893  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:16.852893  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:41:16.852893  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:41:16.852893  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:41:16.852893  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:41:16.852893  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:41:16.856892  6908 net.cpp:122] Setting up conv5_1
I0530 14:41:16.856892  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:16.856892  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:41:16.856892  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:41:16.856892  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:41:16.856892  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:41:16.856892  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:41:16.856892  6908 net.cpp:122] Setting up relu5_1
I0530 14:41:16.856892  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:16.856892  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:41:16.856892  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:41:16.856892  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:41:16.856892  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:41:16.856892  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:41:16.860893  6908 net.cpp:122] Setting up conv5_2
I0530 14:41:16.860893  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:16.860893  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:41:16.860893  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:41:16.860893  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:41:16.860893  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:41:16.860893  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:41:16.860893  6908 net.cpp:122] Setting up relu5_2
I0530 14:41:16.860893  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:16.860893  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:41:16.860893  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:41:16.860893  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:41:16.860893  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:41:16.860893  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:41:16.863596  6908 net.cpp:122] Setting up conv5_3
I0530 14:41:16.863596  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:16.863596  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:41:16.863596  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:41:16.863596  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:41:16.863596  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:41:16.863596  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:41:16.863596  6908 net.cpp:122] Setting up relu5_3
I0530 14:41:16.863596  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:16.863596  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:41:16.863596  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:41:16.863596  6908 net.cpp:84] Creating Layer pool5
I0530 14:41:16.863596  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:41:16.863596  6908 net.cpp:380] pool5 -> pool5
I0530 14:41:16.864595  6908 net.cpp:122] Setting up pool5
I0530 14:41:16.864595  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:41:16.864595  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:41:16.864595  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:41:16.864595  6908 net.cpp:84] Creating Layer drop6
I0530 14:41:16.864595  6908 net.cpp:406] drop6 <- pool5
I0530 14:41:16.864595  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:41:16.864595  6908 net.cpp:122] Setting up drop6
I0530 14:41:16.864595  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:41:16.864595  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:41:16.864595  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:41:16.864595  6908 net.cpp:84] Creating Layer fc6
I0530 14:41:16.864595  6908 net.cpp:406] fc6 <- pool5
I0530 14:41:16.864595  6908 net.cpp:380] fc6 -> fc6
I0530 14:41:16.867488  6908 net.cpp:122] Setting up fc6
I0530 14:41:16.867488  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:41:16.867488  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:41:16.867488  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:41:16.867488  6908 net.cpp:84] Creating Layer relu6
I0530 14:41:16.867488  6908 net.cpp:406] relu6 <- fc6
I0530 14:41:16.867488  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:41:16.867488  6908 net.cpp:122] Setting up relu6
I0530 14:41:16.867488  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:41:16.867488  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:41:16.867488  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:41:16.867488  6908 net.cpp:84] Creating Layer fc7
I0530 14:41:16.867488  6908 net.cpp:406] fc7 <- fc6
I0530 14:41:16.867488  6908 net.cpp:380] fc7 -> fc7
I0530 14:41:16.867488  6908 net.cpp:122] Setting up fc7
I0530 14:41:16.867488  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:41:16.867488  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:41:16.867488  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:41:16.867488  6908 net.cpp:84] Creating Layer prob
I0530 14:41:16.867488  6908 net.cpp:406] prob <- fc7
I0530 14:41:16.867488  6908 net.cpp:380] prob -> prob
I0530 14:41:16.867488  6908 net.cpp:122] Setting up prob
I0530 14:41:16.867488  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:41:16.867488  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:41:16.867488  6908 net.cpp:200] prob does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:200] input does not need backward computation.
I0530 14:41:16.867488  6908 net.cpp:242] This network produces output prob
I0530 14:41:16.867488  6908 net.cpp:255] Network initialization done.
I0530 14:41:16.886489  6908 net.cpp:744] Ignoring source layer data
I0530 14:41:16.889490  6908 net.cpp:744] Ignoring source layer loss
I0530 14:41:50.654386  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:41:50.654386  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:41:50.654386  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:41:50.654386  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:41:50.654386  6908 layer_factory.hpp:77] Creating layer input
I0530 14:41:50.654386  6908 net.cpp:84] Creating Layer input
I0530 14:41:50.654386  6908 net.cpp:380] input -> data
I0530 14:41:50.655386  6908 net.cpp:122] Setting up input
I0530 14:41:50.655386  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:41:50.655386  6908 net.cpp:137] Memory required for data: 16384
I0530 14:41:50.655386  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:41:50.655386  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:41:50.655386  6908 net.cpp:406] conv1_1 <- data
I0530 14:41:50.655386  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:41:50.656388  6908 net.cpp:122] Setting up conv1_1
I0530 14:41:50.656388  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:41:50.656388  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:41:50.656388  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:41:50.656388  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:41:50.656388  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:41:50.656388  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:41:50.656388  6908 net.cpp:122] Setting up relu1_1
I0530 14:41:50.656388  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:41:50.657387  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:41:50.657387  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:41:50.657387  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:41:50.657387  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:41:50.657387  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:41:50.658309  6908 net.cpp:122] Setting up conv1_2
I0530 14:41:50.658309  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:41:50.658309  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:41:50.658309  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:41:50.658309  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:41:50.658309  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:41:50.658309  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:41:50.658309  6908 net.cpp:122] Setting up relu1_2
I0530 14:41:50.658309  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:41:50.658309  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:41:50.658309  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:41:50.658309  6908 net.cpp:84] Creating Layer pool1
I0530 14:41:50.658309  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:41:50.658309  6908 net.cpp:380] pool1 -> pool1
I0530 14:41:50.658309  6908 net.cpp:122] Setting up pool1
I0530 14:41:50.658309  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:50.658309  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:41:50.658309  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:41:50.658309  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:41:50.658309  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:41:50.658309  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:41:50.659312  6908 net.cpp:122] Setting up conv2_1
I0530 14:41:50.659312  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:41:50.659312  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:41:50.659312  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:41:50.659312  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:41:50.659312  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:41:50.659312  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:41:50.659312  6908 net.cpp:122] Setting up relu2_1
I0530 14:41:50.659312  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:41:50.659312  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:41:50.659312  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:41:50.659312  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:41:50.659312  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:41:50.659312  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:41:50.659312  6908 net.cpp:122] Setting up conv2_2
I0530 14:41:50.659312  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:50.659312  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:41:50.659312  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:41:50.659312  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:41:50.659312  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:41:50.659312  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:41:50.659312  6908 net.cpp:122] Setting up relu2_2
I0530 14:41:50.659312  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:41:50.659312  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:41:50.659312  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:41:50.659312  6908 net.cpp:84] Creating Layer pool2
I0530 14:41:50.659312  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:41:50.659312  6908 net.cpp:380] pool2 -> pool2
I0530 14:41:50.659312  6908 net.cpp:122] Setting up pool2
I0530 14:41:50.659312  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:50.659312  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:41:50.659312  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:41:50.659312  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:41:50.659312  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:41:50.659312  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:41:50.660311  6908 net.cpp:122] Setting up conv3_1
I0530 14:41:50.660311  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:50.660311  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:41:50.660311  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:41:50.660311  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:41:50.660311  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:41:50.660311  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:41:50.660311  6908 net.cpp:122] Setting up relu3_1
I0530 14:41:50.660311  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:50.660311  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:41:50.660311  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:41:50.660311  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:41:50.660311  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:41:50.660311  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:41:50.661311  6908 net.cpp:122] Setting up conv3_2
I0530 14:41:50.661311  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:50.661311  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:41:50.661311  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:41:50.661311  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:41:50.661311  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:41:50.661311  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:41:50.661311  6908 net.cpp:122] Setting up relu3_2
I0530 14:41:50.661311  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:50.661311  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:41:50.661311  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:41:50.661311  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:41:50.661311  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:41:50.661311  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:41:50.662348  6908 net.cpp:122] Setting up conv3_3
I0530 14:41:50.662348  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:50.662348  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:41:50.662348  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:41:50.662348  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:41:50.662348  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:41:50.663381  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:41:50.663381  6908 net.cpp:122] Setting up relu3_3
I0530 14:41:50.663381  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:41:50.663381  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:41:50.663381  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:41:50.663381  6908 net.cpp:84] Creating Layer pool3
I0530 14:41:50.663381  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:41:50.663381  6908 net.cpp:380] pool3 -> pool3
I0530 14:41:50.663381  6908 net.cpp:122] Setting up pool3
I0530 14:41:50.663381  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:41:50.663381  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:41:50.663381  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:41:50.663381  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:41:50.663381  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:41:50.663381  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:41:50.664381  6908 net.cpp:122] Setting up conv4_1
I0530 14:41:50.664381  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:50.664381  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:41:50.664381  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:41:50.664381  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:41:50.664381  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:41:50.664381  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:41:50.664381  6908 net.cpp:122] Setting up relu4_1
I0530 14:41:50.664381  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:50.664381  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:41:50.664381  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:41:50.664381  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:41:50.664381  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:41:50.664381  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:41:50.668385  6908 net.cpp:122] Setting up conv4_2
I0530 14:41:50.668385  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:50.668385  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:41:50.668385  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:41:50.668385  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:41:50.668385  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:41:50.668385  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:41:50.668385  6908 net.cpp:122] Setting up relu4_2
I0530 14:41:50.668385  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:50.668385  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:41:50.668385  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:41:50.668385  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:41:50.668385  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:41:50.668385  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:41:50.671380  6908 net.cpp:122] Setting up conv4_3
I0530 14:41:50.671380  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:50.671380  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:41:50.671380  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:41:50.671380  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:41:50.671380  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:41:50.671380  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:41:50.671380  6908 net.cpp:122] Setting up relu4_3
I0530 14:41:50.671380  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:41:50.671380  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:41:50.671380  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:41:50.671380  6908 net.cpp:84] Creating Layer pool4
I0530 14:41:50.671380  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:41:50.671380  6908 net.cpp:380] pool4 -> pool4
I0530 14:41:50.671380  6908 net.cpp:122] Setting up pool4
I0530 14:41:50.671380  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:50.671380  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:41:50.671380  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:41:50.672380  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:41:50.672380  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:41:50.672380  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:41:50.675382  6908 net.cpp:122] Setting up conv5_1
I0530 14:41:50.675382  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:50.675382  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:41:50.675382  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:41:50.675382  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:41:50.675382  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:41:50.675382  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:41:50.675382  6908 net.cpp:122] Setting up relu5_1
I0530 14:41:50.675382  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:50.675382  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:41:50.675382  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:41:50.675382  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:41:50.675382  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:41:50.675382  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:41:50.679373  6908 net.cpp:122] Setting up conv5_2
I0530 14:41:50.679373  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:50.679373  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:41:50.679373  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:41:50.679373  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:41:50.679373  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:41:50.679373  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:41:50.679373  6908 net.cpp:122] Setting up relu5_2
I0530 14:41:50.679373  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:50.679373  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:41:50.679373  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:41:50.679373  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:41:50.679373  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:41:50.679373  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:41:50.683373  6908 net.cpp:122] Setting up conv5_3
I0530 14:41:50.683373  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:50.683373  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:41:50.683373  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:41:50.683373  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:41:50.683373  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:41:50.683373  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:41:50.683373  6908 net.cpp:122] Setting up relu5_3
I0530 14:41:50.683373  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:41:50.683373  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:41:50.683373  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:41:50.683373  6908 net.cpp:84] Creating Layer pool5
I0530 14:41:50.683373  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:41:50.683373  6908 net.cpp:380] pool5 -> pool5
I0530 14:41:50.683373  6908 net.cpp:122] Setting up pool5
I0530 14:41:50.683373  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:41:50.683373  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:41:50.683373  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:41:50.683373  6908 net.cpp:84] Creating Layer drop6
I0530 14:41:50.683373  6908 net.cpp:406] drop6 <- pool5
I0530 14:41:50.683373  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:41:50.683373  6908 net.cpp:122] Setting up drop6
I0530 14:41:50.683373  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:41:50.683373  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:41:50.683373  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:41:50.683373  6908 net.cpp:84] Creating Layer fc6
I0530 14:41:50.683373  6908 net.cpp:406] fc6 <- pool5
I0530 14:41:50.683373  6908 net.cpp:380] fc6 -> fc6
I0530 14:41:50.686942  6908 net.cpp:122] Setting up fc6
I0530 14:41:50.686942  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:41:50.686942  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:41:50.686942  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:41:50.686942  6908 net.cpp:84] Creating Layer relu6
I0530 14:41:50.686942  6908 net.cpp:406] relu6 <- fc6
I0530 14:41:50.686942  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:41:50.686942  6908 net.cpp:122] Setting up relu6
I0530 14:41:50.686942  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:41:50.686942  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:41:50.686942  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:41:50.686942  6908 net.cpp:84] Creating Layer fc7
I0530 14:41:50.686942  6908 net.cpp:406] fc7 <- fc6
I0530 14:41:50.686942  6908 net.cpp:380] fc7 -> fc7
I0530 14:41:50.686942  6908 net.cpp:122] Setting up fc7
I0530 14:41:50.686942  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:41:50.686942  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:41:50.686942  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:41:50.686942  6908 net.cpp:84] Creating Layer prob
I0530 14:41:50.686942  6908 net.cpp:406] prob <- fc7
I0530 14:41:50.686942  6908 net.cpp:380] prob -> prob
I0530 14:41:50.686942  6908 net.cpp:122] Setting up prob
I0530 14:41:50.686942  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:41:50.686942  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:41:50.686942  6908 net.cpp:200] prob does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:200] input does not need backward computation.
I0530 14:41:50.686942  6908 net.cpp:242] This network produces output prob
I0530 14:41:50.686942  6908 net.cpp:255] Network initialization done.
I0530 14:41:50.705943  6908 net.cpp:744] Ignoring source layer data
I0530 14:41:50.708943  6908 net.cpp:744] Ignoring source layer loss
I0530 14:42:26.030067  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:42:26.030067  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:42:26.030067  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:42:26.030067  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:42:26.030067  6908 layer_factory.hpp:77] Creating layer input
I0530 14:42:26.030067  6908 net.cpp:84] Creating Layer input
I0530 14:42:26.030067  6908 net.cpp:380] input -> data
I0530 14:42:26.031067  6908 net.cpp:122] Setting up input
I0530 14:42:26.031067  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:42:26.031067  6908 net.cpp:137] Memory required for data: 16384
I0530 14:42:26.031067  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:42:26.031067  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:42:26.031067  6908 net.cpp:406] conv1_1 <- data
I0530 14:42:26.031067  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:42:26.032644  6908 net.cpp:122] Setting up conv1_1
I0530 14:42:26.032644  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:42:26.032644  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:42:26.032644  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:42:26.032644  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:42:26.032644  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:42:26.032644  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:42:26.032644  6908 net.cpp:122] Setting up relu1_1
I0530 14:42:26.032644  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:42:26.032644  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:42:26.032644  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:42:26.032644  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:42:26.032644  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:42:26.032644  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:42:26.033648  6908 net.cpp:122] Setting up conv1_2
I0530 14:42:26.033648  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:42:26.033648  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:42:26.033648  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:42:26.033648  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:42:26.033648  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:42:26.033648  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:42:26.033648  6908 net.cpp:122] Setting up relu1_2
I0530 14:42:26.033648  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:42:26.033648  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:42:26.033648  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:42:26.033648  6908 net.cpp:84] Creating Layer pool1
I0530 14:42:26.033648  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:42:26.033648  6908 net.cpp:380] pool1 -> pool1
I0530 14:42:26.033648  6908 net.cpp:122] Setting up pool1
I0530 14:42:26.033648  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:42:26.033648  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:42:26.033648  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:42:26.033648  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:42:26.033648  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:42:26.033648  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:42:26.034677  6908 net.cpp:122] Setting up conv2_1
I0530 14:42:26.034677  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:42:26.034677  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:42:26.034677  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:42:26.034677  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:42:26.034677  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:42:26.034677  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:42:26.034677  6908 net.cpp:122] Setting up relu2_1
I0530 14:42:26.034677  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:42:26.034677  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:42:26.034677  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:42:26.034677  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:42:26.034677  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:42:26.034677  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:42:26.034677  6908 net.cpp:122] Setting up conv2_2
I0530 14:42:26.034677  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:42:26.034677  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:42:26.034677  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:42:26.034677  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:42:26.034677  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:42:26.034677  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:42:26.034677  6908 net.cpp:122] Setting up relu2_2
I0530 14:42:26.034677  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:42:26.034677  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:42:26.034677  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:42:26.034677  6908 net.cpp:84] Creating Layer pool2
I0530 14:42:26.034677  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:42:26.034677  6908 net.cpp:380] pool2 -> pool2
I0530 14:42:26.034677  6908 net.cpp:122] Setting up pool2
I0530 14:42:26.034677  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:42:26.034677  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:42:26.034677  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:42:26.034677  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:42:26.034677  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:42:26.034677  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:42:26.035671  6908 net.cpp:122] Setting up conv3_1
I0530 14:42:26.035671  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:42:26.035671  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:42:26.035671  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:42:26.035671  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:42:26.035671  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:42:26.035671  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:42:26.035671  6908 net.cpp:122] Setting up relu3_1
I0530 14:42:26.035671  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:42:26.035671  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:42:26.035671  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:42:26.035671  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:42:26.035671  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:42:26.035671  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:42:26.036671  6908 net.cpp:122] Setting up conv3_2
I0530 14:42:26.036671  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:42:26.036671  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:42:26.036671  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:42:26.036671  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:42:26.036671  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:42:26.036671  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:42:26.036671  6908 net.cpp:122] Setting up relu3_2
I0530 14:42:26.036671  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:42:26.036671  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:42:26.036671  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:42:26.036671  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:42:26.036671  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:42:26.036671  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:42:26.038674  6908 net.cpp:122] Setting up conv3_3
I0530 14:42:26.038674  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:42:26.038674  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:42:26.038674  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:42:26.038674  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:42:26.038674  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:42:26.038674  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:42:26.038674  6908 net.cpp:122] Setting up relu3_3
I0530 14:42:26.038674  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:42:26.038674  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:42:26.038674  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:42:26.038674  6908 net.cpp:84] Creating Layer pool3
I0530 14:42:26.038674  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:42:26.038674  6908 net.cpp:380] pool3 -> pool3
I0530 14:42:26.038674  6908 net.cpp:122] Setting up pool3
I0530 14:42:26.038674  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:42:26.038674  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:42:26.038674  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:42:26.038674  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:42:26.038674  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:42:26.038674  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:42:26.039671  6908 net.cpp:122] Setting up conv4_1
I0530 14:42:26.039671  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:42:26.039671  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:42:26.039671  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:42:26.039671  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:42:26.039671  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:42:26.040647  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:42:26.040647  6908 net.cpp:122] Setting up relu4_1
I0530 14:42:26.040647  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:42:26.040647  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:42:26.040647  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:42:26.040647  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:42:26.040647  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:42:26.040647  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:42:26.043684  6908 net.cpp:122] Setting up conv4_2
I0530 14:42:26.043684  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:42:26.043684  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:42:26.043684  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:42:26.043684  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:42:26.043684  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:42:26.043684  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:42:26.043684  6908 net.cpp:122] Setting up relu4_2
I0530 14:42:26.043684  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:42:26.043684  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:42:26.043684  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:42:26.043684  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:42:26.043684  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:42:26.043684  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:42:26.047680  6908 net.cpp:122] Setting up conv4_3
I0530 14:42:26.047680  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:42:26.047680  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:42:26.047680  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:42:26.047680  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:42:26.047680  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:42:26.047680  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:42:26.047680  6908 net.cpp:122] Setting up relu4_3
I0530 14:42:26.047680  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:42:26.047680  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:42:26.047680  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:42:26.047680  6908 net.cpp:84] Creating Layer pool4
I0530 14:42:26.047680  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:42:26.047680  6908 net.cpp:380] pool4 -> pool4
I0530 14:42:26.047680  6908 net.cpp:122] Setting up pool4
I0530 14:42:26.047680  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:42:26.047680  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:42:26.047680  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:42:26.047680  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:42:26.047680  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:42:26.047680  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:42:26.051684  6908 net.cpp:122] Setting up conv5_1
I0530 14:42:26.051684  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:42:26.051684  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:42:26.051684  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:42:26.051684  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:42:26.051684  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:42:26.051684  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:42:26.051684  6908 net.cpp:122] Setting up relu5_1
I0530 14:42:26.051684  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:42:26.051684  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:42:26.051684  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:42:26.051684  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:42:26.051684  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:42:26.051684  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:42:26.054679  6908 net.cpp:122] Setting up conv5_2
I0530 14:42:26.055680  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:42:26.055680  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:42:26.055680  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:42:26.055680  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:42:26.055680  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:42:26.055680  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:42:26.055680  6908 net.cpp:122] Setting up relu5_2
I0530 14:42:26.055680  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:42:26.055680  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:42:26.055680  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:42:26.055680  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:42:26.055680  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:42:26.055680  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:42:26.058683  6908 net.cpp:122] Setting up conv5_3
I0530 14:42:26.058683  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:42:26.058683  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:42:26.058683  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:42:26.058683  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:42:26.058683  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:42:26.058683  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:42:26.058683  6908 net.cpp:122] Setting up relu5_3
I0530 14:42:26.058683  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:42:26.058683  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:42:26.058683  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:42:26.058683  6908 net.cpp:84] Creating Layer pool5
I0530 14:42:26.058683  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:42:26.058683  6908 net.cpp:380] pool5 -> pool5
I0530 14:42:26.058683  6908 net.cpp:122] Setting up pool5
I0530 14:42:26.058683  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:42:26.058683  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:42:26.058683  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:42:26.058683  6908 net.cpp:84] Creating Layer drop6
I0530 14:42:26.058683  6908 net.cpp:406] drop6 <- pool5
I0530 14:42:26.058683  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:42:26.058683  6908 net.cpp:122] Setting up drop6
I0530 14:42:26.058683  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:42:26.058683  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:42:26.058683  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:42:26.058683  6908 net.cpp:84] Creating Layer fc6
I0530 14:42:26.058683  6908 net.cpp:406] fc6 <- pool5
I0530 14:42:26.058683  6908 net.cpp:380] fc6 -> fc6
I0530 14:42:26.062680  6908 net.cpp:122] Setting up fc6
I0530 14:42:26.062680  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:42:26.062680  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:42:26.062680  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:42:26.062680  6908 net.cpp:84] Creating Layer relu6
I0530 14:42:26.062680  6908 net.cpp:406] relu6 <- fc6
I0530 14:42:26.062680  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:42:26.062680  6908 net.cpp:122] Setting up relu6
I0530 14:42:26.062680  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:42:26.062680  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:42:26.062680  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:42:26.062680  6908 net.cpp:84] Creating Layer fc7
I0530 14:42:26.062680  6908 net.cpp:406] fc7 <- fc6
I0530 14:42:26.062680  6908 net.cpp:380] fc7 -> fc7
I0530 14:42:26.062680  6908 net.cpp:122] Setting up fc7
I0530 14:42:26.062680  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:42:26.062680  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:42:26.062680  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:42:26.062680  6908 net.cpp:84] Creating Layer prob
I0530 14:42:26.062680  6908 net.cpp:406] prob <- fc7
I0530 14:42:26.062680  6908 net.cpp:380] prob -> prob
I0530 14:42:26.062680  6908 net.cpp:122] Setting up prob
I0530 14:42:26.062680  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:42:26.062680  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:42:26.062680  6908 net.cpp:200] prob does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:200] input does not need backward computation.
I0530 14:42:26.062680  6908 net.cpp:242] This network produces output prob
I0530 14:42:26.062680  6908 net.cpp:255] Network initialization done.
I0530 14:42:26.081691  6908 net.cpp:744] Ignoring source layer data
I0530 14:42:26.083670  6908 net.cpp:744] Ignoring source layer loss
I0530 14:44:56.647315  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:44:56.647315  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:44:56.647315  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:44:56.647315  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:44:56.647315  6908 layer_factory.hpp:77] Creating layer input
I0530 14:44:56.647315  6908 net.cpp:84] Creating Layer input
I0530 14:44:56.647315  6908 net.cpp:380] input -> data
I0530 14:44:56.648316  6908 net.cpp:122] Setting up input
I0530 14:44:56.648316  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:44:56.648316  6908 net.cpp:137] Memory required for data: 16384
I0530 14:44:56.648316  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:44:56.648316  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:44:56.648316  6908 net.cpp:406] conv1_1 <- data
I0530 14:44:56.648316  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:44:56.650315  6908 net.cpp:122] Setting up conv1_1
I0530 14:44:56.650315  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:44:56.650315  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:44:56.650315  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:44:56.650315  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:44:56.650315  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:44:56.650315  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:44:56.650315  6908 net.cpp:122] Setting up relu1_1
I0530 14:44:56.650315  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:44:56.650315  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:44:56.650315  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:44:56.650315  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:44:56.650315  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:44:56.650315  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:44:56.651314  6908 net.cpp:122] Setting up conv1_2
I0530 14:44:56.651314  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:44:56.651314  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:44:56.651314  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:44:56.652313  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:44:56.652313  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:44:56.652313  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:44:56.652313  6908 net.cpp:122] Setting up relu1_2
I0530 14:44:56.652313  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:44:56.652313  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:44:56.652313  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:44:56.652313  6908 net.cpp:84] Creating Layer pool1
I0530 14:44:56.652313  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:44:56.652313  6908 net.cpp:380] pool1 -> pool1
I0530 14:44:56.652313  6908 net.cpp:122] Setting up pool1
I0530 14:44:56.652313  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:44:56.652313  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:44:56.652313  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:44:56.652313  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:44:56.652313  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:44:56.652313  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:44:56.652313  6908 net.cpp:122] Setting up conv2_1
I0530 14:44:56.652313  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:44:56.652313  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:44:56.652313  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:44:56.652313  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:44:56.652313  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:44:56.652313  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:44:56.652313  6908 net.cpp:122] Setting up relu2_1
I0530 14:44:56.652313  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:44:56.652313  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:44:56.652313  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:44:56.652313  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:44:56.652313  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:44:56.652313  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:44:56.653313  6908 net.cpp:122] Setting up conv2_2
I0530 14:44:56.653313  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:44:56.653313  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:44:56.653313  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:44:56.653313  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:44:56.653313  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:44:56.653313  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:44:56.653313  6908 net.cpp:122] Setting up relu2_2
I0530 14:44:56.653313  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:44:56.653313  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:44:56.653313  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:44:56.653313  6908 net.cpp:84] Creating Layer pool2
I0530 14:44:56.653313  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:44:56.653313  6908 net.cpp:380] pool2 -> pool2
I0530 14:44:56.653313  6908 net.cpp:122] Setting up pool2
I0530 14:44:56.653313  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:44:56.653313  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:44:56.653313  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:44:56.653313  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:44:56.653313  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:44:56.653313  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:44:56.654345  6908 net.cpp:122] Setting up conv3_1
I0530 14:44:56.654345  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:44:56.654345  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:44:56.654345  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:44:56.654345  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:44:56.654345  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:44:56.654345  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:44:56.654345  6908 net.cpp:122] Setting up relu3_1
I0530 14:44:56.654345  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:44:56.654345  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:44:56.654345  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:44:56.654345  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:44:56.654345  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:44:56.654345  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:44:56.655342  6908 net.cpp:122] Setting up conv3_2
I0530 14:44:56.655342  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:44:56.655342  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:44:56.655342  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:44:56.655342  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:44:56.655342  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:44:56.655342  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:44:56.655342  6908 net.cpp:122] Setting up relu3_2
I0530 14:44:56.655342  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:44:56.655342  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:44:56.655342  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:44:56.655342  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:44:56.655342  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:44:56.655342  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:44:56.656524  6908 net.cpp:122] Setting up conv3_3
I0530 14:44:56.656524  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:44:56.656524  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:44:56.656524  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:44:56.656524  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:44:56.656524  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:44:56.656524  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:44:56.656524  6908 net.cpp:122] Setting up relu3_3
I0530 14:44:56.656524  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:44:56.656524  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:44:56.656524  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:44:56.656524  6908 net.cpp:84] Creating Layer pool3
I0530 14:44:56.656524  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:44:56.656524  6908 net.cpp:380] pool3 -> pool3
I0530 14:44:56.656524  6908 net.cpp:122] Setting up pool3
I0530 14:44:56.656524  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:44:56.656524  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:44:56.656524  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:44:56.656524  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:44:56.656524  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:44:56.656524  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:44:56.658527  6908 net.cpp:122] Setting up conv4_1
I0530 14:44:56.658527  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:44:56.658527  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:44:56.658527  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:44:56.658527  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:44:56.658527  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:44:56.658527  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:44:56.658527  6908 net.cpp:122] Setting up relu4_1
I0530 14:44:56.658527  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:44:56.658527  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:44:56.658527  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:44:56.658527  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:44:56.658527  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:44:56.658527  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:44:56.662526  6908 net.cpp:122] Setting up conv4_2
I0530 14:44:56.662526  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:44:56.662526  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:44:56.662526  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:44:56.662526  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:44:56.662526  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:44:56.662526  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:44:56.662526  6908 net.cpp:122] Setting up relu4_2
I0530 14:44:56.662526  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:44:56.662526  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:44:56.662526  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:44:56.662526  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:44:56.662526  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:44:56.662526  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:44:56.665526  6908 net.cpp:122] Setting up conv4_3
I0530 14:44:56.665526  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:44:56.665526  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:44:56.665526  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:44:56.665526  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:44:56.665526  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:44:56.665526  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:44:56.665526  6908 net.cpp:122] Setting up relu4_3
I0530 14:44:56.665526  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:44:56.665526  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:44:56.665526  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:44:56.665526  6908 net.cpp:84] Creating Layer pool4
I0530 14:44:56.665526  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:44:56.665526  6908 net.cpp:380] pool4 -> pool4
I0530 14:44:56.665526  6908 net.cpp:122] Setting up pool4
I0530 14:44:56.665526  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:44:56.665526  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:44:56.665526  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:44:56.665526  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:44:56.665526  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:44:56.665526  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:44:56.669526  6908 net.cpp:122] Setting up conv5_1
I0530 14:44:56.669526  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:44:56.669526  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:44:56.669526  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:44:56.669526  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:44:56.669526  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:44:56.669526  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:44:56.669526  6908 net.cpp:122] Setting up relu5_1
I0530 14:44:56.669526  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:44:56.669526  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:44:56.669526  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:44:56.669526  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:44:56.669526  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:44:56.669526  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:44:56.673768  6908 net.cpp:122] Setting up conv5_2
I0530 14:44:56.673768  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:44:56.673768  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:44:56.673768  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:44:56.673768  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:44:56.673768  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:44:56.673768  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:44:56.673768  6908 net.cpp:122] Setting up relu5_2
I0530 14:44:56.673768  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:44:56.673768  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:44:56.673768  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:44:56.673768  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:44:56.673768  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:44:56.673768  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:44:56.676769  6908 net.cpp:122] Setting up conv5_3
I0530 14:44:56.676769  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:44:56.676769  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:44:56.676769  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:44:56.676769  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:44:56.676769  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:44:56.676769  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:44:56.676769  6908 net.cpp:122] Setting up relu5_3
I0530 14:44:56.676769  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:44:56.676769  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:44:56.676769  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:44:56.676769  6908 net.cpp:84] Creating Layer pool5
I0530 14:44:56.676769  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:44:56.676769  6908 net.cpp:380] pool5 -> pool5
I0530 14:44:56.676769  6908 net.cpp:122] Setting up pool5
I0530 14:44:56.676769  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:44:56.676769  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:44:56.676769  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:44:56.676769  6908 net.cpp:84] Creating Layer drop6
I0530 14:44:56.676769  6908 net.cpp:406] drop6 <- pool5
I0530 14:44:56.676769  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:44:56.676769  6908 net.cpp:122] Setting up drop6
I0530 14:44:56.676769  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:44:56.676769  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:44:56.676769  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:44:56.676769  6908 net.cpp:84] Creating Layer fc6
I0530 14:44:56.676769  6908 net.cpp:406] fc6 <- pool5
I0530 14:44:56.676769  6908 net.cpp:380] fc6 -> fc6
I0530 14:44:56.680732  6908 net.cpp:122] Setting up fc6
I0530 14:44:56.680732  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:44:56.680732  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:44:56.680732  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:44:56.680732  6908 net.cpp:84] Creating Layer relu6
I0530 14:44:56.680732  6908 net.cpp:406] relu6 <- fc6
I0530 14:44:56.680732  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:44:56.680732  6908 net.cpp:122] Setting up relu6
I0530 14:44:56.680732  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:44:56.680732  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:44:56.680732  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:44:56.680732  6908 net.cpp:84] Creating Layer fc7
I0530 14:44:56.680732  6908 net.cpp:406] fc7 <- fc6
I0530 14:44:56.680732  6908 net.cpp:380] fc7 -> fc7
I0530 14:44:56.680732  6908 net.cpp:122] Setting up fc7
I0530 14:44:56.680732  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:44:56.680732  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:44:56.680732  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:44:56.680732  6908 net.cpp:84] Creating Layer prob
I0530 14:44:56.680732  6908 net.cpp:406] prob <- fc7
I0530 14:44:56.680732  6908 net.cpp:380] prob -> prob
I0530 14:44:56.680732  6908 net.cpp:122] Setting up prob
I0530 14:44:56.680732  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:44:56.680732  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:44:56.680732  6908 net.cpp:200] prob does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:200] input does not need backward computation.
I0530 14:44:56.680732  6908 net.cpp:242] This network produces output prob
I0530 14:44:56.680732  6908 net.cpp:255] Network initialization done.
I0530 14:44:56.699733  6908 net.cpp:744] Ignoring source layer data
I0530 14:44:56.701733  6908 net.cpp:744] Ignoring source layer loss
I0530 14:48:13.745260  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:48:13.745260  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:48:13.745260  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:48:13.745260  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:48:13.745260  6908 layer_factory.hpp:77] Creating layer input
I0530 14:48:13.745260  6908 net.cpp:84] Creating Layer input
I0530 14:48:13.745260  6908 net.cpp:380] input -> data
I0530 14:48:13.746273  6908 net.cpp:122] Setting up input
I0530 14:48:13.746273  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:48:13.746273  6908 net.cpp:137] Memory required for data: 16384
I0530 14:48:13.746273  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:48:13.746273  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:48:13.746273  6908 net.cpp:406] conv1_1 <- data
I0530 14:48:13.746273  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:48:13.747835  6908 net.cpp:122] Setting up conv1_1
I0530 14:48:13.747835  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:48:13.747835  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:48:13.747835  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:48:13.747835  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:48:13.747835  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:48:13.747835  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:48:13.747835  6908 net.cpp:122] Setting up relu1_1
I0530 14:48:13.747835  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:48:13.747835  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:48:13.747835  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:48:13.747835  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:48:13.747835  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:48:13.747835  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:48:13.749075  6908 net.cpp:122] Setting up conv1_2
I0530 14:48:13.749075  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:48:13.749075  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:48:13.749075  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:48:13.749075  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:48:13.749075  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:48:13.749075  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:48:13.749075  6908 net.cpp:122] Setting up relu1_2
I0530 14:48:13.749075  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:48:13.749075  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:48:13.749075  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:48:13.749075  6908 net.cpp:84] Creating Layer pool1
I0530 14:48:13.749075  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:48:13.749075  6908 net.cpp:380] pool1 -> pool1
I0530 14:48:13.749075  6908 net.cpp:122] Setting up pool1
I0530 14:48:13.749075  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:48:13.749075  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:48:13.749075  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:48:13.749075  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:48:13.749075  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:48:13.749075  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:48:13.750105  6908 net.cpp:122] Setting up conv2_1
I0530 14:48:13.750105  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:48:13.750105  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:48:13.750105  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:48:13.750105  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:48:13.750105  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:48:13.750105  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:48:13.750105  6908 net.cpp:122] Setting up relu2_1
I0530 14:48:13.750105  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:48:13.750105  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:48:13.750105  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:48:13.750105  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:48:13.750105  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:48:13.750105  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:48:13.750105  6908 net.cpp:122] Setting up conv2_2
I0530 14:48:13.750105  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:48:13.750105  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:48:13.750105  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:48:13.750105  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:48:13.750105  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:48:13.750105  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:48:13.750105  6908 net.cpp:122] Setting up relu2_2
I0530 14:48:13.750105  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:48:13.750105  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:48:13.750105  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:48:13.750105  6908 net.cpp:84] Creating Layer pool2
I0530 14:48:13.750105  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:48:13.750105  6908 net.cpp:380] pool2 -> pool2
I0530 14:48:13.750105  6908 net.cpp:122] Setting up pool2
I0530 14:48:13.750105  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:13.750105  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:48:13.750105  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:48:13.750105  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:48:13.750105  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:48:13.750105  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:48:13.751106  6908 net.cpp:122] Setting up conv3_1
I0530 14:48:13.751106  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:13.751106  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:48:13.751106  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:48:13.751106  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:48:13.751106  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:48:13.751106  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:48:13.751106  6908 net.cpp:122] Setting up relu3_1
I0530 14:48:13.751106  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:13.751106  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:48:13.751106  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:48:13.751106  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:48:13.751106  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:48:13.751106  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:48:13.752105  6908 net.cpp:122] Setting up conv3_2
I0530 14:48:13.752105  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:13.752105  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:48:13.752105  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:48:13.752105  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:48:13.752105  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:48:13.752105  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:48:13.752105  6908 net.cpp:122] Setting up relu3_2
I0530 14:48:13.752105  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:13.752105  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:48:13.752105  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:48:13.752105  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:48:13.752105  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:48:13.752105  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:48:13.754106  6908 net.cpp:122] Setting up conv3_3
I0530 14:48:13.754106  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:13.754106  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:48:13.754106  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:48:13.754106  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:48:13.754106  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:48:13.754106  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:48:13.754106  6908 net.cpp:122] Setting up relu3_3
I0530 14:48:13.754106  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:13.754106  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:48:13.754106  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:48:13.754106  6908 net.cpp:84] Creating Layer pool3
I0530 14:48:13.754106  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:48:13.754106  6908 net.cpp:380] pool3 -> pool3
I0530 14:48:13.754106  6908 net.cpp:122] Setting up pool3
I0530 14:48:13.754106  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:48:13.754106  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:48:13.754106  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:48:13.754106  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:48:13.754106  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:48:13.754106  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:48:13.755105  6908 net.cpp:122] Setting up conv4_1
I0530 14:48:13.755105  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:13.755105  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:48:13.755105  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:48:13.755105  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:48:13.755105  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:48:13.755105  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:48:13.755105  6908 net.cpp:122] Setting up relu4_1
I0530 14:48:13.755105  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:13.755105  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:48:13.755105  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:48:13.755105  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:48:13.755105  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:48:13.755105  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:48:13.759111  6908 net.cpp:122] Setting up conv4_2
I0530 14:48:13.759111  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:13.759111  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:48:13.759111  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:48:13.759111  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:48:13.759111  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:48:13.759111  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:48:13.759111  6908 net.cpp:122] Setting up relu4_2
I0530 14:48:13.759111  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:13.759111  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:48:13.759111  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:48:13.759111  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:48:13.759111  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:48:13.759111  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:48:13.763111  6908 net.cpp:122] Setting up conv4_3
I0530 14:48:13.763111  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:13.763111  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:48:13.763111  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:48:13.763111  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:48:13.763111  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:48:13.763111  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:48:13.763111  6908 net.cpp:122] Setting up relu4_3
I0530 14:48:13.763111  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:13.763111  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:48:13.763111  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:48:13.763111  6908 net.cpp:84] Creating Layer pool4
I0530 14:48:13.763111  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:48:13.763111  6908 net.cpp:380] pool4 -> pool4
I0530 14:48:13.763111  6908 net.cpp:122] Setting up pool4
I0530 14:48:13.763111  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:13.763111  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:48:13.763111  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:48:13.763111  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:48:13.763111  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:48:13.763111  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:48:13.766111  6908 net.cpp:122] Setting up conv5_1
I0530 14:48:13.766111  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:13.766111  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:48:13.766111  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:48:13.766111  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:48:13.766111  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:48:13.767112  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:48:13.767112  6908 net.cpp:122] Setting up relu5_1
I0530 14:48:13.767112  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:13.767112  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:48:13.767112  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:48:13.767112  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:48:13.767112  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:48:13.767112  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:48:13.770112  6908 net.cpp:122] Setting up conv5_2
I0530 14:48:13.770112  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:13.770112  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:48:13.770112  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:48:13.770112  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:48:13.770112  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:48:13.770112  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:48:13.770112  6908 net.cpp:122] Setting up relu5_2
I0530 14:48:13.770112  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:13.770112  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:48:13.770112  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:48:13.770112  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:48:13.770112  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:48:13.770112  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:48:13.774078  6908 net.cpp:122] Setting up conv5_3
I0530 14:48:13.774078  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:13.774078  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:48:13.774078  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:48:13.774078  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:48:13.774078  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:48:13.774078  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:48:13.774078  6908 net.cpp:122] Setting up relu5_3
I0530 14:48:13.774078  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:13.774078  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:48:13.774078  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:48:13.774078  6908 net.cpp:84] Creating Layer pool5
I0530 14:48:13.774078  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:48:13.774078  6908 net.cpp:380] pool5 -> pool5
I0530 14:48:13.774078  6908 net.cpp:122] Setting up pool5
I0530 14:48:13.774078  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:48:13.774078  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:48:13.774078  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:48:13.774078  6908 net.cpp:84] Creating Layer drop6
I0530 14:48:13.774078  6908 net.cpp:406] drop6 <- pool5
I0530 14:48:13.774078  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:48:13.774078  6908 net.cpp:122] Setting up drop6
I0530 14:48:13.774078  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:48:13.774078  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:48:13.774078  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:48:13.774078  6908 net.cpp:84] Creating Layer fc6
I0530 14:48:13.774078  6908 net.cpp:406] fc6 <- pool5
I0530 14:48:13.774078  6908 net.cpp:380] fc6 -> fc6
I0530 14:48:13.778111  6908 net.cpp:122] Setting up fc6
I0530 14:48:13.778111  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:48:13.778111  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:48:13.778111  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:48:13.778111  6908 net.cpp:84] Creating Layer relu6
I0530 14:48:13.778111  6908 net.cpp:406] relu6 <- fc6
I0530 14:48:13.778111  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:48:13.778111  6908 net.cpp:122] Setting up relu6
I0530 14:48:13.778111  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:48:13.778111  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:48:13.778111  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:48:13.778111  6908 net.cpp:84] Creating Layer fc7
I0530 14:48:13.778111  6908 net.cpp:406] fc7 <- fc6
I0530 14:48:13.778111  6908 net.cpp:380] fc7 -> fc7
I0530 14:48:13.778111  6908 net.cpp:122] Setting up fc7
I0530 14:48:13.778111  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:48:13.778111  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:48:13.778111  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:48:13.778111  6908 net.cpp:84] Creating Layer prob
I0530 14:48:13.778111  6908 net.cpp:406] prob <- fc7
I0530 14:48:13.778111  6908 net.cpp:380] prob -> prob
I0530 14:48:13.778111  6908 net.cpp:122] Setting up prob
I0530 14:48:13.778111  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:48:13.778111  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:48:13.778111  6908 net.cpp:200] prob does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:200] input does not need backward computation.
I0530 14:48:13.778111  6908 net.cpp:242] This network produces output prob
I0530 14:48:13.778111  6908 net.cpp:255] Network initialization done.
I0530 14:48:13.797111  6908 net.cpp:744] Ignoring source layer data
I0530 14:48:13.799111  6908 net.cpp:744] Ignoring source layer loss
W0530 14:48:38.535598  6908 net.hpp:41] DEPRECATED: ForwardPrefilled() will be removed in a future version. Use Forward().
I0530 14:48:58.610750  6908 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ./deploy.prototxt
I0530 14:48:58.610750  6908 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0530 14:48:58.610750  6908 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0530 14:48:58.610750  6908 net.cpp:51] Initializing net from parameters: 
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 64
      dim: 64
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "pool5"
  top: "pool5"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc7"
  top: "prob"
}
I0530 14:48:58.611749  6908 layer_factory.hpp:77] Creating layer input
I0530 14:48:58.611749  6908 net.cpp:84] Creating Layer input
I0530 14:48:58.611749  6908 net.cpp:380] input -> data
I0530 14:48:58.611749  6908 net.cpp:122] Setting up input
I0530 14:48:58.611749  6908 net.cpp:129] Top shape: 1 1 64 64 (4096)
I0530 14:48:58.611749  6908 net.cpp:137] Memory required for data: 16384
I0530 14:48:58.611749  6908 layer_factory.hpp:77] Creating layer conv1_1
I0530 14:48:58.611749  6908 net.cpp:84] Creating Layer conv1_1
I0530 14:48:58.611749  6908 net.cpp:406] conv1_1 <- data
I0530 14:48:58.611749  6908 net.cpp:380] conv1_1 -> conv1_1
I0530 14:48:58.613775  6908 net.cpp:122] Setting up conv1_1
I0530 14:48:58.613775  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:48:58.613775  6908 net.cpp:137] Memory required for data: 1064960
I0530 14:48:58.613775  6908 layer_factory.hpp:77] Creating layer relu1_1
I0530 14:48:58.613775  6908 net.cpp:84] Creating Layer relu1_1
I0530 14:48:58.613775  6908 net.cpp:406] relu1_1 <- conv1_1
I0530 14:48:58.613775  6908 net.cpp:367] relu1_1 -> conv1_1 (in-place)
I0530 14:48:58.613775  6908 net.cpp:122] Setting up relu1_1
I0530 14:48:58.613775  6908 net.cpp:129] Top shape: 1 64 64 64 (262144)
I0530 14:48:58.613775  6908 net.cpp:137] Memory required for data: 2113536
I0530 14:48:58.613775  6908 layer_factory.hpp:77] Creating layer conv1_2
I0530 14:48:58.613775  6908 net.cpp:84] Creating Layer conv1_2
I0530 14:48:58.613775  6908 net.cpp:406] conv1_2 <- conv1_1
I0530 14:48:58.613775  6908 net.cpp:380] conv1_2 -> conv1_2
I0530 14:48:58.614776  6908 net.cpp:122] Setting up conv1_2
I0530 14:48:58.614776  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:48:58.614776  6908 net.cpp:137] Memory required for data: 4210688
I0530 14:48:58.614776  6908 layer_factory.hpp:77] Creating layer relu1_2
I0530 14:48:58.614776  6908 net.cpp:84] Creating Layer relu1_2
I0530 14:48:58.614776  6908 net.cpp:406] relu1_2 <- conv1_2
I0530 14:48:58.614776  6908 net.cpp:367] relu1_2 -> conv1_2 (in-place)
I0530 14:48:58.614776  6908 net.cpp:122] Setting up relu1_2
I0530 14:48:58.614776  6908 net.cpp:129] Top shape: 1 128 64 64 (524288)
I0530 14:48:58.614776  6908 net.cpp:137] Memory required for data: 6307840
I0530 14:48:58.614776  6908 layer_factory.hpp:77] Creating layer pool1
I0530 14:48:58.614776  6908 net.cpp:84] Creating Layer pool1
I0530 14:48:58.614776  6908 net.cpp:406] pool1 <- conv1_2
I0530 14:48:58.614776  6908 net.cpp:380] pool1 -> pool1
I0530 14:48:58.614776  6908 net.cpp:122] Setting up pool1
I0530 14:48:58.614776  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:48:58.614776  6908 net.cpp:137] Memory required for data: 6832128
I0530 14:48:58.614776  6908 layer_factory.hpp:77] Creating layer conv2_1
I0530 14:48:58.614776  6908 net.cpp:84] Creating Layer conv2_1
I0530 14:48:58.614776  6908 net.cpp:406] conv2_1 <- pool1
I0530 14:48:58.614776  6908 net.cpp:380] conv2_1 -> conv2_1
I0530 14:48:58.615775  6908 net.cpp:122] Setting up conv2_1
I0530 14:48:58.615775  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:48:58.615775  6908 net.cpp:137] Memory required for data: 7094272
I0530 14:48:58.615775  6908 layer_factory.hpp:77] Creating layer relu2_1
I0530 14:48:58.615775  6908 net.cpp:84] Creating Layer relu2_1
I0530 14:48:58.615775  6908 net.cpp:406] relu2_1 <- conv2_1
I0530 14:48:58.615775  6908 net.cpp:367] relu2_1 -> conv2_1 (in-place)
I0530 14:48:58.615775  6908 net.cpp:122] Setting up relu2_1
I0530 14:48:58.615775  6908 net.cpp:129] Top shape: 1 64 32 32 (65536)
I0530 14:48:58.615775  6908 net.cpp:137] Memory required for data: 7356416
I0530 14:48:58.615775  6908 layer_factory.hpp:77] Creating layer conv2_2
I0530 14:48:58.615775  6908 net.cpp:84] Creating Layer conv2_2
I0530 14:48:58.615775  6908 net.cpp:406] conv2_2 <- conv2_1
I0530 14:48:58.615775  6908 net.cpp:380] conv2_2 -> conv2_2
I0530 14:48:58.615775  6908 net.cpp:122] Setting up conv2_2
I0530 14:48:58.615775  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:48:58.615775  6908 net.cpp:137] Memory required for data: 7880704
I0530 14:48:58.615775  6908 layer_factory.hpp:77] Creating layer relu2_2
I0530 14:48:58.615775  6908 net.cpp:84] Creating Layer relu2_2
I0530 14:48:58.615775  6908 net.cpp:406] relu2_2 <- conv2_2
I0530 14:48:58.615775  6908 net.cpp:367] relu2_2 -> conv2_2 (in-place)
I0530 14:48:58.615775  6908 net.cpp:122] Setting up relu2_2
I0530 14:48:58.615775  6908 net.cpp:129] Top shape: 1 128 32 32 (131072)
I0530 14:48:58.615775  6908 net.cpp:137] Memory required for data: 8404992
I0530 14:48:58.615775  6908 layer_factory.hpp:77] Creating layer pool2
I0530 14:48:58.615775  6908 net.cpp:84] Creating Layer pool2
I0530 14:48:58.615775  6908 net.cpp:406] pool2 <- conv2_2
I0530 14:48:58.615775  6908 net.cpp:380] pool2 -> pool2
I0530 14:48:58.615775  6908 net.cpp:122] Setting up pool2
I0530 14:48:58.615775  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:58.615775  6908 net.cpp:137] Memory required for data: 8536064
I0530 14:48:58.615775  6908 layer_factory.hpp:77] Creating layer conv3_1
I0530 14:48:58.615775  6908 net.cpp:84] Creating Layer conv3_1
I0530 14:48:58.616775  6908 net.cpp:406] conv3_1 <- pool2
I0530 14:48:58.616775  6908 net.cpp:380] conv3_1 -> conv3_1
I0530 14:48:58.616775  6908 net.cpp:122] Setting up conv3_1
I0530 14:48:58.616775  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:58.616775  6908 net.cpp:137] Memory required for data: 8667136
I0530 14:48:58.616775  6908 layer_factory.hpp:77] Creating layer relu3_1
I0530 14:48:58.616775  6908 net.cpp:84] Creating Layer relu3_1
I0530 14:48:58.616775  6908 net.cpp:406] relu3_1 <- conv3_1
I0530 14:48:58.616775  6908 net.cpp:367] relu3_1 -> conv3_1 (in-place)
I0530 14:48:58.616775  6908 net.cpp:122] Setting up relu3_1
I0530 14:48:58.616775  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:58.616775  6908 net.cpp:137] Memory required for data: 8798208
I0530 14:48:58.616775  6908 layer_factory.hpp:77] Creating layer conv3_2
I0530 14:48:58.616775  6908 net.cpp:84] Creating Layer conv3_2
I0530 14:48:58.616775  6908 net.cpp:406] conv3_2 <- conv3_1
I0530 14:48:58.616775  6908 net.cpp:380] conv3_2 -> conv3_2
I0530 14:48:58.617775  6908 net.cpp:122] Setting up conv3_2
I0530 14:48:58.617775  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:58.617775  6908 net.cpp:137] Memory required for data: 8929280
I0530 14:48:58.617775  6908 layer_factory.hpp:77] Creating layer relu3_2
I0530 14:48:58.617775  6908 net.cpp:84] Creating Layer relu3_2
I0530 14:48:58.617775  6908 net.cpp:406] relu3_2 <- conv3_2
I0530 14:48:58.617775  6908 net.cpp:367] relu3_2 -> conv3_2 (in-place)
I0530 14:48:58.617775  6908 net.cpp:122] Setting up relu3_2
I0530 14:48:58.617775  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:58.617775  6908 net.cpp:137] Memory required for data: 9060352
I0530 14:48:58.617775  6908 layer_factory.hpp:77] Creating layer conv3_3
I0530 14:48:58.617775  6908 net.cpp:84] Creating Layer conv3_3
I0530 14:48:58.617775  6908 net.cpp:406] conv3_3 <- conv3_2
I0530 14:48:58.617775  6908 net.cpp:380] conv3_3 -> conv3_3
I0530 14:48:58.619454  6908 net.cpp:122] Setting up conv3_3
I0530 14:48:58.619454  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:58.619454  6908 net.cpp:137] Memory required for data: 9191424
I0530 14:48:58.619454  6908 layer_factory.hpp:77] Creating layer relu3_3
I0530 14:48:58.619454  6908 net.cpp:84] Creating Layer relu3_3
I0530 14:48:58.619454  6908 net.cpp:406] relu3_3 <- conv3_3
I0530 14:48:58.619454  6908 net.cpp:367] relu3_3 -> conv3_3 (in-place)
I0530 14:48:58.619454  6908 net.cpp:122] Setting up relu3_3
I0530 14:48:58.619454  6908 net.cpp:129] Top shape: 1 128 16 16 (32768)
I0530 14:48:58.619454  6908 net.cpp:137] Memory required for data: 9322496
I0530 14:48:58.619454  6908 layer_factory.hpp:77] Creating layer pool3
I0530 14:48:58.619454  6908 net.cpp:84] Creating Layer pool3
I0530 14:48:58.619454  6908 net.cpp:406] pool3 <- conv3_3
I0530 14:48:58.619454  6908 net.cpp:380] pool3 -> pool3
I0530 14:48:58.619454  6908 net.cpp:122] Setting up pool3
I0530 14:48:58.619454  6908 net.cpp:129] Top shape: 1 128 8 8 (8192)
I0530 14:48:58.619454  6908 net.cpp:137] Memory required for data: 9355264
I0530 14:48:58.619454  6908 layer_factory.hpp:77] Creating layer conv4_1
I0530 14:48:58.619454  6908 net.cpp:84] Creating Layer conv4_1
I0530 14:48:58.619454  6908 net.cpp:406] conv4_1 <- pool3
I0530 14:48:58.619454  6908 net.cpp:380] conv4_1 -> conv4_1
I0530 14:48:58.621457  6908 net.cpp:122] Setting up conv4_1
I0530 14:48:58.621457  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:58.621457  6908 net.cpp:137] Memory required for data: 9420800
I0530 14:48:58.621457  6908 layer_factory.hpp:77] Creating layer relu4_1
I0530 14:48:58.621457  6908 net.cpp:84] Creating Layer relu4_1
I0530 14:48:58.621457  6908 net.cpp:406] relu4_1 <- conv4_1
I0530 14:48:58.621457  6908 net.cpp:367] relu4_1 -> conv4_1 (in-place)
I0530 14:48:58.621457  6908 net.cpp:122] Setting up relu4_1
I0530 14:48:58.621457  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:58.621457  6908 net.cpp:137] Memory required for data: 9486336
I0530 14:48:58.621457  6908 layer_factory.hpp:77] Creating layer conv4_2
I0530 14:48:58.621457  6908 net.cpp:84] Creating Layer conv4_2
I0530 14:48:58.621457  6908 net.cpp:406] conv4_2 <- conv4_1
I0530 14:48:58.621457  6908 net.cpp:380] conv4_2 -> conv4_2
I0530 14:48:58.625602  6908 net.cpp:122] Setting up conv4_2
I0530 14:48:58.625602  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:58.625602  6908 net.cpp:137] Memory required for data: 9551872
I0530 14:48:58.625602  6908 layer_factory.hpp:77] Creating layer relu4_2
I0530 14:48:58.625602  6908 net.cpp:84] Creating Layer relu4_2
I0530 14:48:58.625602  6908 net.cpp:406] relu4_2 <- conv4_2
I0530 14:48:58.625602  6908 net.cpp:367] relu4_2 -> conv4_2 (in-place)
I0530 14:48:58.625602  6908 net.cpp:122] Setting up relu4_2
I0530 14:48:58.625602  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:58.625602  6908 net.cpp:137] Memory required for data: 9617408
I0530 14:48:58.625602  6908 layer_factory.hpp:77] Creating layer conv4_3
I0530 14:48:58.625602  6908 net.cpp:84] Creating Layer conv4_3
I0530 14:48:58.625602  6908 net.cpp:406] conv4_3 <- conv4_2
I0530 14:48:58.625602  6908 net.cpp:380] conv4_3 -> conv4_3
I0530 14:48:58.628598  6908 net.cpp:122] Setting up conv4_3
I0530 14:48:58.628598  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:58.628598  6908 net.cpp:137] Memory required for data: 9682944
I0530 14:48:58.628598  6908 layer_factory.hpp:77] Creating layer relu4_3
I0530 14:48:58.628598  6908 net.cpp:84] Creating Layer relu4_3
I0530 14:48:58.628598  6908 net.cpp:406] relu4_3 <- conv4_3
I0530 14:48:58.628598  6908 net.cpp:367] relu4_3 -> conv4_3 (in-place)
I0530 14:48:58.628598  6908 net.cpp:122] Setting up relu4_3
I0530 14:48:58.628598  6908 net.cpp:129] Top shape: 1 256 8 8 (16384)
I0530 14:48:58.628598  6908 net.cpp:137] Memory required for data: 9748480
I0530 14:48:58.628598  6908 layer_factory.hpp:77] Creating layer pool4
I0530 14:48:58.628598  6908 net.cpp:84] Creating Layer pool4
I0530 14:48:58.628598  6908 net.cpp:406] pool4 <- conv4_3
I0530 14:48:58.628598  6908 net.cpp:380] pool4 -> pool4
I0530 14:48:58.628598  6908 net.cpp:122] Setting up pool4
I0530 14:48:58.628598  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:58.628598  6908 net.cpp:137] Memory required for data: 9764864
I0530 14:48:58.628598  6908 layer_factory.hpp:77] Creating layer conv5_1
I0530 14:48:58.628598  6908 net.cpp:84] Creating Layer conv5_1
I0530 14:48:58.628598  6908 net.cpp:406] conv5_1 <- pool4
I0530 14:48:58.628598  6908 net.cpp:380] conv5_1 -> conv5_1
I0530 14:48:58.632598  6908 net.cpp:122] Setting up conv5_1
I0530 14:48:58.632598  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:58.632598  6908 net.cpp:137] Memory required for data: 9781248
I0530 14:48:58.632598  6908 layer_factory.hpp:77] Creating layer relu5_1
I0530 14:48:58.632598  6908 net.cpp:84] Creating Layer relu5_1
I0530 14:48:58.632598  6908 net.cpp:406] relu5_1 <- conv5_1
I0530 14:48:58.632598  6908 net.cpp:367] relu5_1 -> conv5_1 (in-place)
I0530 14:48:58.632598  6908 net.cpp:122] Setting up relu5_1
I0530 14:48:58.632598  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:58.632598  6908 net.cpp:137] Memory required for data: 9797632
I0530 14:48:58.632598  6908 layer_factory.hpp:77] Creating layer conv5_2
I0530 14:48:58.632598  6908 net.cpp:84] Creating Layer conv5_2
I0530 14:48:58.632598  6908 net.cpp:406] conv5_2 <- conv5_1
I0530 14:48:58.632598  6908 net.cpp:380] conv5_2 -> conv5_2
I0530 14:48:58.636600  6908 net.cpp:122] Setting up conv5_2
I0530 14:48:58.636600  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:58.636600  6908 net.cpp:137] Memory required for data: 9814016
I0530 14:48:58.636600  6908 layer_factory.hpp:77] Creating layer relu5_2
I0530 14:48:58.636600  6908 net.cpp:84] Creating Layer relu5_2
I0530 14:48:58.636600  6908 net.cpp:406] relu5_2 <- conv5_2
I0530 14:48:58.636600  6908 net.cpp:367] relu5_2 -> conv5_2 (in-place)
I0530 14:48:58.636600  6908 net.cpp:122] Setting up relu5_2
I0530 14:48:58.636600  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:58.636600  6908 net.cpp:137] Memory required for data: 9830400
I0530 14:48:58.636600  6908 layer_factory.hpp:77] Creating layer conv5_3
I0530 14:48:58.636600  6908 net.cpp:84] Creating Layer conv5_3
I0530 14:48:58.636600  6908 net.cpp:406] conv5_3 <- conv5_2
I0530 14:48:58.636600  6908 net.cpp:380] conv5_3 -> conv5_3
I0530 14:48:58.640591  6908 net.cpp:122] Setting up conv5_3
I0530 14:48:58.640591  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:58.640591  6908 net.cpp:137] Memory required for data: 9846784
I0530 14:48:58.640591  6908 layer_factory.hpp:77] Creating layer relu5_3
I0530 14:48:58.640591  6908 net.cpp:84] Creating Layer relu5_3
I0530 14:48:58.640591  6908 net.cpp:406] relu5_3 <- conv5_3
I0530 14:48:58.640591  6908 net.cpp:367] relu5_3 -> conv5_3 (in-place)
I0530 14:48:58.640591  6908 net.cpp:122] Setting up relu5_3
I0530 14:48:58.640591  6908 net.cpp:129] Top shape: 1 256 4 4 (4096)
I0530 14:48:58.640591  6908 net.cpp:137] Memory required for data: 9863168
I0530 14:48:58.640591  6908 layer_factory.hpp:77] Creating layer pool5
I0530 14:48:58.640591  6908 net.cpp:84] Creating Layer pool5
I0530 14:48:58.640591  6908 net.cpp:406] pool5 <- conv5_3
I0530 14:48:58.640591  6908 net.cpp:380] pool5 -> pool5
I0530 14:48:58.640591  6908 net.cpp:122] Setting up pool5
I0530 14:48:58.640591  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:48:58.640591  6908 net.cpp:137] Memory required for data: 9867264
I0530 14:48:58.640591  6908 layer_factory.hpp:77] Creating layer drop6
I0530 14:48:58.640591  6908 net.cpp:84] Creating Layer drop6
I0530 14:48:58.640591  6908 net.cpp:406] drop6 <- pool5
I0530 14:48:58.640591  6908 net.cpp:367] drop6 -> pool5 (in-place)
I0530 14:48:58.640591  6908 net.cpp:122] Setting up drop6
I0530 14:48:58.640591  6908 net.cpp:129] Top shape: 1 256 2 2 (1024)
I0530 14:48:58.640591  6908 net.cpp:137] Memory required for data: 9871360
I0530 14:48:58.640591  6908 layer_factory.hpp:77] Creating layer fc6
I0530 14:48:58.640591  6908 net.cpp:84] Creating Layer fc6
I0530 14:48:58.640591  6908 net.cpp:406] fc6 <- pool5
I0530 14:48:58.640591  6908 net.cpp:380] fc6 -> fc6
I0530 14:48:58.643590  6908 net.cpp:122] Setting up fc6
I0530 14:48:58.643590  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:48:58.643590  6908 net.cpp:137] Memory required for data: 9873408
I0530 14:48:58.643590  6908 layer_factory.hpp:77] Creating layer relu6
I0530 14:48:58.643590  6908 net.cpp:84] Creating Layer relu6
I0530 14:48:58.643590  6908 net.cpp:406] relu6 <- fc6
I0530 14:48:58.643590  6908 net.cpp:367] relu6 -> fc6 (in-place)
I0530 14:48:58.643590  6908 net.cpp:122] Setting up relu6
I0530 14:48:58.643590  6908 net.cpp:129] Top shape: 1 512 (512)
I0530 14:48:58.643590  6908 net.cpp:137] Memory required for data: 9875456
I0530 14:48:58.643590  6908 layer_factory.hpp:77] Creating layer fc7
I0530 14:48:58.643590  6908 net.cpp:84] Creating Layer fc7
I0530 14:48:58.643590  6908 net.cpp:406] fc7 <- fc6
I0530 14:48:58.643590  6908 net.cpp:380] fc7 -> fc7
I0530 14:48:58.643590  6908 net.cpp:122] Setting up fc7
I0530 14:48:58.643590  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:48:58.643590  6908 net.cpp:137] Memory required for data: 9875464
I0530 14:48:58.643590  6908 layer_factory.hpp:77] Creating layer prob
I0530 14:48:58.643590  6908 net.cpp:84] Creating Layer prob
I0530 14:48:58.643590  6908 net.cpp:406] prob <- fc7
I0530 14:48:58.643590  6908 net.cpp:380] prob -> prob
I0530 14:48:58.644594  6908 net.cpp:122] Setting up prob
I0530 14:48:58.644594  6908 net.cpp:129] Top shape: 1 2 (2)
I0530 14:48:58.644594  6908 net.cpp:137] Memory required for data: 9875472
I0530 14:48:58.644594  6908 net.cpp:200] prob does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] fc7 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu6 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] fc6 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] drop6 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] pool5 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu5_3 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv5_3 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu5_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv5_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu5_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv5_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] pool4 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu4_3 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv4_3 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu4_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv4_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu4_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv4_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] pool3 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu3_3 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv3_3 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu3_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv3_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu3_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv3_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] pool2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu2_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv2_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu2_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv2_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] pool1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu1_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv1_2 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] relu1_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] conv1_1 does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:200] input does not need backward computation.
I0530 14:48:58.644594  6908 net.cpp:242] This network produces output prob
I0530 14:48:58.644594  6908 net.cpp:255] Network initialization done.
I0530 14:48:58.663599  6908 net.cpp:744] Ignoring source layer data
I0530 14:48:58.666586  6908 net.cpp:744] Ignoring source layer loss
